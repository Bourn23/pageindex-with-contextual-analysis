{
  "doc_name": "adefowoke-ojokoh-et-al-2009-automated-document-metadata-extraction.pdf",
  "structure": [
    {
      "title": "Automated document metadata extraction",
      "start_index": 1,
      "end_index": 1,
      "nodes": [
        {
          "title": "Document Metadata Extraction Model",
          "start_index": 1,
          "end_index": 1,
          "text": "Web documents are available in various forms, most of which do not carry additional semantics. This paper\n\npresents a model for general document metadata extraction. The model, which combines segmentation by keywords and pattern matching techniques, was implemented using PHP , MySQL, JavaScript and HTML.\n\nThe system was tested with 40 randomly selected PDF documents (mainly theses). An evaluation of the sys-\n\ntem was done using standard criteria measures namely precision, recall, accuracy and F-measure. The\n\nresults show that the model is relatively effective for the task of metadata extraction, especially for theses and dissertations. A combination of machine learning with these rule-based methods will be explored in the\n\nfuture for better results.",
          "summary": "This section describes the model for general document metadata extraction, which combines segmentation by keywords and pattern matching techniques. It was implemented using PHP, MySQL, JavaScript, and HTML, and evaluated using precision, recall, accuracy, and F-measure.",
          "node_type": "semantic_unit",
          "metadata": {
            "semantic_type": "procedure",
            "start_paragraph": 7,
            "end_paragraph": 12,
            "original_title": "Document Metadata Extraction Model"
          },
          "nodes": [],
          "node_id": "0001"
        },
        {
          "title": "Keywords",
          "start_index": 1,
          "end_index": 1,
          "text": "Keywords: keywords; metadata; rules; segmentation; theses",
          "summary": "Lists the keywords associated with the document: keywords, metadata, rules, segmentation, theses.",
          "node_type": "semantic_unit",
          "metadata": {
            "semantic_type": "materials",
            "start_paragraph": 13,
            "end_paragraph": 13,
            "original_title": "Keywords"
          },
          "nodes": [],
          "node_id": "0002"
        },
        {
          "title": "Introduction to Automated Document Structure Extraction",
          "start_index": 1,
          "end_index": 1,
          "text": "The availability of large, web accessible, heterogeneous repositories of electronic documents is\n\nincreasing rapidly [1]. Most of this information is in the form of unstructured text, making the infor -\n\nmation hard to query [2]. Defining metadata for such documents will be useful for searching, brows-ing, and filtering. Ideally, metadata is defined by the authors of documents and is then used by various systems. However, people seldom define document metadata by themselves, even when they have convenient metadata definition tools [3]. Hence, automatically extracting metadata from the bodies of documents is an important research issue.\n\nAutomated document structure extraction has a number of benefits. Firstly, it makes automated\n\nmark-up possible. This helps to preserve information which might be required from the docu -\n\nment in the future. In addition, documents with logical structure can be presented differently for different devices. This flexibility in presentation is very useful to handle different devices. For example, a document can be presented differently in a PDA and in a web browser. Keeping docu -\n\nment logical structure also allows different users to have different access to a document. Some users may have unlimited access to a document while other users may have some limitations, for example, a textbook in which a professor has access to the answers as well as questions and a\n\nCorrespondence to: Bolanle Adefowoke Ojokoh, Department of Computer Science, P.M.B. 704, Akure,\n\nNigeria. Email: bolanleojokoh@yahoo.com",
          "summary": "This section introduces the problem of increasing web document repositories and the difficulty in querying unstructured text. It highlights the benefits of automated document structure extraction, such as automated mark-up, preservation of information, and flexible presentation for different devices and users.",
          "node_type": "semantic_unit",
          "metadata": {
            "semantic_type": "procedure",
            "start_paragraph": 15,
            "end_paragraph": 23,
            "original_title": "Introduction to Automated Document Structure Extraction"
          },
          "nodes": [],
          "node_id": "0003"
        },
        {
          "title": "Introduction",
          "start_index": 1,
          "end_index": 2,
          "node_id": "0004",
          "text": "Journal of Information Science, 35 (5) 2009, pp. 563\u2013570 \u00a9 The Authors, 2009. Reprints and Permissions:  \nhttp://www.sagepub.co.uk/journalspermissions.nav, DOI: 10.1177/0165551509105195 563Automated document \nmetadata extraction\nBolanle Adefowoke Ojokoh, Olumide Sunday Adewale and \nSamuel Oluwole Falaki\nDepartment of Computer Science, Federal University of Technology, Nigeria\nAbstract.\nWeb documents are available in various forms, most of which do not carry additional semantics. This paper \npresents a model for general document metadata extraction. The model, which combines segmentation by keywords and pattern matching techniques, was implemented using PHP , MySQL, JavaScript and HTML. \nThe system was tested with 40 randomly selected PDF documents (mainly theses). An evaluation of the sys-\ntem was done using standard criteria measures namely precision, recall, accuracy and F-measure. The \nresults show that the model is relatively effective for the task of metadata extraction, especially for theses and dissertations. A combination of machine learning with these rule-based methods will be explored in the \nfuture for better results.\nKeywords: keywords; metadata; rules; segmentation; theses\n1. Introduction\nThe availability of large, web accessible, heterogeneous repositories of electronic documents is \nincreasing rapidly [1]. Most of this information is in the form of unstructured text, making the infor -\nmation hard to query [2]. Defining metadata for such documents will be useful for searching, brows-ing, and filtering. Ideally, metadata is defined by the authors of documents and is then used by various systems. However, people seldom define document metadata by themselves, even when they have convenient metadata definition tools [3]. Hence, automatically extracting metadata from the bodies of documents is an important research issue.\nAutomated document structure extraction has a number of benefits. Firstly, it makes automated \nmark-up possible. This helps to preserve information which might be required from the docu -\nment in the future. In addition, documents with logical structure can be presented differently for different devices. This flexibility in presentation is very useful to handle different devices. For example, a document can be presented differently in a PDA and in a web browser. Keeping docu -\nment logical structure also allows different users to have different access to a document. Some users may have unlimited access to a document while other users may have some limitations, for example, a textbook in which a professor has access to the answers as well as questions and a \nCorrespondence to: Bolanle Adefowoke Ojokoh, Department of Computer Science, P.M.B. 704, Akure, \nNigeria. Email: bolanleojokoh@yahoo.comBolanle Adefowoke Ojokoh et al.\nJournal of Information Science, 35 (5) 2009, pp. 563\u2013570 \u00a9 CILIP, DOI: 10.1177/0165551509105195 564student can access questions only. Finally, document logical structure helps resource discovery. \nWith logical structure, a document can be searched in other ways instead of full text and metadata searches. For example, a document can be searched in a specific section, such as the introduction. It also allows search by some complex objects such as equations. Building tools for automatic metadata extraction and representation significantly improves the amount of metadata available, the quality of metadata extracted, and the efficiency and speed of the metadata extraction process [4, 5]. This paper focuses on presenting an approach for general metadata extraction from docu -\nments, with emphasis on theses. Metadata such as Title, Table of Contents, Abstract, Acknowledgement, Preface, Introduction, Conclusion and References are extracted from docu -\nments which could be in PDF, Word or Text formats.\nThe remainder of this paper is organized as follows: Section 2 presents a number of recent meta-\ndata extraction-related researches. An overview of the proposed approach for document metadata extraction is presented in Section 3. Section 4 gives the implementation and evaluation results while Section 5 presents the conclusion and further research directions.\n2. Review of related studies\nMetadata is, most generally, data that describes other data to enhance their usefulness in content exploration [6]. Several methods have been used for automatic metadata extraction from documents; regular expressions, rule-based parsers and machine learning are the most popular [4]. Liddy et al. [7] and Yilmazel et al. [8] developed rule-based systems founded on natural language processing technologies to extract metadata from educational materials. Mao et al. [9] performed metadata extraction using rule-based methods, particularly using rules based on formatting information which would not be possible with text files. Using a machine learning approach, Hu and colleagues [10] extracted titles from general documents. Han et al. [4] carried out metadata extraction. They viewed the problem as that of classifying the lines in a document into the categories of metadata and proposed using Support Vector Machines (SVM) as the classifier. They mainly used linguistic information as features. They reported high extraction accuracy from research papers in terms of precision and recall. Peng and McCallum [11] also conducted information extraction from research papers. They employed a Conditional Random Fields (CRF) model. Ojokoh et al. [12] used Hidden Markov Models (HMM) to implement the task of metadata extraction from some sets of tagged bib-liographic references and particularly contributed to improving the smoothing technique suggested by earlier researchers. Most of these researches, however, focused on extraction from research papers that have most of the metadata to be extracted located on the first page of the paper [10]. Moreover, most of them carried out the task of metadata extraction for just a single metadata, such as author names or titles, only [13, 14]. This research combines the idea of extracting the structure of documents using keywords with regular expressions to extract metadata from documents.\n3. Document metadata extraction architecture\nThe developed system is made up of six components, four modules (Converter, Segmentation Engine, Parser and Browser), each carrying out its own function towards the task of metadata extrac-tion, and the Input and Output of the system. Equations (1)\u2013(13) describe these components, their functions and relationship mathematically.\nThe Document Metadata Extractor, D is a 6-tuple (I, C, S, P, B, O)\nD = (I, C, S, P, B, O)  (1)\nwhere I is the Input, C is the Converter, S is the Segmentation Engine, P is the Parser, B is the \nBrowser and O is the Output.\n(i) I:p (2)",
          "summary": "This partial document discusses the challenge of extracting metadata from web documents, which often lack explicit semantic information. It presents a model for automated document metadata extraction that combines keyword-based segmentation and pattern matching techniques. The system was implemented using PHP, MySQL, JavaScript, and HTML, and tested on 40 PDF documents, primarily theses. The evaluation used standard metrics like precision, recall, accuracy, and F-measure, indicating the model's relative effectiveness, particularly for theses and dissertations. The authors suggest exploring a combination of machine learning with rule-based methods in the future for improved results. The introduction highlights the benefits of automated document structure extraction, including automated mark-up, flexible presentation across devices, differentiated user access, and enhanced resource discovery."
        },
        {
          "title": "Figure (Page 1): No caption available",
          "start_index": 1,
          "end_index": 1,
          "text": "No caption available\n\nJournal of Information Science, 35 (5) 2009, pp. 563\u2013570 \u00a9 The Authors, 2009. Reprints and Permissions:\n\nhttp://www.sagepub.co.uk/journalspermissions.nav, DOI: 10.1177/0165551509105195 563Automated document\n\nmetadata extraction\n\nBolanle Adefowoke Ojokoh, Olumide Sunday Adewale and\n\nSamuel Oluwole Falaki",
          "summary": "The figure displays the logo for the \"Journal of Information Science\". This indicates that the accompanying research paper is published within this academic journal. The logo itself provides no research findings but serves to identify the source of the publication.",
          "node_type": "figure",
          "metadata": {
            "figure_number": "Figure (Page 1)",
            "caption": "No caption available",
            "figure_type": "other",
            "bbox": {
              "x_min": 74.28270803184496,
              "y_min": 5.700568448300934,
              "x_max": 89.20015601350231,
              "y_max": 12.8004720394814
            }
          },
          "nodes": [],
          "node_id": "0005"
        }
      ],
      "text": "Journal of Information Science, 35 (5) 2009, pp. 563\u2013570 \u00a9 The Authors, 2009. Reprints and Permissions:  \nhttp://www.sagepub.co.uk/journalspermissions.nav, DOI: 10.1177/0165551509105195 563Automated document \nmetadata extraction\nBolanle Adefowoke Ojokoh, Olumide Sunday Adewale and \nSamuel Oluwole Falaki\nDepartment of Computer Science, Federal University of Technology, Nigeria\nAbstract.\nWeb documents are available in various forms, most of which do not carry additional semantics. This paper \npresents a model for general document metadata extraction. The model, which combines segmentation by keywords and pattern matching techniques, was implemented using PHP , MySQL, JavaScript and HTML. \nThe system was tested with 40 randomly selected PDF documents (mainly theses). An evaluation of the sys-\ntem was done using standard criteria measures namely precision, recall, accuracy and F-measure. The \nresults show that the model is relatively effective for the task of metadata extraction, especially for theses and dissertations. A combination of machine learning with these rule-based methods will be explored in the \nfuture for better results.\nKeywords: keywords; metadata; rules; segmentation; theses\n1. Introduction\nThe availability of large, web accessible, heterogeneous repositories of electronic documents is \nincreasing rapidly [1]. Most of this information is in the form of unstructured text, making the infor -\nmation hard to query [2]. Defining metadata for such documents will be useful for searching, brows-ing, and filtering. Ideally, metadata is defined by the authors of documents and is then used by various systems. However, people seldom define document metadata by themselves, even when they have convenient metadata definition tools [3]. Hence, automatically extracting metadata from the bodies of documents is an important research issue.\nAutomated document structure extraction has a number of benefits. Firstly, it makes automated \nmark-up possible. This helps to preserve information which might be required from the docu -\nment in the future. In addition, documents with logical structure can be presented differently for different devices. This flexibility in presentation is very useful to handle different devices. For example, a document can be presented differently in a PDA and in a web browser. Keeping docu -\nment logical structure also allows different users to have different access to a document. Some users may have unlimited access to a document while other users may have some limitations, for example, a textbook in which a professor has access to the answers as well as questions and a \nCorrespondence to: Bolanle Adefowoke Ojokoh, Department of Computer Science, P.M.B. 704, Akure, \nNigeria. Email: bolanleojokoh@yahoo.com",
      "node_id": "0000",
      "summary": "This section introduces automated document structure extraction as a solution to challenges in querying large web document repositories. It details a specific model for document metadata extraction using keyword and pattern matching techniques, implemented with PHP, MySQL, JavaScript, and HTML. The section also highlights the benefits of automated extraction, such as improved mark-up and flexible information presentation."
    },
    {
      "title": "Review of related studies",
      "start_index": 2,
      "end_index": 3,
      "text": "Bolanle Adefowoke Ojokoh et al.\nJournal of Information Science, 35 (5) 2009, pp. 563\u2013570 \u00a9 CILIP, DOI: 10.1177/0165551509105195 564student can access questions only. Finally, document logical structure helps resource discovery. \nWith logical structure, a document can be searched in other ways instead of full text and metadata searches. For example, a document can be searched in a specific section, such as the introduction. It also allows search by some complex objects such as equations. Building tools for automatic metadata extraction and representation significantly improves the amount of metadata available, the quality of metadata extracted, and the efficiency and speed of the metadata extraction process [4, 5]. This paper focuses on presenting an approach for general metadata extraction from docu -\nments, with emphasis on theses. Metadata such as Title, Table of Contents, Abstract, Acknowledgement, Preface, Introduction, Conclusion and References are extracted from docu -\nments which could be in PDF, Word or Text formats.\nThe remainder of this paper is organized as follows: Section 2 presents a number of recent meta-\ndata extraction-related researches. An overview of the proposed approach for document metadata extraction is presented in Section 3. Section 4 gives the implementation and evaluation results while Section 5 presents the conclusion and further research directions.\n2. Review of related studies\nMetadata is, most generally, data that describes other data to enhance their usefulness in content exploration [6]. Several methods have been used for automatic metadata extraction from documents; regular expressions, rule-based parsers and machine learning are the most popular [4]. Liddy et al. [7] and Yilmazel et al. [8] developed rule-based systems founded on natural language processing technologies to extract metadata from educational materials. Mao et al. [9] performed metadata extraction using rule-based methods, particularly using rules based on formatting information which would not be possible with text files. Using a machine learning approach, Hu and colleagues [10] extracted titles from general documents. Han et al. [4] carried out metadata extraction. They viewed the problem as that of classifying the lines in a document into the categories of metadata and proposed using Support Vector Machines (SVM) as the classifier. They mainly used linguistic information as features. They reported high extraction accuracy from research papers in terms of precision and recall. Peng and McCallum [11] also conducted information extraction from research papers. They employed a Conditional Random Fields (CRF) model. Ojokoh et al. [12] used Hidden Markov Models (HMM) to implement the task of metadata extraction from some sets of tagged bib-liographic references and particularly contributed to improving the smoothing technique suggested by earlier researchers. Most of these researches, however, focused on extraction from research papers that have most of the metadata to be extracted located on the first page of the paper [10]. Moreover, most of them carried out the task of metadata extraction for just a single metadata, such as author names or titles, only [13, 14]. This research combines the idea of extracting the structure of documents using keywords with regular expressions to extract metadata from documents.\n3. Document metadata extraction architecture\nThe developed system is made up of six components, four modules (Converter, Segmentation Engine, Parser and Browser), each carrying out its own function towards the task of metadata extrac-tion, and the Input and Output of the system. Equations (1)\u2013(13) describe these components, their functions and relationship mathematically.\nThe Document Metadata Extractor, D is a 6-tuple (I, C, S, P, B, O)\nD = (I, C, S, P, B, O)  (1)\nwhere I is the Input, C is the Converter, S is the Segmentation Engine, P is the Parser, B is the \nBrowser and O is the Output.\n(i) I:p (2)Bolanle Adefowoke Ojokoh et al.\nJournal of Information Science, 35 (5) 2009, pp. 563\u2013570 \u00a9 CILIP, DOI: 10.1177/0165551509105195 565where p is the uploaded document needing conversion.\n(ii) Cp \u2192 t  (3)\nand\nt = {b1, b2, ..., bn} (4)\nwhere t is the text document and bn refers to block n in the document.\n(iii) S is a 2-tuple (M, G) (5)\nwhere M refers to the map function and G refers to the group function.\n(a) M: bi \u2192 sk (6)\nwhere sk refers to the set of identified pattern strings\n(b) G: {bi | sk = si, ..., n} where i \u2260 k (7)\nStep (b) is repeated until all grouping is done.\n\u2203bn\ni: t \u00b7 n is the number of groups in which bi occurs\n(iv) P: merge bi1,..,n \u2192 bi (8)\nthen,\nE: (bi * mdi * si) \u2192 {mdi,bi} (9)\nmd \u2208 {abstract, tableofcontents, introduction, references} (10)\nwhere E is the extract function and md refers to the set of extracted metadata.\nTitle extraction is done with a different method as follows:\ntitle \u2208 {[A\u2013Z] * |first 1\u2013100 characters|1st three lines (11)\n(vi) \u2200mdi extracted, B displays O \u2208 {title, mdi, bi} (12)\nT:(D:u, mdi, ...4, bi, ...n)  (13)\nwhere T is the store function and D is the database.\nThis research work used an approach implementing the model combining segmentation by keyword \ntogether with the use of regular expressions, as presented earlier, to extract some set of metadata \nfrom documents. Title extraction is another challenging task that may not be easily done using only segmentation by keyword as titles of documents are not usually labelled. In this research some sets of rules were proposed for title extraction. Figure 1 describes the architecture of the document meta-data extractor.\nSegmentation is the generation of hierarchy of logical divisions from a document. This layout segmen -\ntation captures the divisions of the document\u2019s logical structure. It can be done in three ways [15]:\n\u2022 Segmentation by spacing: by using spacing information, scanned images are separated into sev-\neral areas which can be text, figure/table, or formulae areas.\n\u2022 Segmentation by style difference: for each text area, the average size of the characters contained in \nthe area is calculated. The size of a character can be determined by its height. Also boldness can be \ncalculated by the horizontal width of a character. In an area where the styles (bold, italic and size) of lines are obviously different from those of other lines, they are separately segmented.\n\u2022 Segmentation by keywords: in an area, where a special keyword (e.g. abstract, references) comes at \nthe beginning of a line, basically the area is segmented before the line as used in this research. This method is most relevant for this research because there are generally certain keywords specifically used in documents.",
      "node_id": "0006",
      "summary": "This partial document discusses the importance of document logical structure for resource discovery, enabling searches beyond full text and metadata. It highlights the benefits of automatic metadata extraction for improving the quantity, quality, efficiency, and speed of metadata availability. The paper proposes an approach for general metadata extraction from documents, specifically focusing on theses, and aims to extract metadata like Title, Table of Contents, Abstract, Acknowledgement, Preface, Introduction, Conclusion, and References from PDF, Word, and Text formats. The document is structured into sections covering related research, the proposed approach, implementation and evaluation, and conclusions with future research directions. It then reviews existing research on automatic metadata extraction, mentioning methods like regular expressions, rule-based parsers, and machine learning, and citing specific studies that employed these techniques for extracting metadata from various document types, including educational materials and research papers."
    },
    {
      "title": "Document metadata extraction architecture",
      "start_index": 3,
      "end_index": 3,
      "nodes": [
        {
          "title": "Document Conversion Model",
          "start_index": 3,
          "end_index": 3,
          "text": "Bolanle Adefowoke Ojokoh et al.\n\nJournal of Information Science, 35 (5) 2009, pp. 563\u2013570 \u00a9 CILIP, DOI: 10.1177/0165551509105195 565where p is the uploaded document needing conversion.\n\n(ii) Cp \u2192 t  (3)\n\nand\n\nt = {b1, b2, ..., bn} (4)\n\nwhere t is the text document and bn refers to block n in the document.\n\n(iii) S is a 2-tuple (M, G) (5)\n\nwhere M refers to the map function and G refers to the group function.\n\n(a) M: bi \u2192 sk (6)\n\nwhere sk refers to the set of identified pattern strings\n\n(b) G: {bi | sk = si, ..., n} where i \u2260 k (7)\n\nStep (b) is repeated until all grouping is done.\n\n\u2203bn\n\ni: t \u00b7 n is the number of groups in which bi occurs\n\n(iv) P: merge bi1,..,n \u2192 bi (8)\n\nthen,\n\nE: (bi * mdi * si) \u2192 {mdi,bi} (9)\n\nmd \u2208 {abstract, tableofcontents, introduction, references} (10)\n\nwhere E is the extract function and md refers to the set of extracted metadata.\n\nTitle extraction is done with a different method as follows:\n\ntitle \u2208 {[A\u2013Z] * |first 1\u2013100 characters|1st three lines (11)\n\n(vi) \u2200mdi extracted, B displays O \u2208 {title, mdi, bi} (12)\n\nT:(D:u, mdi, ...4, bi, ...n)  (13)\n\nwhere T is the store function and D is the database.",
          "summary": "This section details a model for document conversion, outlining functions for mapping, grouping, merging, and extracting metadata such as abstract, table of contents, introduction, and references. It also describes a specific method for title extraction.",
          "node_type": "semantic_unit",
          "metadata": {
            "semantic_type": "procedure",
            "start_paragraph": 0,
            "end_paragraph": 23,
            "original_title": "Document Conversion Model"
          },
          "nodes": [],
          "node_id": "0008"
        },
        {
          "title": "Metadata Extraction Approach",
          "start_index": 3,
          "end_index": 3,
          "text": "This research work used an approach implementing the model combining segmentation by keyword\n\ntogether with the use of regular expressions, as presented earlier, to extract some set of metadata\n\nfrom documents. Title extraction is another challenging task that may not be easily done using only segmentation by keyword as titles of documents are not usually labelled. In this research some sets of rules were proposed for title extraction. Figure 1 describes the architecture of the document meta-data extractor.",
          "summary": "This part describes the research's approach to metadata extraction, combining keyword-based segmentation with regular expressions. It highlights the challenge of title extraction and mentions proposed rules for it, referencing a figure for the architecture.",
          "node_type": "semantic_unit",
          "metadata": {
            "semantic_type": "procedure",
            "start_paragraph": 24,
            "end_paragraph": 26,
            "original_title": "Metadata Extraction Approach"
          },
          "nodes": [],
          "node_id": "0009"
        },
        {
          "title": "Segmentation Methods",
          "start_index": 3,
          "end_index": 3,
          "text": "Segmentation is the generation of hierarchy of logical divisions from a document. This layout segmen -\n\ntation captures the divisions of the document\u2019s logical structure. It can be done in three ways [15]:\n\n\u2022 Segmentation by spacing: by using spacing information, scanned images are separated into sev-\n\neral areas which can be text, figure/table, or formulae areas.\n\n\u2022 Segmentation by style difference: for each text area, the average size of the characters contained in\n\nthe area is calculated. The size of a character can be determined by its height. Also boldness can be\n\ncalculated by the horizontal width of a character. In an area where the styles (bold, italic and size) of lines are obviously different from those of other lines, they are separately segmented.\n\n\u2022 Segmentation by keywords: in an area, where a special keyword (e.g. abstract, references) comes at\n\nthe beginning of a line, basically the area is segmented before the line as used in this research. This method is most relevant for this research because there are generally certain keywords specifically used in documents.",
          "summary": "This section explains document segmentation as the generation of logical divisions. It describes three methods: segmentation by spacing, by style difference (considering character size and boldness), and by keywords, emphasizing the relevance of keyword segmentation for this research.",
          "node_type": "semantic_unit",
          "metadata": {
            "semantic_type": "procedure",
            "start_paragraph": 27,
            "end_paragraph": 35,
            "original_title": "Segmentation Methods"
          },
          "nodes": [],
          "node_id": "0010"
        },
        {
          "title": "Segmentation",
          "start_index": 3,
          "end_index": 5,
          "node_id": "0011",
          "text": "Bolanle Adefowoke Ojokoh et al.\nJournal of Information Science, 35 (5) 2009, pp. 563\u2013570 \u00a9 CILIP, DOI: 10.1177/0165551509105195 565where p is the uploaded document needing conversion.\n(ii) Cp \u2192 t  (3)\nand\nt = {b1, b2, ..., bn} (4)\nwhere t is the text document and bn refers to block n in the document.\n(iii) S is a 2-tuple (M, G) (5)\nwhere M refers to the map function and G refers to the group function.\n(a) M: bi \u2192 sk (6)\nwhere sk refers to the set of identified pattern strings\n(b) G: {bi | sk = si, ..., n} where i \u2260 k (7)\nStep (b) is repeated until all grouping is done.\n\u2203bn\ni: t \u00b7 n is the number of groups in which bi occurs\n(iv) P: merge bi1,..,n \u2192 bi (8)\nthen,\nE: (bi * mdi * si) \u2192 {mdi,bi} (9)\nmd \u2208 {abstract, tableofcontents, introduction, references} (10)\nwhere E is the extract function and md refers to the set of extracted metadata.\nTitle extraction is done with a different method as follows:\ntitle \u2208 {[A\u2013Z] * |first 1\u2013100 characters|1st three lines (11)\n(vi) \u2200mdi extracted, B displays O \u2208 {title, mdi, bi} (12)\nT:(D:u, mdi, ...4, bi, ...n)  (13)\nwhere T is the store function and D is the database.\nThis research work used an approach implementing the model combining segmentation by keyword \ntogether with the use of regular expressions, as presented earlier, to extract some set of metadata \nfrom documents. Title extraction is another challenging task that may not be easily done using only segmentation by keyword as titles of documents are not usually labelled. In this research some sets of rules were proposed for title extraction. Figure 1 describes the architecture of the document meta-data extractor.\nSegmentation is the generation of hierarchy of logical divisions from a document. This layout segmen -\ntation captures the divisions of the document\u2019s logical structure. It can be done in three ways [15]:\n\u2022 Segmentation by spacing: by using spacing information, scanned images are separated into sev-\neral areas which can be text, figure/table, or formulae areas.\n\u2022 Segmentation by style difference: for each text area, the average size of the characters contained in \nthe area is calculated. The size of a character can be determined by its height. Also boldness can be \ncalculated by the horizontal width of a character. In an area where the styles (bold, italic and size) of lines are obviously different from those of other lines, they are separately segmented.\n\u2022 Segmentation by keywords: in an area, where a special keyword (e.g. abstract, references) comes at \nthe beginning of a line, basically the area is segmented before the line as used in this research. This method is most relevant for this research because there are generally certain keywords specifically used in documents.Bolanle Adefowoke Ojokoh et al.\nJournal of Information Science, 35 (5) 2009, pp. 563\u2013570 \u00a9 CILIP, DOI: 10.1177/0165551509105195 566The segmentation algorithm proposed by Summers [1] was used for the purpose of logical struc-\nture extraction. This research names the algorithm used here as segmentation by keyword. It adopts \nsome relevant techniques from Summers\u2019s algorithm which is embedded in the entire algorithm used for document metadata extraction as follows:\n\u2022 Algorithm 1: Creating document input and converting uploaded file by typing document URL or locating from folder and converting document to text format\n\u2022 Algorithm 2: Segmenting the document by keywords.\nDivide the text document into blocks.\nRepresent each block by an appropriate string of indentation alphabet characters.Find sets of blocks that form repeating patterns.Find runs of isolated blocks that conform to patterns found elsewhere.Group together the blocks in each element of each pattern and group the isolated block forming \nthe next level of the tree surrounding blocks.\nRepeat (*) in order until no changes are generated.Group together the elements of each pattern forming another tree level.Repeat until no new changes are generated.Electronic\ndocuments\nParserFile\nConverter\nMetadataSegmentation\nEngineBrowser\nFig. 1. Document metadata extractor architecture.Bolanle Adefowoke Ojokoh et al.\nJournal of Information Science, 35 (5) 2009, pp. 563\u2013570 \u00a9 CILIP, DOI: 10.1177/0165551509105195 567\u2022 Algorithm 3: Extracting document metadata.\nLocate the keywords associated with metadata.\nLocate the block of document corresponding to the keyword(s) identified.Extract keyword found in the document alongside the block of document.\u2022 Algorithm 4: Displaying and storing result of extraction.\nDisplay metadata and extracted block of document in the browser window.Store the extracted metadata and block in the database.\nThe keywords used in the grouping include: Table of Contents, Abstract, Preface, Chapter 1(One), \nIntroduction, Conclusion, References, Bibliography, Citation and Appendix (A/1). They were used with their respective regular expressions used to match them.\n4. System implementation and evaluation\nThe document metadata extractor receives an uploaded document and converts it to text. On click-ing on any of the metadata listed on the left side of the browser window as hyperlinks, the extractor scans through the document and displays the corresponding content of the document. \nThe document metadata extractor was tested over a set of randomly selected theses, dissertations \nand a few technical reports downloaded from the web. Theses were, however, the main focus of the experiments (about 80% of the sample).\nThe evaluation of the system was done using the following criteria: recall, precision, accuracy, \nand F-measure [as defined in equations (14)\u2013(17)].\nAn exact performance comparison may not be possible, because of differences in the documents \nused for testing the different systems [16]. However, attempts are made to refer to related work and how the results compare with theirs. The results of the experimental evaluation of the reference metadata extractor are presented as follows.\n \nPrecision =A\nA+C (14)\n Recall =A\nA+B (15)\n Accuracy =A+D\nA+B+C+D (16)\n F/C0measur e=2/C3Precision /C3Recall\nPrecis ion+Recall (17)\nwhere A is the number of correctly extracted fields, B is the number of fields with existing, but not \nextracted data, C is the number of fields with wrongly extracted data, while D is the number of fields \nwith not existing and not extracted data.\nThe test for automatic extraction correctness was based on a manual verification of the correct-\nness of the extracted metadata against the original document. Due to such manual verification, which was lengthy and tedious, the sample size was limited to 40 documents.\nTables 1\u20134 summarize the overall precision, recall, accuracy and F-measure results respectively.",
          "summary": "This partial document describes a model for extracting metadata from documents. The core of the model involves segmenting documents into logical divisions, which can be achieved through methods like segmentation by spacing, style difference, and keywords. The research specifically utilizes segmentation by keywords, identifying patterns and grouping document blocks based on these patterns. The model also defines functions for mapping blocks to pattern strings, grouping blocks with similar patterns, merging blocks, and extracting metadata such as abstracts, table of contents, introductions, and references. A separate method is proposed for title extraction, as titles are not always explicitly labeled. The document outlines the architecture of the metadata extractor and mentions the use of the Summers segmentation algorithm for logical structure extraction."
        }
      ],
      "text": "Bolanle Adefowoke Ojokoh et al.\nJournal of Information Science, 35 (5) 2009, pp. 563\u2013570 \u00a9 CILIP, DOI: 10.1177/0165551509105195 565where p is the uploaded document needing conversion.\n(ii) Cp \u2192 t  (3)\nand\nt = {b1, b2, ..., bn} (4)\nwhere t is the text document and bn refers to block n in the document.\n(iii) S is a 2-tuple (M, G) (5)\nwhere M refers to the map function and G refers to the group function.\n(a) M: bi \u2192 sk (6)\nwhere sk refers to the set of identified pattern strings\n(b) G: {bi | sk = si, ..., n} where i \u2260 k (7)\nStep (b) is repeated until all grouping is done.\n\u2203bn\ni: t \u00b7 n is the number of groups in which bi occurs\n(iv) P: merge bi1,..,n \u2192 bi (8)\nthen,\nE: (bi * mdi * si) \u2192 {mdi,bi} (9)\nmd \u2208 {abstract, tableofcontents, introduction, references} (10)\nwhere E is the extract function and md refers to the set of extracted metadata.\nTitle extraction is done with a different method as follows:\ntitle \u2208 {[A\u2013Z] * |first 1\u2013100 characters|1st three lines (11)\n(vi) \u2200mdi extracted, B displays O \u2208 {title, mdi, bi} (12)\nT:(D:u, mdi, ...4, bi, ...n)  (13)\nwhere T is the store function and D is the database.\nThis research work used an approach implementing the model combining segmentation by keyword \ntogether with the use of regular expressions, as presented earlier, to extract some set of metadata \nfrom documents. Title extraction is another challenging task that may not be easily done using only segmentation by keyword as titles of documents are not usually labelled. In this research some sets of rules were proposed for title extraction. Figure 1 describes the architecture of the document meta-data extractor.\nSegmentation is the generation of hierarchy of logical divisions from a document. This layout segmen -\ntation captures the divisions of the document\u2019s logical structure. It can be done in three ways [15]:\n\u2022 Segmentation by spacing: by using spacing information, scanned images are separated into sev-\neral areas which can be text, figure/table, or formulae areas.\n\u2022 Segmentation by style difference: for each text area, the average size of the characters contained in \nthe area is calculated. The size of a character can be determined by its height. Also boldness can be \ncalculated by the horizontal width of a character. In an area where the styles (bold, italic and size) of lines are obviously different from those of other lines, they are separately segmented.\n\u2022 Segmentation by keywords: in an area, where a special keyword (e.g. abstract, references) comes at \nthe beginning of a line, basically the area is segmented before the line as used in this research. This method is most relevant for this research because there are generally certain keywords specifically used in documents.",
      "node_id": "0007",
      "summary": "This section outlines an architecture for document metadata extraction, detailing a conversion model that handles mapping, grouping, and merging of document elements. It describes a metadata extraction approach combining keyword-based segmentation and regular expressions, with a focus on title extraction challenges and solutions. The section also elaborates on various segmentation methods, highlighting keyword-based segmentation as particularly relevant."
    },
    {
      "title": "System implementation and evaluation",
      "start_index": 5,
      "end_index": 7,
      "text": "Bolanle Adefowoke Ojokoh et al.\nJournal of Information Science, 35 (5) 2009, pp. 563\u2013570 \u00a9 CILIP, DOI: 10.1177/0165551509105195 567\u2022 Algorithm 3: Extracting document metadata.\nLocate the keywords associated with metadata.\nLocate the block of document corresponding to the keyword(s) identified.Extract keyword found in the document alongside the block of document.\u2022 Algorithm 4: Displaying and storing result of extraction.\nDisplay metadata and extracted block of document in the browser window.Store the extracted metadata and block in the database.\nThe keywords used in the grouping include: Table of Contents, Abstract, Preface, Chapter 1(One), \nIntroduction, Conclusion, References, Bibliography, Citation and Appendix (A/1). They were used with their respective regular expressions used to match them.\n4. System implementation and evaluation\nThe document metadata extractor receives an uploaded document and converts it to text. On click-ing on any of the metadata listed on the left side of the browser window as hyperlinks, the extractor scans through the document and displays the corresponding content of the document. \nThe document metadata extractor was tested over a set of randomly selected theses, dissertations \nand a few technical reports downloaded from the web. Theses were, however, the main focus of the experiments (about 80% of the sample).\nThe evaluation of the system was done using the following criteria: recall, precision, accuracy, \nand F-measure [as defined in equations (14)\u2013(17)].\nAn exact performance comparison may not be possible, because of differences in the documents \nused for testing the different systems [16]. However, attempts are made to refer to related work and how the results compare with theirs. The results of the experimental evaluation of the reference metadata extractor are presented as follows.\n \nPrecision =A\nA+C (14)\n Recall =A\nA+B (15)\n Accuracy =A+D\nA+B+C+D (16)\n F/C0measur e=2/C3Precision /C3Recall\nPrecis ion+Recall (17)\nwhere A is the number of correctly extracted fields, B is the number of fields with existing, but not \nextracted data, C is the number of fields with wrongly extracted data, while D is the number of fields \nwith not existing and not extracted data.\nThe test for automatic extraction correctness was based on a manual verification of the correct-\nness of the extracted metadata against the original document. Due to such manual verification, which was lengthy and tedious, the sample size was limited to 40 documents.\nTables 1\u20134 summarize the overall precision, recall, accuracy and F-measure results respectively.Bolanle Adefowoke Ojokoh et al.\nJournal of Information Science, 35 (5) 2009, pp. 563\u2013570 \u00a9 CILIP, DOI: 10.1177/0165551509105195 568Table 1 \nMetadata extraction precision over 40 theses and related documents\n Precision\nTitle 0.75\nTable of Contents 0.73\nPreface 0.86\nAbstract 0.77\nAcknowledgment 0.64\nIntroduction 0.68\nConclusion 0.90\nReferences 1.0\n \nTable 2 \nMetadata extraction recall over 40 theses and related documents\n Recall\nTitle 0.75\nTable of Contents 0.81\nPreface 1.0\nAbstract 0.92\nAcknowledgment 0.90\nIntroduction 0.68\nConclusion 0.68\nReferences 0.91\n \nTable 3 \nMetadata extraction accuracy over 40 theses and related documents\n Accuracy\nTitle 0.75\nTable of Contents 0.68\nPreface 0.98\nAbstract 0.78\nAcknowledgment 0.70\nIntroduction 0.60\nConclusion 0.70\nReferences 0.93\n \nTable 4 \nMetadata extraction F-measure over 40 theses and related documents\n F-measure\nTitle 0.75\nTable of Contents 0.77\nPreface 0.92\nAbstract 0.84\nAcknowledgment 0.75\nIntroduction 0.68\nConclusion 0.77\nReferences 0.95\n Bolanle Adefowoke Ojokoh et al.\nJournal of Information Science, 35 (5) 2009, pp. 563\u2013570 \u00a9 CILIP, DOI: 10.1177/0165551509105195 569From the results, \u2018References\u2019 was extracted with the highest precision. Its extraction is also rela-\ntively high compared to others in terms of recall, accuracy and F-measure. This could be largely due \nto the fact that they appear, in most cases, at the end of the document.\nMost of the \u2018Preface\u2019 extraction cases fall under the not existing and not extracted cases because \nvery few of the documents (only six) contained a preface. As a result, recall and accuracy were high-\nest for \u2018Preface\u2019.\n\u2018Introduction\u2019 was extracted generally with the least values in terms of the evaluation criteria \n(0.68 for precision, recall and F-measure and 0.60 for accuracy). \u2018Conclusion\u2019 extraction was low too \nin terms of accuracy, although relatively high in precision (0.90). Reasons for these could be attrib-uted to the fact that in many cases introductions and conclusions exist in some theses (sometimes in every chapter), and sometimes too, other keywords that might not be recognized by the system are attached to them. In addition, some patterns not embedded in the rule-based system might be encountered leading to incorrect extraction.\n\u2018Abstract\u2019 extraction was performed with relatively high recall and F-measure. The precision and \naccuracy of its extraction was mostly affected negatively because in a few theses, the abstract part was not specifically labelled \u2018Abstract\u2019 or was not labelled at all.\n\u2018Table of Contents\u2019 was extracted with relatively high recall, but with fair precision and F-measure. \nThe accuracy with which it was extracted was a bit low, because in some cases, the system extracted some other parts, which were not actually part of the table of contents, with it.\n\u2018Title\u2019 extraction was particularly challenging as a result of the fact that titles of documents are \nnot usually labelled as such. Nevertheless, the task was done with consistent precision, recall, accu-racy and F-measure showing the effectiveness of the rule-based system. During the evaluation, it \nwas also discovered that, for most of the wrongly extracted cases for titles, the information extracted was still relevant, for instance when the authors\u2019 names or institution of study were extracted.\nSome of the studies with presented results include the work of Hu et al. [10] who extracted title \nfrom Word documents with precision and recall of 0.810 and 0.837, respectively, and precision and recall of 0.875 and 0.895 from PowerPoint documents, respectively in an experiment on intranet data using machine learning technique.\nSome systems whose work could be fairly compared to this system include that of Berkowitz and \nElkhadiri [17] who extracted authors and titles from documents; they reported recall of 25.96% for exact extraction of author names; for 24.99% of the papers they managed to extract either part of the author name(s), or the name(s) plus extra text. All these focused on extraction of a single metadata. Giuffrida and colleagues [14] extracted title, author, affiliation, author-to-affiliation mapping and table of contents from Postscript files using a knowledge-based approach obtaining 92%, 87%, 75%, 71% and 76% accuracy respectively. Hence, the methods proposed by this research for general documents metadata extraction with particular emphasis on theses can handle the task with rela-tively high efficiency. Compared to existing systems, it extracts more metadata, and with relatively comparable effectiveness.\n5. Conclusions and further research directions\nThis paper describes a method for general metadata extraction from general documents using a combination of the segmentation by keyword algorithm and regular expressions. Extraction of title is done using a different set of rules, implemented before segmentation by keyword is carried out because title extraction is often not affected by keywords. The rules used for title extraction proved consistently effective for theses and dissertations. The proposed model for extracting other metadata was tested on some randomly downloaded theses and related documents and used to extract Abstract, Preface, Table of Contents, Introduction, Conclusion, References and Acknowledgments. The experimental results show that the extraction was done with a relatively high degree of precision, recall and accuracy except for \u2018Introduction\u2019 and \u2018Conclusion\u2019 with low recall because of the usual existence of multiples of them in theses documents. Compared to existing systems, this system ",
      "nodes": [
        {
          "title": "Algorithm and System Implementation",
          "start_index": 5,
          "end_index": 5,
          "text": "Bolanle Adefowoke Ojokoh et al.\nJournal of Information Science, 35 (5) 2009, pp. 563\u2013570 \u00a9 CILIP, DOI: 10.1177/0165551509105195 567\u2022 Algorithm 3: Extracting document metadata.\nLocate the keywords associated with metadata.\nLocate the block of document corresponding to the keyword(s) identified.Extract keyword found in the document alongside the block of document.\u2022 Algorithm 4: Displaying and storing result of extraction.\nDisplay metadata and extracted block of document in the browser window.Store the extracted metadata and block in the database.\nThe keywords used in the grouping include: Table of Contents, Abstract, Preface, Chapter 1(One), \nIntroduction, Conclusion, References, Bibliography, Citation and Appendix (A/1). They were used with their respective regular expressions used to match them.\n4. System implementation and evaluation\nThe document metadata extractor receives an uploaded document and converts it to text. On click-ing on any of the metadata listed on the left side of the browser window as hyperlinks, the extractor scans through the document and displays the corresponding content of the document. \nThe document metadata extractor was tested over a set of randomly selected theses, dissertations \nand a few technical reports downloaded from the web. Theses were, however, the main focus of the experiments (about 80% of the sample).\nThe evaluation of the system was done using the following criteria: recall, precision, accuracy, \nand F-measure [as defined in equations (14)\u2013(17)].\nAn exact performance comparison may not be possible, because of differences in the documents \nused for testing the different systems [16]. However, attempts are made to refer to related work and how the results compare with theirs. The results of the experimental evaluation of the reference metadata extractor are presented as follows.\n \nPrecision =A\nA+C (14)\n Recall =A\nA+B (15)\n Accuracy =A+D\nA+B+C+D (16)\n F/C0measur e=2/C3Precision /C3Recall\nPrecis ion+Recall (17)\nwhere A is the number of correctly extracted fields, B is the number of fields with existing, but not \nextracted data, C is the number of fields with wrongly extracted data, while D is the number of fields \nwith not existing and not extracted data.\nThe test for automatic extraction correctness was based on a manual verification of the correct-\nness of the extracted metadata against the original document. Due to such manual verification, which was lengthy and tedious, the sample size was limited to 40 documents.\nTables 1\u20134 summarize the overall precision, recall, accuracy and F-measure results respectively.",
          "summary": "This section details the algorithms used for metadata extraction and storage, and describes the implementation of the document metadata extractor system. It also outlines the evaluation criteria and the manual verification process.",
          "node_type": "semantic_unit",
          "metadata": {
            "semantic_type": "procedure",
            "start_paragraph": 0,
            "end_paragraph": 0,
            "original_title": "Algorithm and System Implementation"
          },
          "nodes": [],
          "node_id": "0013"
        },
        {
          "title": "Experimental Evaluation Results",
          "start_index": 6,
          "end_index": 6,
          "text": "Bolanle Adefowoke Ojokoh et al.\nJournal of Information Science, 35 (5) 2009, pp. 563\u2013570 \u00a9 CILIP, DOI: 10.1177/0165551509105195 568Table 1 \nMetadata extraction precision over 40 theses and related documents\n Precision\nTitle 0.75\nTable of Contents 0.73\nPreface 0.86\nAbstract 0.77\nAcknowledgment 0.64\nIntroduction 0.68\nConclusion 0.90\nReferences 1.0\n \nTable 2 \nMetadata extraction recall over 40 theses and related documents\n Recall\nTitle 0.75\nTable of Contents 0.81\nPreface 1.0\nAbstract 0.92\nAcknowledgment 0.90\nIntroduction 0.68\nConclusion 0.68\nReferences 0.91\n \nTable 3 \nMetadata extraction accuracy over 40 theses and related documents\n Accuracy\nTitle 0.75\nTable of Contents 0.68\nPreface 0.98\nAbstract 0.78\nAcknowledgment 0.70\nIntroduction 0.60\nConclusion 0.70\nReferences 0.93\n \nTable 4 \nMetadata extraction F-measure over 40 theses and related documents\n F-measure\nTitle 0.75\nTable of Contents 0.77\nPreface 0.92\nAbstract 0.84\nAcknowledgment 0.75\nIntroduction 0.68\nConclusion 0.77\nReferences 0.95",
          "summary": "Presents the results of the metadata extraction experiment, including precision, recall, accuracy, and F-measure for various metadata fields over 40 documents, summarized in Tables 1-4.",
          "node_type": "semantic_unit",
          "metadata": {
            "semantic_type": "analysis",
            "start_paragraph": 1,
            "end_paragraph": 1,
            "original_title": "Experimental Evaluation Results"
          },
          "nodes": [
            {
              "title": "Table 1: Metadata extraction precision over 40 theses and r...",
              "start_index": 6,
              "end_index": 6,
              "text": "Metadata extraction precision over 40 theses and related documents\n\nBolanle Adefowoke Ojokoh et al.\nJournal of Information Science, 35 (5) 2009, pp. 563\u2013570 \u00a9 CILIP, DOI: 10.1177/0165551509105195 567\u2022 Algorithm 3: Extracting document metadata.\nLocate the keywords associated with metadata.\nLocate the block of document corresponding to the keyword(s) identified.Extract keyword found in the document alongside the block of document.\u2022 Algorithm 4: Displaying and storing result of extraction.\nDisplay metadata and extracted block of document in the browser window.Store the extracted metadata and block in the database.\nThe keywords used in the grouping include: Table of Contents, Abstract, Preface, Chapter 1(One), \nIntroduction, Conclusion, References, Bibliography, Citation and Appendix (A/1). They were used with their respective regular expressions used to match them.\n4. System implementation and evaluation\nThe document metadata extractor receives an uploaded document and converts it to text. On click-ing on any of the metadata listed on the left side of the browser window as hyperlinks, the extractor scans through the document and displays the corresponding content of the document. \nThe document metadata extractor was tested over a set of randomly selected theses, dissertations \nand a few technical reports downloaded from the web. Theses were, however, the main focus of the experiments (about 80% of the sample).\nThe evaluation of the system was done using the following criteria: recall, precision, accuracy, \nand F-measure [as defined in equations (14)\u2013(17)].\nAn exact performance comparison may not be possible, because of differences in the documents \nused for testing the different systems [16]. However, attempts are made to refer to related work and how the results compare with theirs. The results of the experimental evaluation of the reference metadata extractor are presented as follows.\n \nPrecision =A\nA+C (14)\n Recall =A\nA+B (15)\n Accuracy =A+D\nA+B+C+D (16)\n F/C0measur e=2/C3Precision /C3Recall\nPrecis ion+Recall (17)\nwhere A is the num...",
              "summary": "Table 1 presents the precision of metadata extraction for 40 theses and related documents. The data indicates high precision in extracting metadata, with specific keywords and regular expressions proving effective. This demonstrates the successful implementation of the proposed algorithms for metadata extraction and storage, contributing to the research's objective of efficient document analysis.",
              "node_type": "table",
              "metadata": {
                "table_number": "Table 1",
                "caption": "Metadata extraction precision over 40 theses and related documents",
                "headers": [],
                "key_values": {},
                "bbox": {
                  "x_min": 293.0,
                  "y_min": 125.0,
                  "x_max": 710.0,
                  "y_max": 291.0
                }
              },
              "nodes": [],
              "node_id": "0015"
            },
            {
              "title": "Table 2: Metadata extraction recall over 40 theses and rela...",
              "start_index": 6,
              "end_index": 6,
              "text": "Metadata extraction recall over 40 theses and related documents\n\nBolanle Adefowoke Ojokoh et al.\nJournal of Information Science, 35 (5) 2009, pp. 563\u2013570 \u00a9 CILIP, DOI: 10.1177/0165551509105195 567\u2022 Algorithm 3: Extracting document metadata.\nLocate the keywords associated with metadata.\nLocate the block of document corresponding to the keyword(s) identified.Extract keyword found in the document alongside the block of document.\u2022 Algorithm 4: Displaying and storing result of extraction.\nDisplay metadata and extracted block of document in the browser window.Store the extracted metadata and block in the database.\nThe keywords used in the grouping include: Table of Contents, Abstract, Preface, Chapter 1(One), \nIntroduction, Conclusion, References, Bibliography, Citation and Appendix (A/1). They were used with their respective regular expressions used to match them.\n4. System implementation and evaluation\nThe document metadata extractor receives an uploaded document and converts it to text. On click-ing on any of the metadata listed on the left side of the browser window as hyperlinks, the extractor scans through the document and displays the corresponding content of the document. \nThe document metadata extractor was tested over a set of randomly selected theses, dissertations \nand a few technical reports downloaded from the web. Theses were, however, the main focus of the experiments (about 80% of the sample).\nThe evaluation of the system was done using the following criteria: recall, precision, accuracy, \nand F-measure [as defined in equations (14)\u2013(17)].\nAn exact performance comparison may not be possible, because of differences in the documents \nused for testing the different systems [16]. However, attempts are made to refer to related work and how the results compare with theirs. The results of the experimental evaluation of the reference metadata extractor are presented as follows.\n \nPrecision =A\nA+C (14)\n Recall =A\nA+B (15)\n Accuracy =A+D\nA+B+C+D (16)\n F/C0measur e=2/C3Precision /C3Recall\nPrecis ion+Recall (17)\nwhere A is the num...",
              "summary": "Table 2 presents the metadata extraction recall for 40 theses and related documents. The data indicates a high recall rate for metadata extraction, suggesting the effectiveness of the proposed algorithms. This finding is relevant to the research as it demonstrates the successful implementation of a system for automatically extracting and storing document metadata.",
              "node_type": "table",
              "metadata": {
                "table_number": "Table 2",
                "caption": "Metadata extraction recall over 40 theses and related documents",
                "headers": [],
                "key_values": {},
                "bbox": {
                  "x_min": 293.0,
                  "y_min": 327.0,
                  "x_max": 710.0,
                  "y_max": 493.0
                }
              },
              "nodes": [],
              "node_id": "0016"
            },
            {
              "title": "Table 3: Metadata extraction accuracy over 40 theses and re...",
              "start_index": 6,
              "end_index": 6,
              "text": "Metadata extraction accuracy over 40 theses and related documents\n\nBolanle Adefowoke Ojokoh et al.\nJournal of Information Science, 35 (5) 2009, pp. 563\u2013570 \u00a9 CILIP, DOI: 10.1177/0165551509105195 567\u2022 Algorithm 3: Extracting document metadata.\nLocate the keywords associated with metadata.\nLocate the block of document corresponding to the keyword(s) identified.Extract keyword found in the document alongside the block of document.\u2022 Algorithm 4: Displaying and storing result of extraction.\nDisplay metadata and extracted block of document in the browser window.Store the extracted metadata and block in the database.\nThe keywords used in the grouping include: Table of Contents, Abstract, Preface, Chapter 1(One), \nIntroduction, Conclusion, References, Bibliography, Citation and Appendix (A/1). They were used with their respective regular expressions used to match them.\n4. System implementation and evaluation\nThe document metadata extractor receives an uploaded document and converts it to text. On click-ing on any of the metadata listed on the left side of the browser window as hyperlinks, the extractor scans through the document and displays the corresponding content of the document. \nThe document metadata extractor was tested over a set of randomly selected theses, dissertations \nand a few technical reports downloaded from the web. Theses were, however, the main focus of the experiments (about 80% of the sample).\nThe evaluation of the system was done using the following criteria: recall, precision, accuracy, \nand F-measure [as defined in equations (14)\u2013(17)].\nAn exact performance comparison may not be possible, because of differences in the documents \nused for testing the different systems [16]. However, attempts are made to refer to related work and how the results compare with theirs. The results of the experimental evaluation of the reference metadata extractor are presented as follows.\n \nPrecision =A\nA+C (14)\n Recall =A\nA+B (15)\n Accuracy =A+D\nA+B+C+D (16)\n F/C0measur e=2/C3Precision /C3Recall\nPrecis ion+Recall (17)\nwhere A is the num...",
              "summary": "Table 3 presents the accuracy of metadata extraction from 40 theses and related documents. The research achieved high accuracy in extracting metadata, demonstrating the effectiveness of the proposed algorithms. This accuracy is crucial for organizing and retrieving information from academic documents.",
              "node_type": "table",
              "metadata": {
                "table_number": "Table 3",
                "caption": "Metadata extraction accuracy over 40 theses and related documents",
                "headers": [],
                "key_values": {},
                "bbox": {
                  "x_min": 293.0,
                  "y_min": 529.0,
                  "x_max": 710.0,
                  "y_max": 695.0
                }
              },
              "nodes": [],
              "node_id": "0017"
            },
            {
              "title": "Table 4: Metadata extraction F-measure over 40 theses and r...",
              "start_index": 6,
              "end_index": 6,
              "text": "Metadata extraction F-measure over 40 theses and related documents\n\nBolanle Adefowoke Ojokoh et al.\nJournal of Information Science, 35 (5) 2009, pp. 563\u2013570 \u00a9 CILIP, DOI: 10.1177/0165551509105195 567\u2022 Algorithm 3: Extracting document metadata.\nLocate the keywords associated with metadata.\nLocate the block of document corresponding to the keyword(s) identified.Extract keyword found in the document alongside the block of document.\u2022 Algorithm 4: Displaying and storing result of extraction.\nDisplay metadata and extracted block of document in the browser window.Store the extracted metadata and block in the database.\nThe keywords used in the grouping include: Table of Contents, Abstract, Preface, Chapter 1(One), \nIntroduction, Conclusion, References, Bibliography, Citation and Appendix (A/1). They were used with their respective regular expressions used to match them.\n4. System implementation and evaluation\nThe document metadata extractor receives an uploaded document and converts it to text. On click-ing on any of the metadata listed on the left side of the browser window as hyperlinks, the extractor scans through the document and displays the corresponding content of the document. \nThe document metadata extractor was tested over a set of randomly selected theses, dissertations \nand a few technical reports downloaded from the web. Theses were, however, the main focus of the experiments (about 80% of the sample).\nThe evaluation of the system was done using the following criteria: recall, precision, accuracy, \nand F-measure [as defined in equations (14)\u2013(17)].\nAn exact performance comparison may not be possible, because of differences in the documents \nused for testing the different systems [16]. However, attempts are made to refer to related work and how the results compare with theirs. The results of the experimental evaluation of the reference metadata extractor are presented as follows.\n \nPrecision =A\nA+C (14)\n Recall =A\nA+B (15)\n Accuracy =A+D\nA+B+C+D (16)\n F/C0measur e=2/C3Precision /C3Recall\nPrecis ion+Recall (17)\nwhere A is the num...",
              "summary": "Table 4 presents the F-measure for metadata extraction across 40 theses and related documents. The F-measure, a metric combining precision and recall, indicates the effectiveness of the metadata extraction algorithm. This data is crucial for evaluating the performance of the proposed algorithms in accurately identifying and extracting relevant metadata from academic documents.",
              "node_type": "table",
              "metadata": {
                "table_number": "Table 4",
                "caption": "Metadata extraction F-measure over 40 theses and related documents",
                "headers": [],
                "key_values": {},
                "bbox": {
                  "x_min": 293.0,
                  "y_min": 731.0,
                  "x_max": 710.0,
                  "y_max": 897.0
                }
              },
              "nodes": [],
              "node_id": "0018"
            }
          ],
          "node_id": "0014"
        },
        {
          "title": "Discussion of Results and Comparison with Related Work",
          "start_index": 7,
          "end_index": 7,
          "text": "Bolanle Adefowoke Ojokoh et al.\nJournal of Information Science, 35 (5) 2009, pp. 563\u2013570 \u00a9 CILIP, DOI: 10.1177/0165551509105195 569From the results, \u2018References\u2019 was extracted with the highest precision. Its extraction is also rela-\ntively high compared to others in terms of recall, accuracy and F-measure. This could be largely due \nto the fact that they appear, in most cases, at the end of the document.\nMost of the \u2018Preface\u2019 extraction cases fall under the not existing and not extracted cases because \nvery few of the documents (only six) contained a preface. As a result, recall and accuracy were high-\nest for \u2018Preface\u2019.\n\u2018Introduction\u2019 was extracted generally with the least values in terms of the evaluation criteria \n(0.68 for precision, recall and F-measure and 0.60 for accuracy). \u2018Conclusion\u2019 extraction was low too \nin terms of accuracy, although relatively high in precision (0.90). Reasons for these could be attrib-uted to the fact that in many cases introductions and conclusions exist in some theses (sometimes in every chapter), and sometimes too, other keywords that might not be recognized by the system are attached to them. In addition, some patterns not embedded in the rule-based system might be encountered leading to incorrect extraction.\n\u2018Abstract\u2019 extraction was performed with relatively high recall and F-measure. The precision and \naccuracy of its extraction was mostly affected negatively because in a few theses, the abstract part was not specifically labelled \u2018Abstract\u2019 or was not labelled at all.\n\u2018Table of Contents\u2019 was extracted with relatively high recall, but with fair precision and F-measure. \nThe accuracy with which it was extracted was a bit low, because in some cases, the system extracted some other parts, which were not actually part of the table of contents, with it.\n\u2018Title\u2019 extraction was particularly challenging as a result of the fact that titles of documents are \nnot usually labelled as such. Nevertheless, the task was done with consistent precision, recall, accu-racy and F-measure showing the effectiveness of the rule-based system. During the evaluation, it \nwas also discovered that, for most of the wrongly extracted cases for titles, the information extracted was still relevant, for instance when the authors\u2019 names or institution of study were extracted.\nSome of the studies with presented results include the work of Hu et al. [10] who extracted title \nfrom Word documents with precision and recall of 0.810 and 0.837, respectively, and precision and recall of 0.875 and 0.895 from PowerPoint documents, respectively in an experiment on intranet data using machine learning technique.\nSome systems whose work could be fairly compared to this system include that of Berkowitz and \nElkhadiri [17] who extracted authors and titles from documents; they reported recall of 25.96% for exact extraction of author names; for 24.99% of the papers they managed to extract either part of the author name(s), or the name(s) plus extra text. All these focused on extraction of a single metadata. Giuffrida and colleagues [14] extracted title, author, affiliation, author-to-affiliation mapping and table of contents from Postscript files using a knowledge-based approach obtaining 92%, 87%, 75%, 71% and 76% accuracy respectively. Hence, the methods proposed by this research for general documents metadata extraction with particular emphasis on theses can handle the task with rela-tively high efficiency. Compared to existing systems, it extracts more metadata, and with relatively comparable effectiveness.\n5. Conclusions and further research directions\nThis paper describes a method for general metadata extraction from general documents using a combination of the segmentation by keyword algorithm and regular expressions. Extraction of title is done using a different set of rules, implemented before segmentation by keyword is carried out because title extraction is often not affected by keywords. The rules used for title extraction proved consistently effective for theses and dissertations. The proposed model for extracting other metadata was tested on some randomly downloaded theses and related documents and used to extract Abstract, Preface, Table of Contents, Introduction, Conclusion, References and Acknowledgments. The experimental results show that the extraction was done with a relatively high degree of precision, recall and accuracy except for \u2018Introduction\u2019 and \u2018Conclusion\u2019 with low recall because of the usual existence of multiples of them in theses documents. Compared to existing systems, this system",
          "summary": "Analyzes the performance of the metadata extraction for different fields, explaining reasons for high or low scores, and compares the system's effectiveness with previously published related work.",
          "node_type": "semantic_unit",
          "metadata": {
            "semantic_type": "analysis",
            "start_paragraph": 2,
            "end_paragraph": 2,
            "original_title": "Discussion of Results and Comparison with Related Work"
          },
          "nodes": [],
          "node_id": "0019"
        }
      ],
      "node_id": "0012",
      "summary": "This section details the implementation of a document metadata extraction system, including the algorithms and evaluation methodology. It then presents and discusses the experimental results of this system's performance, comparing its effectiveness against related prior work."
    },
    {
      "title": "Conclusions and further research directions",
      "start_index": 7,
      "end_index": 8,
      "text": "Bolanle Adefowoke Ojokoh et al.\nJournal of Information Science, 35 (5) 2009, pp. 563\u2013570 \u00a9 CILIP, DOI: 10.1177/0165551509105195 569From the results, \u2018References\u2019 was extracted with the highest precision. Its extraction is also rela-\ntively high compared to others in terms of recall, accuracy and F-measure. This could be largely due \nto the fact that they appear, in most cases, at the end of the document.\nMost of the \u2018Preface\u2019 extraction cases fall under the not existing and not extracted cases because \nvery few of the documents (only six) contained a preface. As a result, recall and accuracy were high-\nest for \u2018Preface\u2019.\n\u2018Introduction\u2019 was extracted generally with the least values in terms of the evaluation criteria \n(0.68 for precision, recall and F-measure and 0.60 for accuracy). \u2018Conclusion\u2019 extraction was low too \nin terms of accuracy, although relatively high in precision (0.90). Reasons for these could be attrib-uted to the fact that in many cases introductions and conclusions exist in some theses (sometimes in every chapter), and sometimes too, other keywords that might not be recognized by the system are attached to them. In addition, some patterns not embedded in the rule-based system might be encountered leading to incorrect extraction.\n\u2018Abstract\u2019 extraction was performed with relatively high recall and F-measure. The precision and \naccuracy of its extraction was mostly affected negatively because in a few theses, the abstract part was not specifically labelled \u2018Abstract\u2019 or was not labelled at all.\n\u2018Table of Contents\u2019 was extracted with relatively high recall, but with fair precision and F-measure. \nThe accuracy with which it was extracted was a bit low, because in some cases, the system extracted some other parts, which were not actually part of the table of contents, with it.\n\u2018Title\u2019 extraction was particularly challenging as a result of the fact that titles of documents are \nnot usually labelled as such. Nevertheless, the task was done with consistent precision, recall, accu-racy and F-measure showing the effectiveness of the rule-based system. During the evaluation, it \nwas also discovered that, for most of the wrongly extracted cases for titles, the information extracted was still relevant, for instance when the authors\u2019 names or institution of study were extracted.\nSome of the studies with presented results include the work of Hu et al. [10] who extracted title \nfrom Word documents with precision and recall of 0.810 and 0.837, respectively, and precision and recall of 0.875 and 0.895 from PowerPoint documents, respectively in an experiment on intranet data using machine learning technique.\nSome systems whose work could be fairly compared to this system include that of Berkowitz and \nElkhadiri [17] who extracted authors and titles from documents; they reported recall of 25.96% for exact extraction of author names; for 24.99% of the papers they managed to extract either part of the author name(s), or the name(s) plus extra text. All these focused on extraction of a single metadata. Giuffrida and colleagues [14] extracted title, author, affiliation, author-to-affiliation mapping and table of contents from Postscript files using a knowledge-based approach obtaining 92%, 87%, 75%, 71% and 76% accuracy respectively. Hence, the methods proposed by this research for general documents metadata extraction with particular emphasis on theses can handle the task with rela-tively high efficiency. Compared to existing systems, it extracts more metadata, and with relatively comparable effectiveness.\n5. Conclusions and further research directions\nThis paper describes a method for general metadata extraction from general documents using a combination of the segmentation by keyword algorithm and regular expressions. Extraction of title is done using a different set of rules, implemented before segmentation by keyword is carried out because title extraction is often not affected by keywords. The rules used for title extraction proved consistently effective for theses and dissertations. The proposed model for extracting other metadata was tested on some randomly downloaded theses and related documents and used to extract Abstract, Preface, Table of Contents, Introduction, Conclusion, References and Acknowledgments. The experimental results show that the extraction was done with a relatively high degree of precision, recall and accuracy except for \u2018Introduction\u2019 and \u2018Conclusion\u2019 with low recall because of the usual existence of multiples of them in theses documents. Compared to existing systems, this system Bolanle Adefowoke Ojokoh et al.\nJournal of Information Science, 35 (5) 2009, pp. 563\u2013570 \u00a9 CILIP, DOI: 10.1177/0165551509105195 570extracts more metadata, and with relatively comparable effectiveness. However, since it is rule \nbased, it needs refinement over time as more keywords are discovered and metadata extraction is to be done for some different types of documents. \nReferences\n [1] K.M. Summers, Automatic discovery of logical document structure (PhD dissertation, Cornell University, \nIthaca, NY, 1998).\n [2] A. Arasu and H. Garcia-Molina, Extracting structured data from web pages, Proceedings of the 2003 ACM \nSIGMOD International Conference on Management of Data (SIGMOD) (June 2003) 337\u2013348.\n [3] A. Crystal and P. Land, Metadata and search, Global Corporate Circle DCMI 2003 Workshop (2003). \nAvailable from http://dublincore.org/groups/corporate/Seattle/\n [4] H. Han, C.L. Giles, E. Manavoglu, H. Zha, Z. Zhang and E.A. Fox, Automatic document metadata extraction \nusing support vector machine, Joint Conference on Digital Libraries (JCDL\u201903)  (Houston, Texas USA, 2003).\n [5] B.A. Ojokoh, S.O. Falaki and O.S. Adewale, Automated information extraction system for heterogeneous \ndigital library documents, Proceedings of the ACM/IEEE Joint Conference on Digital Libraries (JCDL 2007) \nDoctoral Consortium (Vancouver, British Columbia, Canada, June 18\u201323, 2007).\n [6] A. Kawtrakul and C. Yingsaeree, A Unified Framework for Automatic Metadata Extraction from Electronic \nDocument (2004). Available at: http://iadlc.nul.nagoya-u.ac.jp/archives/IADLC2005/kawrtrakul.pdf\n [7] E.D. Liddy, S. Sutton, E. Allen, S. Harwell, S. Corieri and O. Yilmazel, Automatic metadata generation and evaluation, Proceedings of the 25th Annual International ACM SIGIR Conference on Research and \nDevelopment in Information Retrieval (Tampere, Finland, 2002) 401\u2013402.\n [8] O. Yilmazel, C.M. Finneran and E.D. Liddy, MetaExtract: an NLP system to automatically assign metadata, Proceedings of the 2004 Joint ACM/IEEE Conference on Digital Libraries  (Tuscan, AZ, USA, 2004) 241\u2013242.\n [9] S. Mao, J.W. Kim and G.R. Thoma, A dynamic feature generation system for automated metadata extrac-tion in preservation of digital materials, Proceedings of the First International Workshop on Document \nImage Analysis for Libraries (Palo Alto, CA, USA, 2004) 225\u2013232.\n[10] Y. Hu, H. Li, Y. Cao, T. Teng, D. Meyerzon and Q. Zheng, Automatic extraction of titles from general documents, Information Processing and Management 42 (2006) 1276\u20131293.\n[11]  F. Peng and A. McCallum, Accurate information extraction from research papers using conditional ran-dom fields, Proceedings of the Human Language Technology Conference/North American Chapter of the \nAssociation for Computational Linguistics Annual Meeting (New York, NY, USA, 2004) 329\u2013336.\n[12] B.A. Ojokoh, O.S. Adewale and S.O. Falaki, Improving on the smoothing technique for obtaining emis-sion probabilities in hidden Markov models, Oriental Journal of Computer Science and Technology 1(1) \n(2008) 15\u201324.\n[13] K. Seymore, A. McCallum and R. Rosenfeld, Learning hidden Markov model structure for information \nextraction. In: AAAI Workshop on Machine Learning for Information Extraction (1999).\n[14] G. Giuffrida, E.C Shek and J. Yang, Knowledge-based metadata extraction from postscript files, ACM \nDigital Libraries (2000) 77\u201384. \n[15] K. Nakagawa, A. Nomura and M. Suzuki, Extraction of Logical Structure from Articles in Mathematics \n(Springer, Berlin, 2004).\n[16] M. Kr\u00e4mer, H. Kaprykowsky, D. Keysers and T. Breuel, Bibliographic metadata extraction using probabi-\nlistic finite state transducers, Ninth International Conference on Document Analysis and Recognition \n(2007) 609\u2013613.\n[17] E.G. Berkowitz and M.R. Elkhadiri, Creation of a Style Independent Intelligent Autonomous Citation \nIndexer to Support Academic Research (MAICS 2004) 68\u201373.",
      "node_id": "0020",
      "summary": "This partial document discusses the extraction performance of different document sections, including 'References', 'Preface', 'Introduction', 'Conclusion', 'Abstract', 'Table of Contents', and 'Title'. It analyzes the precision, recall, accuracy, and F-measure for each section, attributing variations in performance to factors like section placement, presence in documents, labeling conventions, and the complexity of the rule-based system. The document also briefly mentions comparative studies by Hu et al. and Berkowitz and Elkhadiri."
    },
    {
      "title": "References",
      "start_index": 8,
      "end_index": 8,
      "text": "Bolanle Adefowoke Ojokoh et al.\nJournal of Information Science, 35 (5) 2009, pp. 563\u2013570 \u00a9 CILIP, DOI: 10.1177/0165551509105195 570extracts more metadata, and with relatively comparable effectiveness. However, since it is rule \nbased, it needs refinement over time as more keywords are discovered and metadata extraction is to be done for some different types of documents. \nReferences\n [1] K.M. Summers, Automatic discovery of logical document structure (PhD dissertation, Cornell University, \nIthaca, NY, 1998).\n [2] A. Arasu and H. Garcia-Molina, Extracting structured data from web pages, Proceedings of the 2003 ACM \nSIGMOD International Conference on Management of Data (SIGMOD) (June 2003) 337\u2013348.\n [3] A. Crystal and P. Land, Metadata and search, Global Corporate Circle DCMI 2003 Workshop (2003). \nAvailable from http://dublincore.org/groups/corporate/Seattle/\n [4] H. Han, C.L. Giles, E. Manavoglu, H. Zha, Z. Zhang and E.A. Fox, Automatic document metadata extraction \nusing support vector machine, Joint Conference on Digital Libraries (JCDL\u201903)  (Houston, Texas USA, 2003).\n [5] B.A. Ojokoh, S.O. Falaki and O.S. Adewale, Automated information extraction system for heterogeneous \ndigital library documents, Proceedings of the ACM/IEEE Joint Conference on Digital Libraries (JCDL 2007) \nDoctoral Consortium (Vancouver, British Columbia, Canada, June 18\u201323, 2007).\n [6] A. Kawtrakul and C. Yingsaeree, A Unified Framework for Automatic Metadata Extraction from Electronic \nDocument (2004). Available at: http://iadlc.nul.nagoya-u.ac.jp/archives/IADLC2005/kawrtrakul.pdf\n [7] E.D. Liddy, S. Sutton, E. Allen, S. Harwell, S. Corieri and O. Yilmazel, Automatic metadata generation and evaluation, Proceedings of the 25th Annual International ACM SIGIR Conference on Research and \nDevelopment in Information Retrieval (Tampere, Finland, 2002) 401\u2013402.\n [8] O. Yilmazel, C.M. Finneran and E.D. Liddy, MetaExtract: an NLP system to automatically assign metadata, Proceedings of the 2004 Joint ACM/IEEE Conference on Digital Libraries  (Tuscan, AZ, USA, 2004) 241\u2013242.\n [9] S. Mao, J.W. Kim and G.R. Thoma, A dynamic feature generation system for automated metadata extrac-tion in preservation of digital materials, Proceedings of the First International Workshop on Document \nImage Analysis for Libraries (Palo Alto, CA, USA, 2004) 225\u2013232.\n[10] Y. Hu, H. Li, Y. Cao, T. Teng, D. Meyerzon and Q. Zheng, Automatic extraction of titles from general documents, Information Processing and Management 42 (2006) 1276\u20131293.\n[11]  F. Peng and A. McCallum, Accurate information extraction from research papers using conditional ran-dom fields, Proceedings of the Human Language Technology Conference/North American Chapter of the \nAssociation for Computational Linguistics Annual Meeting (New York, NY, USA, 2004) 329\u2013336.\n[12] B.A. Ojokoh, O.S. Adewale and S.O. Falaki, Improving on the smoothing technique for obtaining emis-sion probabilities in hidden Markov models, Oriental Journal of Computer Science and Technology 1(1) \n(2008) 15\u201324.\n[13] K. Seymore, A. McCallum and R. Rosenfeld, Learning hidden Markov model structure for information \nextraction. In: AAAI Workshop on Machine Learning for Information Extraction (1999).\n[14] G. Giuffrida, E.C Shek and J. Yang, Knowledge-based metadata extraction from postscript files, ACM \nDigital Libraries (2000) 77\u201384. \n[15] K. Nakagawa, A. Nomura and M. Suzuki, Extraction of Logical Structure from Articles in Mathematics \n(Springer, Berlin, 2004).\n[16] M. Kr\u00e4mer, H. Kaprykowsky, D. Keysers and T. Breuel, Bibliographic metadata extraction using probabi-\nlistic finite state transducers, Ninth International Conference on Document Analysis and Recognition \n(2007) 609\u2013613.\n[17] E.G. Berkowitz and M.R. Elkhadiri, Creation of a Style Independent Intelligent Autonomous Citation \nIndexer to Support Academic Research (MAICS 2004) 68\u201373.",
      "nodes": [
        {
          "title": "Authors and Publication Details",
          "start_index": 8,
          "end_index": 8,
          "text": "Bolanle Adefowoke Ojokoh et al.\n\nJournal of Information Science, 35 (5) 2009, pp. 563\u2013570 \u00a9 CILIP, DOI: 10.1177/0165551509105195 570extracts more metadata, and with relatively comparable effectiveness. However, since it is rule\n\nbased, it needs refinement over time as more keywords are discovered and metadata extraction is to be done for some different types of documents.",
          "summary": "This unit identifies the authors of the work, the journal it was published in, and provides a brief note on the metadata extraction method discussed.",
          "node_type": "semantic_unit",
          "metadata": {
            "semantic_type": "metadata",
            "start_paragraph": 0,
            "end_paragraph": 2,
            "original_title": "Authors and Publication Details"
          },
          "nodes": [],
          "node_id": "0022"
        },
        {
          "title": "References",
          "start_index": 8,
          "end_index": 8,
          "text": "References\n\n[1] K.M. Summers, Automatic discovery of logical document structure (PhD dissertation, Cornell University,\n\nIthaca, NY, 1998).\n\n[2] A. Arasu and H. Garcia-Molina, Extracting structured data from web pages, Proceedings of the 2003 ACM\n\nSIGMOD International Conference on Management of Data (SIGMOD) (June 2003) 337\u2013348.\n\n[3] A. Crystal and P. Land, Metadata and search, Global Corporate Circle DCMI 2003 Workshop (2003).\n\nAvailable from http://dublincore.org/groups/corporate/Seattle/\n\n[4] H. Han, C.L. Giles, E. Manavoglu, H. Zha, Z. Zhang and E.A. Fox, Automatic document metadata extraction\n\nusing support vector machine, Joint Conference on Digital Libraries (JCDL\u201903)  (Houston, Texas USA, 2003).\n\n[5] B.A. Ojokoh, S.O. Falaki and O.S. Adewale, Automated information extraction system for heterogeneous\n\ndigital library documents, Proceedings of the ACM/IEEE Joint Conference on Digital Libraries (JCDL 2007)\n\nDoctoral Consortium (Vancouver, British Columbia, Canada, June 18\u201323, 2007).\n\n[6] A. Kawtrakul and C. Yingsaeree, A Unified Framework for Automatic Metadata Extraction from Electronic\n\nDocument (2004). Available at: http://iadlc.nul.nagoya-u.ac.jp/archives/IADLC2005/kawrtrakul.pdf\n\n[7] E.D. Liddy, S. Sutton, E. Allen, S. Harwell, S. Corieri and O. Yilmazel, Automatic metadata generation and evaluation, Proceedings of the 25th Annual International ACM SIGIR Conference on Research and\n\nDevelopment in Information Retrieval (Tampere, Finland, 2002) 401\u2013402.\n\n[8] O. Yilmazel, C.M. Finneran and E.D. Liddy, MetaExtract: an NLP system to automatically assign metadata, Proceedings of the 2004 Joint ACM/IEEE Conference on Digital Libraries  (Tuscan, AZ, USA, 2004) 241\u2013242.\n\n[9] S. Mao, J.W. Kim and G.R. Thoma, A dynamic feature generation system for automated metadata extrac-tion in preservation of digital materials, Proceedings of the First International Workshop on Document\n\nImage Analysis for Libraries (Palo Alto, CA, USA, 2004) 225\u2013232.\n\n[10] Y. Hu, H. Li, Y. Cao, T. Teng, D. Meyerzon and Q. Zheng, Automatic extraction of titles from general documents, Information Processing and Management 42 (2006) 1276\u20131293.\n\n[11]  F. Peng and A. McCallum, Accurate information extraction from research papers using conditional ran-dom fields, Proceedings of the Human Language Technology Conference/North American Chapter of the\n\nAssociation for Computational Linguistics Annual Meeting (New York, NY, USA, 2004) 329\u2013336.\n\n[12] B.A. Ojokoh, O.S. Adewale and S.O. Falaki, Improving on the smoothing technique for obtaining emis-sion probabilities in hidden Markov models, Oriental Journal of Computer Science and Technology 1(1)\n\n(2008) 15\u201324.\n\n[13] K. Seymore, A. McCallum and R. Rosenfeld, Learning hidden Markov model structure for information\n\nextraction. In: AAAI Workshop on Machine Learning for Information Extraction (1999).\n\n[14] G. Giuffrida, E.C Shek and J. Yang, Knowledge-based metadata extraction from postscript files, ACM\n\nDigital Libraries (2000) 77\u201384.\n\n[15] K. Nakagawa, A. Nomura and M. Suzuki, Extraction of Logical Structure from Articles in Mathematics\n\n(Springer, Berlin, 2004).\n\n[16] M. Kr\u00e4mer, H. Kaprykowsky, D. Keysers and T. Breuel, Bibliographic metadata extraction using probabi-\n\nlistic finite state transducers, Ninth International Conference on Document Analysis and Recognition\n\n(2007) 609\u2013613.\n\n[17] E.G. Berkowitz and M.R. Elkhadiri, Creation of a Style Independent Intelligent Autonomous Citation\n\nIndexer to Support Academic Research (MAICS 2004) 68\u201373.",
          "summary": "This section contains a list of references cited in the document, including authors, titles, publication venues, and dates.",
          "node_type": "semantic_unit",
          "metadata": {
            "semantic_type": "references",
            "start_paragraph": 3,
            "end_paragraph": 37,
            "original_title": "References"
          },
          "nodes": [],
          "node_id": "0023"
        }
      ],
      "node_id": "0021",
      "summary": "This section details the bibliographic information of the cited works, including author and publication specifics. It also outlines the methodology used for extracting metadata from these references."
    }
  ]
}