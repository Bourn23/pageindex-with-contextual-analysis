<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Document - Structure Visualization</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }
        
        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif;
            background: #f5f5f5;
            color: #333;
        }
        
        .header {
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            padding: 2rem;
            box-shadow: 0 2px 10px rgba(0,0,0,0.1);
        }
        
        .header h1 {
            font-size: 1.8rem;
            margin-bottom: 0.5rem;
        }
        
        .header .subtitle {
            opacity: 0.9;
            font-size: 0.9rem;
        }
        
        .container {
            display: flex;
            height: calc(100vh - 120px);
        }
        
        .sidebar {
            width: 350px;
            background: white;
            border-right: 1px solid #e0e0e0;
            overflow-y: auto;
            padding: 1rem;
        }
        
        .content {
            flex: 1;
            overflow-y: auto;
            padding: 2rem;
            background: white;
            margin: 1rem;
            border-radius: 8px;
            box-shadow: 0 2px 8px rgba(0,0,0,0.05);
        }
        
        .tree-node {
            margin-left: 1rem;
            border-left: 2px solid #e0e0e0;
            padding-left: 0.5rem;
        }
        
        .tree-node.root {
            margin-left: 0;
            border-left: none;
            padding-left: 0;
        }
        
        .node-title {
            padding: 0.5rem;
            margin: 0.25rem 0;
            cursor: pointer;
            border-radius: 4px;
            transition: all 0.2s;
            display: flex;
            align-items: center;
            gap: 0.5rem;
        }
        
        .node-title:hover {
            background: #f0f0f0;
        }
        
        .node-title.active {
            background: #667eea;
            color: white;
            font-weight: 500;
        }
        
        .node-icon {
            font-size: 0.8rem;
            opacity: 0.6;
        }
        
        .node-badge {
            font-size: 0.7rem;
            padding: 0.15rem 0.4rem;
            border-radius: 3px;
            background: #e0e0e0;
            margin-left: auto;
        }
        
        .node-title.active .node-badge {
            background: rgba(255,255,255,0.2);
        }
        
        .node-title.keyword {
            font-size: 0.85rem;
            background: #f1f8e9;
            border-left: 3px solid #8bc34a;
        }
        
        .node-title.keyword:hover {
            background: #dcedc8;
        }
        
        .node-title.keyword.active {
            background: #689f38;
            color: white;
        }
        
        .detail-section {
            margin-bottom: 2rem;
        }
        
        .detail-section h2 {
            font-size: 1.5rem;
            margin-bottom: 1rem;
            color: #667eea;
        }
        
        .detail-section h3 {
            font-size: 1rem;
            margin-bottom: 0.5rem;
            color: #666;
            text-transform: uppercase;
            letter-spacing: 0.5px;
            font-weight: 600;
        }
        
        .metadata {
            display: flex;
            gap: 1rem;
            margin-bottom: 1rem;
            flex-wrap: wrap;
        }
        
        .metadata-item {
            background: #f5f5f5;
            padding: 0.5rem 1rem;
            border-radius: 4px;
            font-size: 0.9rem;
        }
        
        .metadata-label {
            font-weight: 600;
            color: #666;
        }
        
        .text-content {
            background: #f9f9f9;
            padding: 1.5rem;
            border-radius: 6px;
            border-left: 4px solid #667eea;
            line-height: 1.6;
            white-space: pre-wrap;
            font-family: 'Georgia', serif;
            margin-bottom: 1rem;
        }
        
        .summary-content {
            background: #fff9e6;
            padding: 1.5rem;
            border-radius: 6px;
            border-left: 4px solid #ffc107;
            line-height: 1.6;
            margin-bottom: 1rem;
        }
        
        .empty-state {
            color: #999;
            font-style: italic;
            padding: 1rem;
        }
        
        .stats {
            display: flex;
            gap: 1rem;
            margin-bottom: 1rem;
            font-size: 0.85rem;
        }
        
        .stat {
            background: #e8eaf6;
            padding: 0.4rem 0.8rem;
            border-radius: 4px;
        }
        
        .children-info {
            background: #e3f2fd;
            padding: 0.8rem;
            border-radius: 4px;
            margin-top: 1rem;
            font-size: 0.9rem;
        }
        
        .warning {
            background: #fff3cd;
            border-left: 4px solid #ffc107;
            padding: 1rem;
            border-radius: 4px;
            margin-bottom: 1rem;
        }
        
        .warning-title {
            font-weight: 600;
            margin-bottom: 0.5rem;
            color: #856404;
        }
        
        ::-webkit-scrollbar {
            width: 8px;
            height: 8px;
        }
        
        ::-webkit-scrollbar-track {
            background: #f1f1f1;
        }
        
        ::-webkit-scrollbar-thumb {
            background: #888;
            border-radius: 4px;
        }
        
        ::-webkit-scrollbar-thumb:hover {
            background: #555;
        }
    </style>
</head>
<body>
    <div class="header">
        <h1>ğŸ“„ Document</h1>
        <div class="subtitle">Structure Visualization</div>
    </div>
    
    <div class="container">
        <div class="sidebar" id="sidebar">
            <h3 style="margin-bottom: 1rem; color: #667eea;">Document Structure</h3>
            <div class="tree-node root"><div class="node-title " data-node-id="0000" onclick="showNodeDetails('0000')"><span class="node-icon">ğŸ“„</span><span>Automated document metadata extraction</span><span class="node-badge">p1-1</span></div><div class="tree-node "><div class="node-title " data-node-id="0001" onclick="showNodeDetails('0001')"><span class="node-icon">ğŸ“</span><span>Document Metadata Extraction Model</span><span class="node-badge">p1-1</span></div><div class="tree-node "><div class="node-title " data-node-id="0002" onclick="showNodeDetails('0002')"><span class="node-icon">ğŸ“</span><span>Document Metadata Extraction Model</span><span class="node-badge">p1-1</span></div><div class="tree-node "><div class="node-title keyword" data-node-id="0003" onclick="showNodeDetails('0003')"><span class="node-icon">ï¿½</span><span>Document Metadata Extraction</span><span class="node-badge">p1-1</span></div></div><div class="tree-node "><div class="node-title keyword" data-node-id="0004" onclick="showNodeDetails('0004')"><span class="node-icon">ï¿½</span><span>Web Documents</span><span class="node-badge">p1-1</span></div></div><div class="tree-node "><div class="node-title keyword" data-node-id="0005" onclick="showNodeDetails('0005')"><span class="node-icon">ï¿½</span><span>Additional Semantics</span><span class="node-badge">p1-1</span></div></div><div class="tree-node "><div class="node-title keyword" data-node-id="0006" onclick="showNodeDetails('0006')"><span class="node-icon">ï¿½</span><span>Segmentation by Keywords</span><span class="node-badge">p1-1</span></div></div><div class="tree-node "><div class="node-title keyword" data-node-id="0007" onclick="showNodeDetails('0007')"><span class="node-icon">ï¿½</span><span>Pattern Matching</span><span class="node-badge">p1-1</span></div></div><div class="tree-node "><div class="node-title keyword" data-node-id="0008" onclick="showNodeDetails('0008')"><span class="node-icon">ï¿½</span><span>PHP</span><span class="node-badge">p1-1</span></div></div><div class="tree-node "><div class="node-title keyword" data-node-id="0009" onclick="showNodeDetails('0009')"><span class="node-icon">ï¿½</span><span>MySQL</span><span class="node-badge">p1-1</span></div></div><div class="tree-node "><div class="node-title keyword" data-node-id="0010" onclick="showNodeDetails('0010')"><span class="node-icon">ï¿½</span><span>JavaScript</span><span class="node-badge">p1-1</span></div></div><div class="tree-node "><div class="node-title keyword" data-node-id="0011" onclick="showNodeDetails('0011')"><span class="node-icon">ï¿½</span><span>HTML</span><span class="node-badge">p1-1</span></div></div></div><div class="tree-node "><div class="node-title " data-node-id="0012" onclick="showNodeDetails('0012')"><span class="node-icon">ğŸ“</span><span>System Testing and Evaluation</span><span class="node-badge">p1-1</span></div><div class="tree-node "><div class="node-title keyword" data-node-id="0013" onclick="showNodeDetails('0013')"><span class="node-icon">ï¿½</span><span>System Testing</span><span class="node-badge">p1-1</span></div></div><div class="tree-node "><div class="node-title keyword" data-node-id="0014" onclick="showNodeDetails('0014')"><span class="node-icon">ï¿½</span><span>Evaluation Criteria</span><span class="node-badge">p1-1</span></div></div><div class="tree-node "><div class="node-title keyword" data-node-id="0015" onclick="showNodeDetails('0015')"><span class="node-icon">ï¿½</span><span>Precision</span><span class="node-badge">p1-1</span></div></div><div class="tree-node "><div class="node-title keyword" data-node-id="0016" onclick="showNodeDetails('0016')"><span class="node-icon">ï¿½</span><span>Recall</span><span class="node-badge">p1-1</span></div></div><div class="tree-node "><div class="node-title keyword" data-node-id="0017" onclick="showNodeDetails('0017')"><span class="node-icon">ï¿½</span><span>Accuracy</span><span class="node-badge">p1-1</span></div></div><div class="tree-node "><div class="node-title keyword" data-node-id="0018" onclick="showNodeDetails('0018')"><span class="node-icon">ï¿½</span><span>F-measure</span><span class="node-badge">p1-1</span></div></div><div class="tree-node "><div class="node-title keyword" data-node-id="0019" onclick="showNodeDetails('0019')"><span class="node-icon">ï¿½</span><span>PDF Documents</span><span class="node-badge">p1-1</span></div></div><div class="tree-node "><div class="node-title keyword" data-node-id="0020" onclick="showNodeDetails('0020')"><span class="node-icon">ï¿½</span><span>Randomly Selected</span><span class="node-badge">p1-1</span></div></div></div><div class="tree-node "><div class="node-title " data-node-id="0021" onclick="showNodeDetails('0021')"><span class="node-icon">ğŸ“</span><span>Results and Future Work</span><span class="node-badge">p1-1</span></div><div class="tree-node "><div class="node-title keyword" data-node-id="0022" onclick="showNodeDetails('0022')"><span class="node-icon">ï¿½</span><span>metadata extraction</span><span class="node-badge">p1-1</span></div></div><div class="tree-node "><div class="node-title keyword" data-node-id="0023" onclick="showNodeDetails('0023')"><span class="node-icon">ï¿½</span><span>theses and dissertations</span><span class="node-badge">p1-1</span></div></div><div class="tree-node "><div class="node-title keyword" data-node-id="0024" onclick="showNodeDetails('0024')"><span class="node-icon">ï¿½</span><span>machine learning</span><span class="node-badge">p1-1</span></div></div><div class="tree-node "><div class="node-title keyword" data-node-id="0025" onclick="showNodeDetails('0025')"><span class="node-icon">ï¿½</span><span>rule-based methods</span><span class="node-badge">p1-1</span></div></div></div></div><div class="tree-node "><div class="node-title " data-node-id="0026" onclick="showNodeDetails('0026')"><span class="node-icon">ğŸ“</span><span>Keywords</span><span class="node-badge">p1-1</span></div></div><div class="tree-node "><div class="node-title " data-node-id="0027" onclick="showNodeDetails('0027')"><span class="node-icon">ğŸ“</span><span>Introduction to Automated Document Structure Extraction</span><span class="node-badge">p1-1</span></div><div class="tree-node "><div class="node-title " data-node-id="0028" onclick="showNodeDetails('0028')"><span class="node-icon">ğŸ“</span><span>Motivation: The Need for Automated Metadata Extraction</span><span class="node-badge">p1-1</span></div><div class="tree-node "><div class="node-title " data-node-id="0029" onclick="showNodeDetails('0029')"><span class="node-icon">ğŸ“</span><span>Motivation for Automatic Metadata Extraction</span><span class="node-badge">p1-1</span></div><div class="tree-node "><div class="node-title keyword" data-node-id="0030" onclick="showNodeDetails('0030')"><span class="node-icon">ï¿½</span><span>Heterogeneous repositories</span><span class="node-badge">p1-1</span></div></div><div class="tree-node "><div class="node-title keyword" data-node-id="0031" onclick="showNodeDetails('0031')"><span class="node-icon">ï¿½</span><span>Unstructured text</span><span class="node-badge">p1-1</span></div></div><div class="tree-node "><div class="node-title keyword" data-node-id="0032" onclick="showNodeDetails('0032')"><span class="node-icon">ï¿½</span><span>Document metadata</span><span class="node-badge">p1-1</span></div></div><div class="tree-node "><div class="node-title keyword" data-node-id="0033" onclick="showNodeDetails('0033')"><span class="node-icon">ï¿½</span><span>Searching, browsing, and filtering</span><span class="node-badge">p1-1</span></div></div><div class="tree-node "><div class="node-title keyword" data-node-id="0034" onclick="showNodeDetails('0034')"><span class="node-icon">ï¿½</span><span>Automatic metadata extraction</span><span class="node-badge">p1-1</span></div></div></div></div><div class="tree-node "><div class="node-title " data-node-id="0035" onclick="showNodeDetails('0035')"><span class="node-icon">ğŸ“</span><span>Benefits of Automated Document Structure Extraction</span><span class="node-badge">p1-1</span></div><div class="tree-node "><div class="node-title " data-node-id="0036" onclick="showNodeDetails('0036')"><span class="node-icon">ğŸ“</span><span>Benefits of Automated Document Structure Extraction</span><span class="node-badge">p1-1</span></div><div class="tree-node "><div class="node-title keyword" data-node-id="0037" onclick="showNodeDetails('0037')"><span class="node-icon">ï¿½</span><span>Automated document structure extraction</span><span class="node-badge">p1-1</span></div></div><div class="tree-node "><div class="node-title keyword" data-node-id="0038" onclick="showNodeDetails('0038')"><span class="node-icon">ï¿½</span><span>Automated mark-up</span><span class="node-badge">p1-1</span></div></div><div class="tree-node "><div class="node-title keyword" data-node-id="0039" onclick="showNodeDetails('0039')"><span class="node-icon">ï¿½</span><span>Information preservation</span><span class="node-badge">p1-1</span></div></div><div class="tree-node "><div class="node-title keyword" data-node-id="0040" onclick="showNodeDetails('0040')"><span class="node-icon">ï¿½</span><span>Logical structure</span><span class="node-badge">p1-1</span></div></div><div class="tree-node "><div class="node-title keyword" data-node-id="0041" onclick="showNodeDetails('0041')"><span class="node-icon">ï¿½</span><span>Flexibility in presentation</span><span class="node-badge">p1-1</span></div></div><div class="tree-node "><div class="node-title keyword" data-node-id="0042" onclick="showNodeDetails('0042')"><span class="node-icon">ï¿½</span><span>Different devices</span><span class="node-badge">p1-1</span></div></div><div class="tree-node "><div class="node-title keyword" data-node-id="0043" onclick="showNodeDetails('0043')"><span class="node-icon">ï¿½</span><span>User access</span><span class="node-badge">p1-1</span></div></div></div></div></div><div class="tree-node "><div class="node-title " data-node-id="0044" onclick="showNodeDetails('0044')"><span class="node-icon">ğŸ“„</span><span>Introduction</span><span class="node-badge">p1-2</span></div></div></div><div class="tree-node root"><div class="node-title " data-node-id="0045" onclick="showNodeDetails('0045')"><span class="node-icon">ğŸ“„</span><span>Review of related studies</span><span class="node-badge">p2-3</span></div></div><div class="tree-node root"><div class="node-title " data-node-id="0046" onclick="showNodeDetails('0046')"><span class="node-icon">ğŸ“„</span><span>Document metadata extraction architecture</span><span class="node-badge">p3-3</span></div><div class="tree-node "><div class="node-title " data-node-id="0047" onclick="showNodeDetails('0047')"><span class="node-icon">ğŸ“</span><span>Document Conversion Model</span><span class="node-badge">p3-3</span></div><div class="tree-node "><div class="node-title " data-node-id="0048" onclick="showNodeDetails('0048')"><span class="node-icon">ğŸ“</span><span>Document Conversion Process</span><span class="node-badge">p3-3</span></div><div class="tree-node "><div class="node-title " data-node-id="0049" onclick="showNodeDetails('0049')"><span class="node-icon">ğŸ“</span><span>Document Conversion Process</span><span class="node-badge">p3-3</span></div><div class="tree-node "><div class="node-title keyword" data-node-id="0050" onclick="showNodeDetails('0050')"><span class="node-icon">ï¿½</span><span>Document Conversion Process</span><span class="node-badge">p3-3</span></div></div><div class="tree-node "><div class="node-title keyword" data-node-id="0051" onclick="showNodeDetails('0051')"><span class="node-icon">ï¿½</span><span>Map Function (M)</span><span class="node-badge">p3-3</span></div></div><div class="tree-node "><div class="node-title keyword" data-node-id="0052" onclick="showNodeDetails('0052')"><span class="node-icon">ï¿½</span><span>Group Function (G)</span><span class="node-badge">p3-3</span></div></div><div class="tree-node "><div class="node-title keyword" data-node-id="0053" onclick="showNodeDetails('0053')"><span class="node-icon">ï¿½</span><span>Extracted Metadata (md)</span><span class="node-badge">p3-3</span></div></div><div class="tree-node "><div class="node-title keyword" data-node-id="0054" onclick="showNodeDetails('0054')"><span class="node-icon">ï¿½</span><span>Extract Function (E)</span><span class="node-badge">p3-3</span></div></div><div class="tree-node "><div class="node-title keyword" data-node-id="0055" onclick="showNodeDetails('0055')"><span class="node-icon">ï¿½</span><span>Title Extraction</span><span class="node-badge">p3-3</span></div></div><div class="tree-node "><div class="node-title keyword" data-node-id="0056" onclick="showNodeDetails('0056')"><span class="node-icon">ï¿½</span><span>Store Function (T)</span><span class="node-badge">p3-3</span></div></div><div class="tree-node "><div class="node-title keyword" data-node-id="0057" onclick="showNodeDetails('0057')"><span class="node-icon">ï¿½</span><span>Database (D)</span><span class="node-badge">p3-3</span></div></div></div></div></div><div class="tree-node "><div class="node-title " data-node-id="0058" onclick="showNodeDetails('0058')"><span class="node-icon">ğŸ“</span><span>Metadata Extraction Approach</span><span class="node-badge">p3-3</span></div><div class="tree-node "><div class="node-title " data-node-id="0059" onclick="showNodeDetails('0059')"><span class="node-icon">ğŸ“</span><span>Document Metadata Extraction Approach</span><span class="node-badge">p3-3</span></div><div class="tree-node "><div class="node-title " data-node-id="0060" onclick="showNodeDetails('0060')"><span class="node-icon">ğŸ“</span><span>Document Metadata Extraction Approach</span><span class="node-badge">p3-3</span></div><div class="tree-node "><div class="node-title keyword" data-node-id="0061" onclick="showNodeDetails('0061')"><span class="node-icon">ï¿½</span><span>Document Metadata Extraction</span><span class="node-badge">p3-3</span></div></div><div class="tree-node "><div class="node-title keyword" data-node-id="0062" onclick="showNodeDetails('0062')"><span class="node-icon">ï¿½</span><span>Segmentation by Keyword</span><span class="node-badge">p3-3</span></div></div><div class="tree-node "><div class="node-title keyword" data-node-id="0063" onclick="showNodeDetails('0063')"><span class="node-icon">ï¿½</span><span>Regular Expressions</span><span class="node-badge">p3-3</span></div></div><div class="tree-node "><div class="node-title keyword" data-node-id="0064" onclick="showNodeDetails('0064')"><span class="node-icon">ï¿½</span><span>Title Extraction</span><span class="node-badge">p3-3</span></div></div><div class="tree-node "><div class="node-title keyword" data-node-id="0065" onclick="showNodeDetails('0065')"><span class="node-icon">ï¿½</span><span>Rules for Title Extraction</span><span class="node-badge">p3-3</span></div></div><div class="tree-node "><div class="node-title keyword" data-node-id="0066" onclick="showNodeDetails('0066')"><span class="node-icon">ï¿½</span><span>Document Meta-data Extractor Architecture</span><span class="node-badge">p3-3</span></div></div></div></div></div><div class="tree-node "><div class="node-title " data-node-id="0067" onclick="showNodeDetails('0067')"><span class="node-icon">ğŸ“</span><span>Segmentation Methods</span><span class="node-badge">p3-3</span></div><div class="tree-node "><div class="node-title " data-node-id="0068" onclick="showNodeDetails('0068')"><span class="node-icon">ğŸ“</span><span>Document Segmentation Overview</span><span class="node-badge">p3-3</span></div><div class="tree-node "><div class="node-title keyword" data-node-id="0069" onclick="showNodeDetails('0069')"><span class="node-icon">ï¿½</span><span>Document Segmentation</span><span class="node-badge">p3-3</span></div></div><div class="tree-node "><div class="node-title keyword" data-node-id="0070" onclick="showNodeDetails('0070')"><span class="node-icon">ï¿½</span><span>Logical Divisions</span><span class="node-badge">p3-3</span></div></div><div class="tree-node "><div class="node-title keyword" data-node-id="0071" onclick="showNodeDetails('0071')"><span class="node-icon">ï¿½</span><span>Document Hierarchy</span><span class="node-badge">p3-3</span></div></div><div class="tree-node "><div class="node-title keyword" data-node-id="0072" onclick="showNodeDetails('0072')"><span class="node-icon">ï¿½</span><span>Layout Segmentation</span><span class="node-badge">p3-3</span></div></div></div><div class="tree-node "><div class="node-title " data-node-id="0073" onclick="showNodeDetails('0073')"><span class="node-icon">ğŸ“</span><span>Segmentation by Spacing</span><span class="node-badge">p3-3</span></div><div class="tree-node "><div class="node-title keyword" data-node-id="0074" onclick="showNodeDetails('0074')"><span class="node-icon">ï¿½</span><span>Segmentation by spacing</span><span class="node-badge">p3-3</span></div></div><div class="tree-node "><div class="node-title keyword" data-node-id="0075" onclick="showNodeDetails('0075')"><span class="node-icon">ï¿½</span><span>Scanned images</span><span class="node-badge">p3-3</span></div></div><div class="tree-node "><div class="node-title keyword" data-node-id="0076" onclick="showNodeDetails('0076')"><span class="node-icon">ï¿½</span><span>Text areas</span><span class="node-badge">p3-3</span></div></div><div class="tree-node "><div class="node-title keyword" data-node-id="0077" onclick="showNodeDetails('0077')"><span class="node-icon">ï¿½</span><span>Figure/table areas</span><span class="node-badge">p3-3</span></div></div><div class="tree-node "><div class="node-title keyword" data-node-id="0078" onclick="showNodeDetails('0078')"><span class="node-icon">ï¿½</span><span>Formulae areas</span><span class="node-badge">p3-3</span></div></div></div><div class="tree-node "><div class="node-title " data-node-id="0079" onclick="showNodeDetails('0079')"><span class="node-icon">ğŸ“</span><span>Segmentation by Style Difference</span><span class="node-badge">p3-3</span></div><div class="tree-node "><div class="node-title " data-node-id="0080" onclick="showNodeDetails('0080')"><span class="node-icon">ğŸ“</span><span>Segmentation by Style Difference</span><span class="node-badge">p3-3</span></div><div class="tree-node "><div class="node-title keyword" data-node-id="0081" onclick="showNodeDetails('0081')"><span class="node-icon">ï¿½</span><span>Segmentation by style difference</span><span class="node-badge">p3-3</span></div></div><div class="tree-node "><div class="node-title keyword" data-node-id="0082" onclick="showNodeDetails('0082')"><span class="node-icon">ï¿½</span><span>Character size</span><span class="node-badge">p3-3</span></div></div><div class="tree-node "><div class="node-title keyword" data-node-id="0083" onclick="showNodeDetails('0083')"><span class="node-icon">ï¿½</span><span>Character boldness</span><span class="node-badge">p3-3</span></div></div><div class="tree-node "><div class="node-title keyword" data-node-id="0084" onclick="showNodeDetails('0084')"><span class="node-icon">ï¿½</span><span>Line styles</span><span class="node-badge">p3-3</span></div></div><div class="tree-node "><div class="node-title keyword" data-node-id="0085" onclick="showNodeDetails('0085')"><span class="node-icon">ï¿½</span><span>Text area segmentation</span><span class="node-badge">p3-3</span></div></div></div></div><div class="tree-node "><div class="node-title " data-node-id="0086" onclick="showNodeDetails('0086')"><span class="node-icon">ğŸ“</span><span>Segmentation by Keywords</span><span class="node-badge">p3-3</span></div><div class="tree-node "><div class="node-title keyword" data-node-id="0087" onclick="showNodeDetails('0087')"><span class="node-icon">ï¿½</span><span>Segmentation by keywords</span><span class="node-badge">p3-3</span></div></div><div class="tree-node "><div class="node-title keyword" data-node-id="0088" onclick="showNodeDetails('0088')"><span class="node-icon">ï¿½</span><span>Special keyword</span><span class="node-badge">p3-3</span></div></div><div class="tree-node "><div class="node-title keyword" data-node-id="0089" onclick="showNodeDetails('0089')"><span class="node-icon">ï¿½</span><span>Area segmentation</span><span class="node-badge">p3-3</span></div></div><div class="tree-node "><div class="node-title keyword" data-node-id="0090" onclick="showNodeDetails('0090')"><span class="node-icon">ï¿½</span><span>Document structure</span><span class="node-badge">p3-3</span></div></div></div></div><div class="tree-node "><div class="node-title " data-node-id="0091" onclick="showNodeDetails('0091')"><span class="node-icon">ğŸ“„</span><span>Segmentation</span><span class="node-badge">p3-5</span></div></div></div><div class="tree-node root"><div class="node-title " data-node-id="0092" onclick="showNodeDetails('0092')"><span class="node-icon">ğŸ“„</span><span>System implementation and evaluation</span><span class="node-badge">p5-7</span></div><div class="tree-node "><div class="node-title " data-node-id="0093" onclick="showNodeDetails('0093')"><span class="node-icon">ğŸ“</span><span>Algorithm and System Implementation</span><span class="node-badge">p5-5</span></div><div class="tree-node "><div class="node-title " data-node-id="0094" onclick="showNodeDetails('0094')"><span class="node-icon">ğŸ“</span><span>Algorithm for Metadata Extraction</span><span class="node-badge">p5-5</span></div><div class="tree-node "><div class="node-title " data-node-id="0095" onclick="showNodeDetails('0095')"><span class="node-icon">ğŸ“</span><span>Metadata Extraction Algorithm</span><span class="node-badge">p5-5</span></div><div class="tree-node "><div class="node-title keyword" data-node-id="0096" onclick="showNodeDetails('0096')"><span class="node-icon">ï¿½</span><span>Metadata Extraction Algorithm</span><span class="node-badge">p5-5</span></div></div><div class="tree-node "><div class="node-title keyword" data-node-id="0097" onclick="showNodeDetails('0097')"><span class="node-icon">ï¿½</span><span>Document Metadata</span><span class="node-badge">p5-5</span></div></div><div class="tree-node "><div class="node-title keyword" data-node-id="0098" onclick="showNodeDetails('0098')"><span class="node-icon">ï¿½</span><span>Algorithm 3</span><span class="node-badge">p5-5</span></div></div><div class="tree-node "><div class="node-title keyword" data-node-id="0099" onclick="showNodeDetails('0099')"><span class="node-icon">ï¿½</span><span>Journal of Information Science</span><span class="node-badge">p5-5</span></div></div></div><div class="tree-node "><div class="node-title " data-node-id="0100" onclick="showNodeDetails('0100')"><span class="node-icon">ğŸ“</span><span>Result Display and Storage Algorithm</span><span class="node-badge">p5-5</span></div><div class="tree-node "><div class="node-title keyword" data-node-id="0101" onclick="showNodeDetails('0101')"><span class="node-icon">ï¿½</span><span>Document Block Location</span><span class="node-badge">p5-5</span></div></div><div class="tree-node "><div class="node-title keyword" data-node-id="0102" onclick="showNodeDetails('0102')"><span class="node-icon">ï¿½</span><span>Keyword Extraction</span><span class="node-badge">p5-5</span></div></div><div class="tree-node "><div class="node-title keyword" data-node-id="0103" onclick="showNodeDetails('0103')"><span class="node-icon">ï¿½</span><span>Algorithm 4</span><span class="node-badge">p5-5</span></div></div><div class="tree-node "><div class="node-title keyword" data-node-id="0104" onclick="showNodeDetails('0104')"><span class="node-icon">ï¿½</span><span>Display Metadata</span><span class="node-badge">p5-5</span></div></div><div class="tree-node "><div class="node-title keyword" data-node-id="0105" onclick="showNodeDetails('0105')"><span class="node-icon">ï¿½</span><span>Extracted Document Block</span><span class="node-badge">p5-5</span></div></div><div class="tree-node "><div class="node-title keyword" data-node-id="0106" onclick="showNodeDetails('0106')"><span class="node-icon">ï¿½</span><span>Store Extracted Metadata</span><span class="node-badge">p5-5</span></div></div><div class="tree-node "><div class="node-title keyword" data-node-id="0107" onclick="showNodeDetails('0107')"><span class="node-icon">ï¿½</span><span>Store Document Block</span><span class="node-badge">p5-5</span></div></div><div class="tree-node "><div class="node-title keyword" data-node-id="0108" onclick="showNodeDetails('0108')"><span class="node-icon">ï¿½</span><span>Browser Window Display</span><span class="node-badge">p5-5</span></div></div><div class="tree-node "><div class="node-title keyword" data-node-id="0109" onclick="showNodeDetails('0109')"><span class="node-icon">ï¿½</span><span>Database Storage</span><span class="node-badge">p5-5</span></div></div></div></div><div class="tree-node "><div class="node-title " data-node-id="0110" onclick="showNodeDetails('0110')"><span class="node-icon">ğŸ“</span><span>Keywords for Grouping</span><span class="node-badge">p5-5</span></div><div class="tree-node "><div class="node-title keyword" data-node-id="0111" onclick="showNodeDetails('0111')"><span class="node-icon">ï¿½</span><span>Table of Contents</span><span class="node-badge">p5-5</span></div></div><div class="tree-node "><div class="node-title keyword" data-node-id="0112" onclick="showNodeDetails('0112')"><span class="node-icon">ï¿½</span><span>Abstract</span><span class="node-badge">p5-5</span></div></div><div class="tree-node "><div class="node-title keyword" data-node-id="0113" onclick="showNodeDetails('0113')"><span class="node-icon">ï¿½</span><span>Preface</span><span class="node-badge">p5-5</span></div></div><div class="tree-node "><div class="node-title keyword" data-node-id="0114" onclick="showNodeDetails('0114')"><span class="node-icon">ï¿½</span><span>Chapter 1 (One)</span><span class="node-badge">p5-5</span></div></div><div class="tree-node "><div class="node-title keyword" data-node-id="0115" onclick="showNodeDetails('0115')"><span class="node-icon">ï¿½</span><span>Introduction</span><span class="node-badge">p5-5</span></div></div><div class="tree-node "><div class="node-title keyword" data-node-id="0116" onclick="showNodeDetails('0116')"><span class="node-icon">ï¿½</span><span>Conclusion</span><span class="node-badge">p5-5</span></div></div><div class="tree-node "><div class="node-title keyword" data-node-id="0117" onclick="showNodeDetails('0117')"><span class="node-icon">ï¿½</span><span>References</span><span class="node-badge">p5-5</span></div></div><div class="tree-node "><div class="node-title keyword" data-node-id="0118" onclick="showNodeDetails('0118')"><span class="node-icon">ï¿½</span><span>Bibliography</span><span class="node-badge">p5-5</span></div></div><div class="tree-node "><div class="node-title keyword" data-node-id="0119" onclick="showNodeDetails('0119')"><span class="node-icon">ï¿½</span><span>Citation</span><span class="node-badge">p5-5</span></div></div><div class="tree-node "><div class="node-title keyword" data-node-id="0120" onclick="showNodeDetails('0120')"><span class="node-icon">ï¿½</span><span>Appendix (A/1)</span><span class="node-badge">p5-5</span></div></div><div class="tree-node "><div class="node-title keyword" data-node-id="0121" onclick="showNodeDetails('0121')"><span class="node-icon">ï¿½</span><span>Regular expressions</span><span class="node-badge">p5-5</span></div></div></div><div class="tree-node "><div class="node-title " data-node-id="0122" onclick="showNodeDetails('0122')"><span class="node-icon">ğŸ“</span><span>System Implementation Overview</span><span class="node-badge">p5-5</span></div><div class="tree-node "><div class="node-title keyword" data-node-id="0123" onclick="showNodeDetails('0123')"><span class="node-icon">ï¿½</span><span>System implementation</span><span class="node-badge">p5-5</span></div></div><div class="tree-node "><div class="node-title keyword" data-node-id="0124" onclick="showNodeDetails('0124')"><span class="node-icon">ï¿½</span><span>Document metadata extractor</span><span class="node-badge">p5-5</span></div></div><div class="tree-node "><div class="node-title keyword" data-node-id="0125" onclick="showNodeDetails('0125')"><span class="node-icon">ï¿½</span><span>Uploaded document</span><span class="node-badge">p5-5</span></div></div><div class="tree-node "><div class="node-title keyword" data-node-id="0126" onclick="showNodeDetails('0126')"><span class="node-icon">ï¿½</span><span>Text conversion</span><span class="node-badge">p5-5</span></div></div><div class="tree-node "><div class="node-title keyword" data-node-id="0127" onclick="showNodeDetails('0127')"><span class="node-icon">ï¿½</span><span>Metadata</span><span class="node-badge">p5-5</span></div></div><div class="tree-node "><div class="node-title keyword" data-node-id="0128" onclick="showNodeDetails('0128')"><span class="node-icon">ï¿½</span><span>Browser window</span><span class="node-badge">p5-5</span></div></div><div class="tree-node "><div class="node-title keyword" data-node-id="0129" onclick="showNodeDetails('0129')"><span class="node-icon">ï¿½</span><span>Hyperlinks</span><span class="node-badge">p5-5</span></div></div><div class="tree-node "><div class="node-title keyword" data-node-id="0130" onclick="showNodeDetails('0130')"><span class="node-icon">ï¿½</span><span>Scans document</span><span class="node-badge">p5-5</span></div></div><div class="tree-node "><div class="node-title keyword" data-node-id="0131" onclick="showNodeDetails('0131')"><span class="node-icon">ï¿½</span><span>Corresponding content</span><span class="node-badge">p5-5</span></div></div></div><div class="tree-node "><div class="node-title " data-node-id="0132" onclick="showNodeDetails('0132')"><span class="node-icon">ğŸ“</span><span>Experimental Sample Description</span><span class="node-badge">p5-5</span></div><div class="tree-node "><div class="node-title keyword" data-node-id="0133" onclick="showNodeDetails('0133')"><span class="node-icon">ï¿½</span><span>Document metadata extractor</span><span class="node-badge">p5-5</span></div></div><div class="tree-node "><div class="node-title keyword" data-node-id="0134" onclick="showNodeDetails('0134')"><span class="node-icon">ï¿½</span><span>Experimental sample</span><span class="node-badge">p5-5</span></div></div><div class="tree-node "><div class="node-title keyword" data-node-id="0135" onclick="showNodeDetails('0135')"><span class="node-icon">ï¿½</span><span>Randomly selected theses</span><span class="node-badge">p5-5</span></div></div><div class="tree-node "><div class="node-title keyword" data-node-id="0136" onclick="showNodeDetails('0136')"><span class="node-icon">ï¿½</span><span>Dissertations</span><span class="node-badge">p5-5</span></div></div><div class="tree-node "><div class="node-title keyword" data-node-id="0137" onclick="showNodeDetails('0137')"><span class="node-icon">ï¿½</span><span>Technical reports</span><span class="node-badge">p5-5</span></div></div><div class="tree-node "><div class="node-title keyword" data-node-id="0138" onclick="showNodeDetails('0138')"><span class="node-icon">ï¿½</span><span>Theses focus</span><span class="node-badge">p5-5</span></div></div></div><div class="tree-node "><div class="node-title " data-node-id="0139" onclick="showNodeDetails('0139')"><span class="node-icon">ğŸ“</span><span>Evaluation Criteria</span><span class="node-badge">p5-5</span></div><div class="tree-node "><div class="node-title keyword" data-node-id="0140" onclick="showNodeDetails('0140')"><span class="node-icon">ï¿½</span><span>Evaluation Criteria</span><span class="node-badge">p5-5</span></div></div><div class="tree-node "><div class="node-title keyword" data-node-id="0141" onclick="showNodeDetails('0141')"><span class="node-icon">ï¿½</span><span>Recall</span><span class="node-badge">p5-5</span></div></div><div class="tree-node "><div class="node-title keyword" data-node-id="0142" onclick="showNodeDetails('0142')"><span class="node-icon">ï¿½</span><span>Precision</span><span class="node-badge">p5-5</span></div></div><div class="tree-node "><div class="node-title keyword" data-node-id="0143" onclick="showNodeDetails('0143')"><span class="node-icon">ï¿½</span><span>Accuracy</span><span class="node-badge">p5-5</span></div></div><div class="tree-node "><div class="node-title keyword" data-node-id="0144" onclick="showNodeDetails('0144')"><span class="node-icon">ï¿½</span><span>F-measure</span><span class="node-badge">p5-5</span></div></div><div class="tree-node "><div class="node-title keyword" data-node-id="0145" onclick="showNodeDetails('0145')"><span class="node-icon">ï¿½</span><span>Equations (14)-(17)</span><span class="node-badge">p5-5</span></div></div></div><div class="tree-node "><div class="node-title " data-node-id="0146" onclick="showNodeDetails('0146')"><span class="node-icon">ğŸ“</span><span>Comparison with Related Work</span><span class="node-badge">p5-5</span></div><div class="tree-node "><div class="node-title keyword" data-node-id="0147" onclick="showNodeDetails('0147')"><span class="node-icon">ï¿½</span><span>performance comparison</span><span class="node-badge">p5-5</span></div></div><div class="tree-node "><div class="node-title keyword" data-node-id="0148" onclick="showNodeDetails('0148')"><span class="node-icon">ï¿½</span><span>related work</span><span class="node-badge">p5-5</span></div></div><div class="tree-node "><div class="node-title keyword" data-node-id="0149" onclick="showNodeDetails('0149')"><span class="node-icon">ï¿½</span><span>experimental evaluation</span><span class="node-badge">p5-5</span></div></div><div class="tree-node "><div class="node-title keyword" data-node-id="0150" onclick="showNodeDetails('0150')"><span class="node-icon">ï¿½</span><span>reference metadata extractor</span><span class="node-badge">p5-5</span></div></div><div class="tree-node "><div class="node-title keyword" data-node-id="0151" onclick="showNodeDetails('0151')"><span class="node-icon">ï¿½</span><span>documents used for testing</span><span class="node-badge">p5-5</span></div></div></div><div class="tree-node "><div class="node-title " data-node-id="0152" onclick="showNodeDetails('0152')"><span class="node-icon">ğŸ“</span><span>Performance Metrics Definitions</span><span class="node-badge">p5-5</span></div><div class="tree-node "><div class="node-title " data-node-id="0153" onclick="showNodeDetails('0153')"><span class="node-icon">ğŸ“</span><span>Definitions of Metrics</span><span class="node-badge">p5-5</span></div><div class="tree-node "><div class="node-title keyword" data-node-id="0154" onclick="showNodeDetails('0154')"><span class="node-icon">ï¿½</span><span>Precision</span><span class="node-badge">p5-5</span></div></div><div class="tree-node "><div class="node-title keyword" data-node-id="0155" onclick="showNodeDetails('0155')"><span class="node-icon">ï¿½</span><span>Recall</span><span class="node-badge">p5-5</span></div></div><div class="tree-node "><div class="node-title keyword" data-node-id="0156" onclick="showNodeDetails('0156')"><span class="node-icon">ï¿½</span><span>Accuracy</span><span class="node-badge">p5-5</span></div></div><div class="tree-node "><div class="node-title keyword" data-node-id="0157" onclick="showNodeDetails('0157')"><span class="node-icon">ï¿½</span><span>F-measure</span><span class="node-badge">p5-5</span></div></div><div class="tree-node "><div class="node-title keyword" data-node-id="0158" onclick="showNodeDetails('0158')"><span class="node-icon">ï¿½</span><span>Correctly extracted fields (A)</span><span class="node-badge">p5-5</span></div></div><div class="tree-node "><div class="node-title keyword" data-node-id="0159" onclick="showNodeDetails('0159')"><span class="node-icon">ï¿½</span><span>Fields with existing, not extracted data (B)</span><span class="node-badge">p5-5</span></div></div><div class="tree-node "><div class="node-title keyword" data-node-id="0160" onclick="showNodeDetails('0160')"><span class="node-icon">ï¿½</span><span>Fields with wrongly extracted data (C)</span><span class="node-badge">p5-5</span></div></div><div class="tree-node "><div class="node-title keyword" data-node-id="0161" onclick="showNodeDetails('0161')"><span class="node-icon">ï¿½</span><span>Fields with not existing, not extracted data (D)</span><span class="node-badge">p5-5</span></div></div></div></div><div class="tree-node "><div class="node-title " data-node-id="0162" onclick="showNodeDetails('0162')"><span class="node-icon">ğŸ“</span><span>Manual Verification and Sample Size</span><span class="node-badge">p5-5</span></div><div class="tree-node "><div class="node-title keyword" data-node-id="0163" onclick="showNodeDetails('0163')"><span class="node-icon">ï¿½</span><span>Manual verification</span><span class="node-badge">p5-5</span></div></div><div class="tree-node "><div class="node-title keyword" data-node-id="0164" onclick="showNodeDetails('0164')"><span class="node-icon">ï¿½</span><span>Extracted metadata</span><span class="node-badge">p5-5</span></div></div><div class="tree-node "><div class="node-title keyword" data-node-id="0165" onclick="showNodeDetails('0165')"><span class="node-icon">ï¿½</span><span>Original document</span><span class="node-badge">p5-5</span></div></div><div class="tree-node "><div class="node-title keyword" data-node-id="0166" onclick="showNodeDetails('0166')"><span class="node-icon">ï¿½</span><span>Lengthy and tedious</span><span class="node-badge">p5-5</span></div></div><div class="tree-node "><div class="node-title keyword" data-node-id="0167" onclick="showNodeDetails('0167')"><span class="node-icon">ï¿½</span><span>Sample size</span><span class="node-badge">p5-5</span></div></div><div class="tree-node "><div class="node-title keyword" data-node-id="0168" onclick="showNodeDetails('0168')"><span class="node-icon">ï¿½</span><span>40 documents</span><span class="node-badge">p5-5</span></div></div></div><div class="tree-node "><div class="node-title " data-node-id="0169" onclick="showNodeDetails('0169')"><span class="node-icon">ğŸ“</span><span>Summary of Results</span><span class="node-badge">p5-5</span></div><div class="tree-node "><div class="node-title keyword" data-node-id="0170" onclick="showNodeDetails('0170')"><span class="node-icon">ï¿½</span><span>precision</span><span class="node-badge">p5-5</span></div></div><div class="tree-node "><div class="node-title keyword" data-node-id="0171" onclick="showNodeDetails('0171')"><span class="node-icon">ï¿½</span><span>recall</span><span class="node-badge">p5-5</span></div></div><div class="tree-node "><div class="node-title keyword" data-node-id="0172" onclick="showNodeDetails('0172')"><span class="node-icon">ï¿½</span><span>accuracy</span><span class="node-badge">p5-5</span></div></div><div class="tree-node "><div class="node-title keyword" data-node-id="0173" onclick="showNodeDetails('0173')"><span class="node-icon">ï¿½</span><span>F-measure</span><span class="node-badge">p5-5</span></div></div><div class="tree-node "><div class="node-title keyword" data-node-id="0174" onclick="showNodeDetails('0174')"><span class="node-icon">ï¿½</span><span>Tables 1â€“4</span><span class="node-badge">p5-5</span></div></div></div></div><div class="tree-node "><div class="node-title " data-node-id="0175" onclick="showNodeDetails('0175')"><span class="node-icon">ğŸ“</span><span>Experimental Evaluation Results</span><span class="node-badge">p6-6</span></div><div class="tree-node "><div class="node-title " data-node-id="0176" onclick="showNodeDetails('0176')"><span class="node-icon">ğŸ“</span><span>Metadata Extraction Precision</span><span class="node-badge">p6-6</span></div><div class="tree-node "><div class="node-title " data-node-id="0177" onclick="showNodeDetails('0177')"><span class="node-icon">ğŸ“</span><span>Metadata Extraction Precision Across Document Types</span><span class="node-badge">p6-6</span></div><div class="tree-node "><div class="node-title keyword" data-node-id="0178" onclick="showNodeDetails('0178')"><span class="node-icon">ï¿½</span><span>Metadata Extraction Precision</span><span class="node-badge">p6-6</span></div></div><div class="tree-node "><div class="node-title keyword" data-node-id="0179" onclick="showNodeDetails('0179')"><span class="node-icon">ï¿½</span><span>Document Types</span><span class="node-badge">p6-6</span></div></div><div class="tree-node "><div class="node-title keyword" data-node-id="0180" onclick="showNodeDetails('0180')"><span class="node-icon">ï¿½</span><span>Theses</span><span class="node-badge">p6-6</span></div></div><div class="tree-node "><div class="node-title keyword" data-node-id="0181" onclick="showNodeDetails('0181')"><span class="node-icon">ï¿½</span><span>Title Precision</span><span class="node-badge">p6-6</span></div></div><div class="tree-node "><div class="node-title keyword" data-node-id="0182" onclick="showNodeDetails('0182')"><span class="node-icon">ï¿½</span><span>Table of Contents Precision</span><span class="node-badge">p6-6</span></div></div><div class="tree-node "><div class="node-title keyword" data-node-id="0183" onclick="showNodeDetails('0183')"><span class="node-icon">ï¿½</span><span>Preface Precision</span><span class="node-badge">p6-6</span></div></div><div class="tree-node "><div class="node-title keyword" data-node-id="0184" onclick="showNodeDetails('0184')"><span class="node-icon">ï¿½</span><span>Abstract Precision</span><span class="node-badge">p6-6</span></div></div><div class="tree-node "><div class="node-title keyword" data-node-id="0185" onclick="showNodeDetails('0185')"><span class="node-icon">ï¿½</span><span>Acknowledgment Precision</span><span class="node-badge">p6-6</span></div></div><div class="tree-node "><div class="node-title keyword" data-node-id="0186" onclick="showNodeDetails('0186')"><span class="node-icon">ï¿½</span><span>Introduction Precision</span><span class="node-badge">p6-6</span></div></div><div class="tree-node "><div class="node-title keyword" data-node-id="0187" onclick="showNodeDetails('0187')"><span class="node-icon">ï¿½</span><span>Conclusion Precision</span><span class="node-badge">p6-6</span></div></div></div><div class="tree-node "><div class="node-title " data-node-id="0188" onclick="showNodeDetails('0188')"><span class="node-icon">ğŸ“</span><span>Metadata Extraction Precision for References</span><span class="node-badge">p6-6</span></div><div class="tree-node "><div class="node-title keyword" data-node-id="0189" onclick="showNodeDetails('0189')"><span class="node-icon">ï¿½</span><span>Metadata Extraction</span><span class="node-badge">p6-6</span></div></div><div class="tree-node "><div class="node-title keyword" data-node-id="0190" onclick="showNodeDetails('0190')"><span class="node-icon">ï¿½</span><span>References</span><span class="node-badge">p6-6</span></div></div><div class="tree-node "><div class="node-title keyword" data-node-id="0191" onclick="showNodeDetails('0191')"><span class="node-icon">ï¿½</span><span>Precision</span><span class="node-badge">p6-6</span></div></div><div class="tree-node "><div class="node-title keyword" data-node-id="0192" onclick="showNodeDetails('0192')"><span class="node-icon">ï¿½</span><span>References 1.0</span><span class="node-badge">p6-6</span></div></div><div class="tree-node "><div class="node-title keyword" data-node-id="0193" onclick="showNodeDetails('0193')"><span class="node-icon">ï¿½</span><span>Information Retrieval</span><span class="node-badge">p6-6</span></div></div><div class="tree-node "><div class="node-title keyword" data-node-id="0194" onclick="showNodeDetails('0194')"><span class="node-icon">ï¿½</span><span>Domain-Specific Terminology</span><span class="node-badge">p6-6</span></div></div></div></div><div class="tree-node "><div class="node-title " data-node-id="0195" onclick="showNodeDetails('0195')"><span class="node-icon">ğŸ“</span><span>Metadata Extraction Recall</span><span class="node-badge">p6-6</span></div><div class="tree-node "><div class="node-title " data-node-id="0196" onclick="showNodeDetails('0196')"><span class="node-icon">ğŸ“</span><span>Metadata Extraction Recall for Theses and Related Documents</span><span class="node-badge">p6-6</span></div><div class="tree-node "><div class="node-title keyword" data-node-id="0197" onclick="showNodeDetails('0197')"><span class="node-icon">ï¿½</span><span>Metadata Extraction Recall</span><span class="node-badge">p6-6</span></div></div><div class="tree-node "><div class="node-title keyword" data-node-id="0198" onclick="showNodeDetails('0198')"><span class="node-icon">ï¿½</span><span>Theses</span><span class="node-badge">p6-6</span></div></div><div class="tree-node "><div class="node-title keyword" data-node-id="0199" onclick="showNodeDetails('0199')"><span class="node-icon">ï¿½</span><span>Related Documents</span><span class="node-badge">p6-6</span></div></div><div class="tree-node "><div class="node-title keyword" data-node-id="0200" onclick="showNodeDetails('0200')"><span class="node-icon">ï¿½</span><span>Document Analysis</span><span class="node-badge">p6-6</span></div></div><div class="tree-node "><div class="node-title keyword" data-node-id="0201" onclick="showNodeDetails('0201')"><span class="node-icon">ï¿½</span><span>Information Retrieval</span><span class="node-badge">p6-6</span></div></div></div><div class="tree-node "><div class="node-title " data-node-id="0202" onclick="showNodeDetails('0202')"><span class="node-icon">ğŸ“</span><span>Recall Rates for Specific Document Sections</span><span class="node-badge">p6-6</span></div><div class="tree-node "><div class="node-title keyword" data-node-id="0203" onclick="showNodeDetails('0203')"><span class="node-icon">ï¿½</span><span>Recall Rates</span><span class="node-badge">p6-6</span></div></div><div class="tree-node "><div class="node-title keyword" data-node-id="0204" onclick="showNodeDetails('0204')"><span class="node-icon">ï¿½</span><span>Title Recall</span><span class="node-badge">p6-6</span></div></div><div class="tree-node "><div class="node-title keyword" data-node-id="0205" onclick="showNodeDetails('0205')"><span class="node-icon">ï¿½</span><span>Table of Contents Recall</span><span class="node-badge">p6-6</span></div></div><div class="tree-node "><div class="node-title keyword" data-node-id="0206" onclick="showNodeDetails('0206')"><span class="node-icon">ï¿½</span><span>Preface Recall</span><span class="node-badge">p6-6</span></div></div><div class="tree-node "><div class="node-title keyword" data-node-id="0207" onclick="showNodeDetails('0207')"><span class="node-icon">ï¿½</span><span>Abstract Recall</span><span class="node-badge">p6-6</span></div></div><div class="tree-node "><div class="node-title keyword" data-node-id="0208" onclick="showNodeDetails('0208')"><span class="node-icon">ï¿½</span><span>Acknowledgment Recall</span><span class="node-badge">p6-6</span></div></div><div class="tree-node "><div class="node-title keyword" data-node-id="0209" onclick="showNodeDetails('0209')"><span class="node-icon">ï¿½</span><span>Introduction Recall</span><span class="node-badge">p6-6</span></div></div><div class="tree-node "><div class="node-title keyword" data-node-id="0210" onclick="showNodeDetails('0210')"><span class="node-icon">ï¿½</span><span>Conclusion Recall</span><span class="node-badge">p6-6</span></div></div><div class="tree-node "><div class="node-title keyword" data-node-id="0211" onclick="showNodeDetails('0211')"><span class="node-icon">ï¿½</span><span>References Recall</span><span class="node-badge">p6-6</span></div></div></div></div><div class="tree-node "><div class="node-title " data-node-id="0212" onclick="showNodeDetails('0212')"><span class="node-icon">ğŸ“</span><span>Metadata Extraction Accuracy</span><span class="node-badge">p6-6</span></div><div class="tree-node "><div class="node-title " data-node-id="0213" onclick="showNodeDetails('0213')"><span class="node-icon">ğŸ“</span><span>Metadata Extraction Accuracy Across Document Types</span><span class="node-badge">p6-6</span></div><div class="tree-node "><div class="node-title keyword" data-node-id="0214" onclick="showNodeDetails('0214')"><span class="node-icon">ï¿½</span><span>Metadata Extraction Accuracy</span><span class="node-badge">p6-6</span></div></div><div class="tree-node "><div class="node-title keyword" data-node-id="0215" onclick="showNodeDetails('0215')"><span class="node-icon">ï¿½</span><span>Document Types</span><span class="node-badge">p6-6</span></div></div><div class="tree-node "><div class="node-title keyword" data-node-id="0216" onclick="showNodeDetails('0216')"><span class="node-icon">ï¿½</span><span>Theses</span><span class="node-badge">p6-6</span></div></div><div class="tree-node "><div class="node-title keyword" data-node-id="0217" onclick="showNodeDetails('0217')"><span class="node-icon">ï¿½</span><span>Title Accuracy</span><span class="node-badge">p6-6</span></div></div><div class="tree-node "><div class="node-title keyword" data-node-id="0218" onclick="showNodeDetails('0218')"><span class="node-icon">ï¿½</span><span>Table of Contents Accuracy</span><span class="node-badge">p6-6</span></div></div><div class="tree-node "><div class="node-title keyword" data-node-id="0219" onclick="showNodeDetails('0219')"><span class="node-icon">ï¿½</span><span>Preface Accuracy</span><span class="node-badge">p6-6</span></div></div><div class="tree-node "><div class="node-title keyword" data-node-id="0220" onclick="showNodeDetails('0220')"><span class="node-icon">ï¿½</span><span>Abstract Accuracy</span><span class="node-badge">p6-6</span></div></div><div class="tree-node "><div class="node-title keyword" data-node-id="0221" onclick="showNodeDetails('0221')"><span class="node-icon">ï¿½</span><span>Acknowledgment Accuracy</span><span class="node-badge">p6-6</span></div></div><div class="tree-node "><div class="node-title keyword" data-node-id="0222" onclick="showNodeDetails('0222')"><span class="node-icon">ï¿½</span><span>Introduction Accuracy</span><span class="node-badge">p6-6</span></div></div><div class="tree-node "><div class="node-title keyword" data-node-id="0223" onclick="showNodeDetails('0223')"><span class="node-icon">ï¿½</span><span>Conclusion Accuracy</span><span class="node-badge">p6-6</span></div></div><div class="tree-node "><div class="node-title keyword" data-node-id="0224" onclick="showNodeDetails('0224')"><span class="node-icon">ï¿½</span><span>References Accuracy</span><span class="node-badge">p6-6</span></div></div></div></div><div class="tree-node "><div class="node-title " data-node-id="0225" onclick="showNodeDetails('0225')"><span class="node-icon">ğŸ“</span><span>Metadata Extraction F-measure</span><span class="node-badge">p6-6</span></div><div class="tree-node "><div class="node-title " data-node-id="0226" onclick="showNodeDetails('0226')"><span class="node-icon">ğŸ“</span><span>Metadata Extraction F-measure Across Theses and Related Documents</span><span class="node-badge">p6-6</span></div><div class="tree-node "><div class="node-title keyword" data-node-id="0227" onclick="showNodeDetails('0227')"><span class="node-icon">ï¿½</span><span>Metadata Extraction</span><span class="node-badge">p6-6</span></div></div><div class="tree-node "><div class="node-title keyword" data-node-id="0228" onclick="showNodeDetails('0228')"><span class="node-icon">ï¿½</span><span>F-measure</span><span class="node-badge">p6-6</span></div></div><div class="tree-node "><div class="node-title keyword" data-node-id="0229" onclick="showNodeDetails('0229')"><span class="node-icon">ï¿½</span><span>Theses</span><span class="node-badge">p6-6</span></div></div><div class="tree-node "><div class="node-title keyword" data-node-id="0230" onclick="showNodeDetails('0230')"><span class="node-icon">ï¿½</span><span>Related Documents</span><span class="node-badge">p6-6</span></div></div><div class="tree-node "><div class="node-title keyword" data-node-id="0231" onclick="showNodeDetails('0231')"><span class="node-icon">ï¿½</span><span>Performance Evaluation</span><span class="node-badge">p6-6</span></div></div></div><div class="tree-node "><div class="node-title " data-node-id="0232" onclick="showNodeDetails('0232')"><span class="node-icon">ğŸ“</span><span>F-measure for Specific Document Sections</span><span class="node-badge">p6-6</span></div><div class="tree-node "><div class="node-title keyword" data-node-id="0233" onclick="showNodeDetails('0233')"><span class="node-icon">ï¿½</span><span>F-measure</span><span class="node-badge">p6-6</span></div></div><div class="tree-node "><div class="node-title keyword" data-node-id="0234" onclick="showNodeDetails('0234')"><span class="node-icon">ï¿½</span><span>Title</span><span class="node-badge">p6-6</span></div></div><div class="tree-node "><div class="node-title keyword" data-node-id="0235" onclick="showNodeDetails('0235')"><span class="node-icon">ï¿½</span><span>Table of Contents</span><span class="node-badge">p6-6</span></div></div><div class="tree-node "><div class="node-title keyword" data-node-id="0236" onclick="showNodeDetails('0236')"><span class="node-icon">ï¿½</span><span>Preface</span><span class="node-badge">p6-6</span></div></div><div class="tree-node "><div class="node-title keyword" data-node-id="0237" onclick="showNodeDetails('0237')"><span class="node-icon">ï¿½</span><span>Abstract</span><span class="node-badge">p6-6</span></div></div><div class="tree-node "><div class="node-title keyword" data-node-id="0238" onclick="showNodeDetails('0238')"><span class="node-icon">ï¿½</span><span>Acknowledgment</span><span class="node-badge">p6-6</span></div></div><div class="tree-node "><div class="node-title keyword" data-node-id="0239" onclick="showNodeDetails('0239')"><span class="node-icon">ï¿½</span><span>Introduction</span><span class="node-badge">p6-6</span></div></div><div class="tree-node "><div class="node-title keyword" data-node-id="0240" onclick="showNodeDetails('0240')"><span class="node-icon">ï¿½</span><span>Conclusion</span><span class="node-badge">p6-6</span></div></div><div class="tree-node "><div class="node-title keyword" data-node-id="0241" onclick="showNodeDetails('0241')"><span class="node-icon">ï¿½</span><span>References</span><span class="node-badge">p6-6</span></div></div></div></div></div><div class="tree-node "><div class="node-title " data-node-id="0242" onclick="showNodeDetails('0242')"><span class="node-icon">ğŸ“</span><span>Discussion of Results and Comparison with Related Work</span><span class="node-badge">p7-7</span></div><div class="tree-node "><div class="node-title " data-node-id="0243" onclick="showNodeDetails('0243')"><span class="node-icon">ğŸ“</span><span>Interpretation of &#x27;References&#x27; Extraction</span><span class="node-badge">p7-7</span></div><div class="tree-node "><div class="node-title " data-node-id="0244" onclick="showNodeDetails('0244')"><span class="node-icon">ğŸ“</span><span>Interpretation of High Precision for &#x27;References&#x27;</span><span class="node-badge">p7-7</span></div><div class="tree-node "><div class="node-title keyword" data-node-id="0245" onclick="showNodeDetails('0245')"><span class="node-icon">ï¿½</span><span>References</span><span class="node-badge">p7-7</span></div></div><div class="tree-node "><div class="node-title keyword" data-node-id="0246" onclick="showNodeDetails('0246')"><span class="node-icon">ï¿½</span><span>High Precision</span><span class="node-badge">p7-7</span></div></div><div class="tree-node "><div class="node-title keyword" data-node-id="0247" onclick="showNodeDetails('0247')"><span class="node-icon">ï¿½</span><span>Recall</span><span class="node-badge">p7-7</span></div></div><div class="tree-node "><div class="node-title keyword" data-node-id="0248" onclick="showNodeDetails('0248')"><span class="node-icon">ï¿½</span><span>Accuracy</span><span class="node-badge">p7-7</span></div></div><div class="tree-node "><div class="node-title keyword" data-node-id="0249" onclick="showNodeDetails('0249')"><span class="node-icon">ï¿½</span><span>F-measure</span><span class="node-badge">p7-7</span></div></div><div class="tree-node "><div class="node-title keyword" data-node-id="0250" onclick="showNodeDetails('0250')"><span class="node-icon">ï¿½</span><span>Document End Location</span><span class="node-badge">p7-7</span></div></div></div></div><div class="tree-node "><div class="node-title " data-node-id="0251" onclick="showNodeDetails('0251')"><span class="node-icon">ğŸ“</span><span>Interpretation of &#x27;Preface&#x27; Extraction</span><span class="node-badge">p7-7</span></div><div class="tree-node "><div class="node-title keyword" data-node-id="0252" onclick="showNodeDetails('0252')"><span class="node-icon">ï¿½</span><span>Preface extraction</span><span class="node-badge">p7-7</span></div></div><div class="tree-node "><div class="node-title keyword" data-node-id="0253" onclick="showNodeDetails('0253')"><span class="node-icon">ï¿½</span><span>Not existing cases</span><span class="node-badge">p7-7</span></div></div><div class="tree-node "><div class="node-title keyword" data-node-id="0254" onclick="showNodeDetails('0254')"><span class="node-icon">ï¿½</span><span>Not extracted cases</span><span class="node-badge">p7-7</span></div></div><div class="tree-node "><div class="node-title keyword" data-node-id="0255" onclick="showNodeDetails('0255')"><span class="node-icon">ï¿½</span><span>Recall</span><span class="node-badge">p7-7</span></div></div><div class="tree-node "><div class="node-title keyword" data-node-id="0256" onclick="showNodeDetails('0256')"><span class="node-icon">ï¿½</span><span>Accuracy</span><span class="node-badge">p7-7</span></div></div></div><div class="tree-node "><div class="node-title " data-node-id="0257" onclick="showNodeDetails('0257')"><span class="node-icon">ğŸ“</span><span>Interpretation of &#x27;Introduction&#x27; and &#x27;Conclusion&#x27; Extraction</span><span class="node-badge">p7-7</span></div><div class="tree-node "><div class="node-title " data-node-id="0258" onclick="showNodeDetails('0258')"><span class="node-icon">ğŸ“</span><span>Performance of &#x27;Introduction&#x27; and &#x27;Conclusion&#x27; Extraction</span><span class="node-badge">p7-7</span></div><div class="tree-node "><div class="node-title keyword" data-node-id="0259" onclick="showNodeDetails('0259')"><span class="node-icon">ï¿½</span><span>Introduction extraction</span><span class="node-badge">p7-7</span></div></div><div class="tree-node "><div class="node-title keyword" data-node-id="0260" onclick="showNodeDetails('0260')"><span class="node-icon">ï¿½</span><span>Conclusion extraction</span><span class="node-badge">p7-7</span></div></div><div class="tree-node "><div class="node-title keyword" data-node-id="0261" onclick="showNodeDetails('0261')"><span class="node-icon">ï¿½</span><span>Evaluation criteria</span><span class="node-badge">p7-7</span></div></div><div class="tree-node "><div class="node-title keyword" data-node-id="0262" onclick="showNodeDetails('0262')"><span class="node-icon">ï¿½</span><span>Precision</span><span class="node-badge">p7-7</span></div></div><div class="tree-node "><div class="node-title keyword" data-node-id="0263" onclick="showNodeDetails('0263')"><span class="node-icon">ï¿½</span><span>Recall</span><span class="node-badge">p7-7</span></div></div><div class="tree-node "><div class="node-title keyword" data-node-id="0264" onclick="showNodeDetails('0264')"><span class="node-icon">ï¿½</span><span>F-measure</span><span class="node-badge">p7-7</span></div></div><div class="tree-node "><div class="node-title keyword" data-node-id="0265" onclick="showNodeDetails('0265')"><span class="node-icon">ï¿½</span><span>Accuracy</span><span class="node-badge">p7-7</span></div></div></div><div class="tree-node "><div class="node-title " data-node-id="0266" onclick="showNodeDetails('0266')"><span class="node-icon">ğŸ“</span><span>Reasons for Extraction Challenges</span><span class="node-badge">p7-7</span></div><div class="tree-node "><div class="node-title keyword" data-node-id="0267" onclick="showNodeDetails('0267')"><span class="node-icon">ï¿½</span><span>accuracy</span><span class="node-badge">p7-7</span></div></div><div class="tree-node "><div class="node-title keyword" data-node-id="0268" onclick="showNodeDetails('0268')"><span class="node-icon">ï¿½</span><span>precision</span><span class="node-badge">p7-7</span></div></div><div class="tree-node "><div class="node-title keyword" data-node-id="0269" onclick="showNodeDetails('0269')"><span class="node-icon">ï¿½</span><span>introductions and conclusions</span><span class="node-badge">p7-7</span></div></div><div class="tree-node "><div class="node-title keyword" data-node-id="0270" onclick="showNodeDetails('0270')"><span class="node-icon">ï¿½</span><span>keywords</span><span class="node-badge">p7-7</span></div></div><div class="tree-node "><div class="node-title keyword" data-node-id="0271" onclick="showNodeDetails('0271')"><span class="node-icon">ï¿½</span><span>rule-based system</span><span class="node-badge">p7-7</span></div></div><div class="tree-node "><div class="node-title keyword" data-node-id="0272" onclick="showNodeDetails('0272')"><span class="node-icon">ï¿½</span><span>extraction challenges</span><span class="node-badge">p7-7</span></div></div></div></div><div class="tree-node "><div class="node-title " data-node-id="0273" onclick="showNodeDetails('0273')"><span class="node-icon">ğŸ“</span><span>Interpretation of &#x27;Abstract&#x27; Extraction</span><span class="node-badge">p7-7</span></div><div class="tree-node "><div class="node-title keyword" data-node-id="0274" onclick="showNodeDetails('0274')"><span class="node-icon">ï¿½</span><span>Abstract extraction</span><span class="node-badge">p7-7</span></div></div><div class="tree-node "><div class="node-title keyword" data-node-id="0275" onclick="showNodeDetails('0275')"><span class="node-icon">ï¿½</span><span>Recall</span><span class="node-badge">p7-7</span></div></div><div class="tree-node "><div class="node-title keyword" data-node-id="0276" onclick="showNodeDetails('0276')"><span class="node-icon">ï¿½</span><span>F-measure</span><span class="node-badge">p7-7</span></div></div><div class="tree-node "><div class="node-title keyword" data-node-id="0277" onclick="showNodeDetails('0277')"><span class="node-icon">ï¿½</span><span>Precision</span><span class="node-badge">p7-7</span></div></div><div class="tree-node "><div class="node-title keyword" data-node-id="0278" onclick="showNodeDetails('0278')"><span class="node-icon">ï¿½</span><span>Accuracy</span><span class="node-badge">p7-7</span></div></div><div class="tree-node "><div class="node-title keyword" data-node-id="0279" onclick="showNodeDetails('0279')"><span class="node-icon">ï¿½</span><span>Theses</span><span class="node-badge">p7-7</span></div></div><div class="tree-node "><div class="node-title keyword" data-node-id="0280" onclick="showNodeDetails('0280')"><span class="node-icon">ï¿½</span><span>Labelled abstract</span><span class="node-badge">p7-7</span></div></div></div><div class="tree-node "><div class="node-title " data-node-id="0281" onclick="showNodeDetails('0281')"><span class="node-icon">ğŸ“</span><span>Interpretation of &#x27;Table of Contents&#x27; Extraction</span><span class="node-badge">p7-7</span></div><div class="tree-node "><div class="node-title keyword" data-node-id="0282" onclick="showNodeDetails('0282')"><span class="node-icon">ï¿½</span><span>Table of Contents extraction</span><span class="node-badge">p7-7</span></div></div><div class="tree-node "><div class="node-title keyword" data-node-id="0283" onclick="showNodeDetails('0283')"><span class="node-icon">ï¿½</span><span>Recall</span><span class="node-badge">p7-7</span></div></div><div class="tree-node "><div class="node-title keyword" data-node-id="0284" onclick="showNodeDetails('0284')"><span class="node-icon">ï¿½</span><span>Precision</span><span class="node-badge">p7-7</span></div></div><div class="tree-node "><div class="node-title keyword" data-node-id="0285" onclick="showNodeDetails('0285')"><span class="node-icon">ï¿½</span><span>F-measure</span><span class="node-badge">p7-7</span></div></div><div class="tree-node "><div class="node-title keyword" data-node-id="0286" onclick="showNodeDetails('0286')"><span class="node-icon">ï¿½</span><span>Accuracy</span><span class="node-badge">p7-7</span></div></div></div><div class="tree-node "><div class="node-title " data-node-id="0287" onclick="showNodeDetails('0287')"><span class="node-icon">ğŸ“</span><span>Interpretation of &#x27;Title&#x27; Extraction</span><span class="node-badge">p7-7</span></div><div class="tree-node "><div class="node-title " data-node-id="0288" onclick="showNodeDetails('0288')"><span class="node-icon">ğŸ“</span><span>Effectiveness of Rule-Based System for Title Extraction</span><span class="node-badge">p7-7</span></div><div class="tree-node "><div class="node-title keyword" data-node-id="0289" onclick="showNodeDetails('0289')"><span class="node-icon">ï¿½</span><span>Title extraction</span><span class="node-badge">p7-7</span></div></div><div class="tree-node "><div class="node-title keyword" data-node-id="0290" onclick="showNodeDetails('0290')"><span class="node-icon">ï¿½</span><span>Rule-based system</span><span class="node-badge">p7-7</span></div></div><div class="tree-node "><div class="node-title keyword" data-node-id="0291" onclick="showNodeDetails('0291')"><span class="node-icon">ï¿½</span><span>Precision</span><span class="node-badge">p7-7</span></div></div><div class="tree-node "><div class="node-title keyword" data-node-id="0292" onclick="showNodeDetails('0292')"><span class="node-icon">ï¿½</span><span>Recall</span><span class="node-badge">p7-7</span></div></div><div class="tree-node "><div class="node-title keyword" data-node-id="0293" onclick="showNodeDetails('0293')"><span class="node-icon">ï¿½</span><span>Accuracy</span><span class="node-badge">p7-7</span></div></div><div class="tree-node "><div class="node-title keyword" data-node-id="0294" onclick="showNodeDetails('0294')"><span class="node-icon">ï¿½</span><span>F-measure</span><span class="node-badge">p7-7</span></div></div><div class="tree-node "><div class="node-title keyword" data-node-id="0295" onclick="showNodeDetails('0295')"><span class="node-icon">ï¿½</span><span>Unlabelled titles</span><span class="node-badge">p7-7</span></div></div></div><div class="tree-node "><div class="node-title " data-node-id="0296" onclick="showNodeDetails('0296')"><span class="node-icon">ğŸ“</span><span>Relevance of Mis-extracted Information</span><span class="node-badge">p7-7</span></div><div class="tree-node "><div class="node-title keyword" data-node-id="0297" onclick="showNodeDetails('0297')"><span class="node-icon">ï¿½</span><span>wrongly extracted cases</span><span class="node-badge">p7-7</span></div></div><div class="tree-node "><div class="node-title keyword" data-node-id="0298" onclick="showNodeDetails('0298')"><span class="node-icon">ï¿½</span><span>extracted information</span><span class="node-badge">p7-7</span></div></div><div class="tree-node "><div class="node-title keyword" data-node-id="0299" onclick="showNodeDetails('0299')"><span class="node-icon">ï¿½</span><span>authors&#x27; names</span><span class="node-badge">p7-7</span></div></div><div class="tree-node "><div class="node-title keyword" data-node-id="0300" onclick="showNodeDetails('0300')"><span class="node-icon">ï¿½</span><span>institution of study</span><span class="node-badge">p7-7</span></div></div></div></div><div class="tree-node "><div class="node-title " data-node-id="0301" onclick="showNodeDetails('0301')"><span class="node-icon">ğŸ“</span><span>Comparison with Hu et al. [10]</span><span class="node-badge">p7-7</span></div><div class="tree-node "><div class="node-title keyword" data-node-id="0302" onclick="showNodeDetails('0302')"><span class="node-icon">ï¿½</span><span>Hu et al. [10]</span><span class="node-badge">p7-7</span></div></div><div class="tree-node "><div class="node-title keyword" data-node-id="0303" onclick="showNodeDetails('0303')"><span class="node-icon">ï¿½</span><span>title extraction</span><span class="node-badge">p7-7</span></div></div><div class="tree-node "><div class="node-title keyword" data-node-id="0304" onclick="showNodeDetails('0304')"><span class="node-icon">ï¿½</span><span>Word documents</span><span class="node-badge">p7-7</span></div></div><div class="tree-node "><div class="node-title keyword" data-node-id="0305" onclick="showNodeDetails('0305')"><span class="node-icon">ï¿½</span><span>PowerPoint documents</span><span class="node-badge">p7-7</span></div></div><div class="tree-node "><div class="node-title keyword" data-node-id="0306" onclick="showNodeDetails('0306')"><span class="node-icon">ï¿½</span><span>precision</span><span class="node-badge">p7-7</span></div></div><div class="tree-node "><div class="node-title keyword" data-node-id="0307" onclick="showNodeDetails('0307')"><span class="node-icon">ï¿½</span><span>recall</span><span class="node-badge">p7-7</span></div></div><div class="tree-node "><div class="node-title keyword" data-node-id="0308" onclick="showNodeDetails('0308')"><span class="node-icon">ï¿½</span><span>intranet data</span><span class="node-badge">p7-7</span></div></div><div class="tree-node "><div class="node-title keyword" data-node-id="0309" onclick="showNodeDetails('0309')"><span class="node-icon">ï¿½</span><span>machine learning technique</span><span class="node-badge">p7-7</span></div></div></div><div class="tree-node "><div class="node-title " data-node-id="0310" onclick="showNodeDetails('0310')"><span class="node-icon">ğŸ“</span><span>Comparison with Berkowitz and Elkhadiri [17] and Giuffrida et al. [14]</span><span class="node-badge">p7-7</span></div><div class="tree-node "><div class="node-title keyword" data-node-id="0311" onclick="showNodeDetails('0311')"><span class="node-icon">ï¿½</span><span>Berkowitz and Elkhadiri [17]</span><span class="node-badge">p7-7</span></div></div><div class="tree-node "><div class="node-title keyword" data-node-id="0312" onclick="showNodeDetails('0312')"><span class="node-icon">ï¿½</span><span>author name extraction</span><span class="node-badge">p7-7</span></div></div><div class="tree-node "><div class="node-title keyword" data-node-id="0313" onclick="showNodeDetails('0313')"><span class="node-icon">ï¿½</span><span>Giuffrida et al. [14]</span><span class="node-badge">p7-7</span></div></div><div class="tree-node "><div class="node-title keyword" data-node-id="0314" onclick="showNodeDetails('0314')"><span class="node-icon">ï¿½</span><span>knowledge-based approach</span><span class="node-badge">p7-7</span></div></div><div class="tree-node "><div class="node-title keyword" data-node-id="0315" onclick="showNodeDetails('0315')"><span class="node-icon">ï¿½</span><span>general documents metadata extraction</span><span class="node-badge">p7-7</span></div></div><div class="tree-node "><div class="node-title keyword" data-node-id="0316" onclick="showNodeDetails('0316')"><span class="node-icon">ï¿½</span><span>theses metadata extraction</span><span class="node-badge">p7-7</span></div></div></div><div class="tree-node "><div class="node-title " data-node-id="0317" onclick="showNodeDetails('0317')"><span class="node-icon">ğŸ“</span><span>Conclusions and Future Research Directions</span><span class="node-badge">p7-7</span></div><div class="tree-node "><div class="node-title keyword" data-node-id="0318" onclick="showNodeDetails('0318')"><span class="node-icon">ï¿½</span><span>metadata extraction</span><span class="node-badge">p7-7</span></div></div><div class="tree-node "><div class="node-title keyword" data-node-id="0319" onclick="showNodeDetails('0319')"><span class="node-icon">ï¿½</span><span>segmentation by keyword algorithm</span><span class="node-badge">p7-7</span></div></div><div class="tree-node "><div class="node-title keyword" data-node-id="0320" onclick="showNodeDetails('0320')"><span class="node-icon">ï¿½</span><span>regular expressions</span><span class="node-badge">p7-7</span></div></div><div class="tree-node "><div class="node-title keyword" data-node-id="0321" onclick="showNodeDetails('0321')"><span class="node-icon">ï¿½</span><span>title extraction</span><span class="node-badge">p7-7</span></div></div><div class="tree-node "><div class="node-title keyword" data-node-id="0322" onclick="showNodeDetails('0322')"><span class="node-icon">ï¿½</span><span>theses and dissertations</span><span class="node-badge">p7-7</span></div></div><div class="tree-node "><div class="node-title keyword" data-node-id="0323" onclick="showNodeDetails('0323')"><span class="node-icon">ï¿½</span><span>Abstract, Preface, Table of Contents, Introduction, Conclusion, References, Acknowledgments</span><span class="node-badge">p7-7</span></div></div><div class="tree-node "><div class="node-title keyword" data-node-id="0324" onclick="showNodeDetails('0324')"><span class="node-icon">ï¿½</span><span>precision, recall, and accuracy</span><span class="node-badge">p7-7</span></div></div><div class="tree-node "><div class="node-title keyword" data-node-id="0325" onclick="showNodeDetails('0325')"><span class="node-icon">ï¿½</span><span>low recall</span><span class="node-badge">p7-7</span></div></div></div></div></div><div class="tree-node root"><div class="node-title " data-node-id="0326" onclick="showNodeDetails('0326')"><span class="node-icon">ğŸ“„</span><span>Conclusions and further research directions</span><span class="node-badge">p7-8</span></div></div><div class="tree-node root"><div class="node-title " data-node-id="0327" onclick="showNodeDetails('0327')"><span class="node-icon">ğŸ“„</span><span>References</span><span class="node-badge">p8-8</span></div><div class="tree-node "><div class="node-title " data-node-id="0328" onclick="showNodeDetails('0328')"><span class="node-icon">ğŸ“</span><span>Authors and Publication Details</span><span class="node-badge">p8-8</span></div><div class="tree-node "><div class="node-title " data-node-id="0329" onclick="showNodeDetails('0329')"><span class="node-icon">ğŸ“</span><span>Citation and Metadata Extraction Discussion</span><span class="node-badge">p8-8</span></div><div class="tree-node "><div class="node-title keyword" data-node-id="0330" onclick="showNodeDetails('0330')"><span class="node-icon">ï¿½</span><span>metadata extraction</span><span class="node-badge">p8-8</span></div></div><div class="tree-node "><div class="node-title keyword" data-node-id="0331" onclick="showNodeDetails('0331')"><span class="node-icon">ï¿½</span><span>rule-based system</span><span class="node-badge">p8-8</span></div></div><div class="tree-node "><div class="node-title keyword" data-node-id="0332" onclick="showNodeDetails('0332')"><span class="node-icon">ï¿½</span><span>refinement over time</span><span class="node-badge">p8-8</span></div></div><div class="tree-node "><div class="node-title keyword" data-node-id="0333" onclick="showNodeDetails('0333')"><span class="node-icon">ï¿½</span><span>keywords</span><span class="node-badge">p8-8</span></div></div><div class="tree-node "><div class="node-title keyword" data-node-id="0334" onclick="showNodeDetails('0334')"><span class="node-icon">ï¿½</span><span>different types of documents</span><span class="node-badge">p8-8</span></div></div></div></div><div class="tree-node "><div class="node-title " data-node-id="0335" onclick="showNodeDetails('0335')"><span class="node-icon">ğŸ“</span><span>References</span><span class="node-badge">p8-8</span></div><div class="tree-node "><div class="node-title " data-node-id="0336" onclick="showNodeDetails('0336')"><span class="node-icon">ğŸ“</span><span>References</span><span class="node-badge">p8-8</span></div><div class="tree-node "><div class="node-title " data-node-id="0337" onclick="showNodeDetails('0337')"><span class="node-icon">ğŸ“</span><span>References</span><span class="node-badge">p8-8</span></div><div class="tree-node "><div class="node-title keyword" data-node-id="0338" onclick="showNodeDetails('0338')"><span class="node-icon">ï¿½</span><span>Logical document structure</span><span class="node-badge">p8-8</span></div></div><div class="tree-node "><div class="node-title keyword" data-node-id="0339" onclick="showNodeDetails('0339')"><span class="node-icon">ï¿½</span><span>Extracting structured data</span><span class="node-badge">p8-8</span></div></div><div class="tree-node "><div class="node-title keyword" data-node-id="0340" onclick="showNodeDetails('0340')"><span class="node-icon">ï¿½</span><span>Metadata extraction</span><span class="node-badge">p8-8</span></div></div><div class="tree-node "><div class="node-title keyword" data-node-id="0341" onclick="showNodeDetails('0341')"><span class="node-icon">ï¿½</span><span>Support vector machine</span><span class="node-badge">p8-8</span></div></div><div class="tree-node "><div class="node-title keyword" data-node-id="0342" onclick="showNodeDetails('0342')"><span class="node-icon">ï¿½</span><span>Information extraction</span><span class="node-badge">p8-8</span></div></div><div class="tree-node "><div class="node-title keyword" data-node-id="0343" onclick="showNodeDetails('0343')"><span class="node-icon">ï¿½</span><span>Digital library documents</span><span class="node-badge">p8-8</span></div></div><div class="tree-node "><div class="node-title keyword" data-node-id="0344" onclick="showNodeDetails('0344')"><span class="node-icon">ï¿½</span><span>NLP system</span><span class="node-badge">p8-8</span></div></div><div class="tree-node "><div class="node-title keyword" data-node-id="0345" onclick="showNodeDetails('0345')"><span class="node-icon">ï¿½</span><span>Feature generation</span><span class="node-badge">p8-8</span></div></div><div class="tree-node "><div class="node-title keyword" data-node-id="0346" onclick="showNodeDetails('0346')"><span class="node-icon">ï¿½</span><span>Conditional random fields</span><span class="node-badge">p8-8</span></div></div><div class="tree-node "><div class="node-title keyword" data-node-id="0347" onclick="showNodeDetails('0347')"><span class="node-icon">ï¿½</span><span>Hidden Markov models</span><span class="node-badge">p8-8</span></div></div><div class="tree-node "><div class="node-title keyword" data-node-id="0348" onclick="showNodeDetails('0348')"><span class="node-icon">ï¿½</span><span>Knowledge-based extraction</span><span class="node-badge">p8-8</span></div></div><div class="tree-node "><div class="node-title keyword" data-node-id="0349" onclick="showNodeDetails('0349')"><span class="node-icon">ï¿½</span><span>Bibliographic metadata</span><span class="node-badge">p8-8</span></div></div></div></div></div></div>
        </div>
        
        <div class="content" id="content">
            <div class="empty-state">
                ğŸ‘ˆ Select a node from the tree to view its details
            </div>
        </div>
    </div>
    
    <script>
        const nodeData = [{"title": "Automated document metadata extraction", "start_index": 1, "end_index": 1, "nodes": [{"title": "Document Metadata Extraction Model", "start_index": 1, "end_index": 1, "text": "Web documents are available in various forms, most of which do not carry additional semantics. This paper\n\npresents a model for general document metadata extraction. The model, which combines segmentation by keywords and pattern matching techniques, was implemented using PHP , MySQL, JavaScript and HTML.\n\nThe system was tested with 40 randomly selected PDF documents (mainly theses). An evaluation of the sys-\n\ntem was done using standard criteria measures namely precision, recall, accuracy and F-measure. The\n\nresults show that the model is relatively effective for the task of metadata extraction, especially for theses and dissertations. A combination of machine learning with these rule-based methods will be explored in the\n\nfuture for better results.", "summary": "This section describes the model for general document metadata extraction, which combines segmentation by keywords and pattern matching techniques. It was implemented using PHP, MySQL, JavaScript, and HTML, and evaluated using precision, recall, accuracy, and F-measure.", "node_type": "semantic_unit", "metadata": {"semantic_type": "procedure", "start_paragraph": 7, "end_paragraph": 12, "original_title": "Document Metadata Extraction Model"}, "nodes": [{"title": "Document Metadata Extraction Model", "start_index": 1, "end_index": 1, "text": "Web documents are available in various forms, most of which do not carry additional semantics. This paper\n\npresents a model for general document metadata extraction. The model, which combines segmentation by keywords and pattern matching techniques, was implemented using PHP , MySQL, JavaScript and HTML.", "summary": "Presents a model for general document metadata extraction using segmentation by keywords and pattern matching techniques. The model was implemented using PHP, MySQL, JavaScript, and HTML.", "node_type": "semantic_unit", "metadata": {"semantic_type": "experimental_setup", "start_paragraph": 0, "end_paragraph": 1, "original_title": "Document Metadata Extraction Model"}, "nodes": [{"title": "Document Metadata Extraction", "start_index": 1, "end_index": 1, "text": "Web documents are available in various forms, most of which do not carry additional semantics. This paper\n\npresents a model for general document metadata extraction. The model, which combines segmentation by keywords and pattern matching techniques, was implemented using PHP , MySQL, JavaScript and HTML.", "summary": "The process of identifying and extracting meaningful information from documents.", "node_type": "keyword", "_text_locked": true, "metadata": {"term": "Document Metadata Extraction", "context": "The process of identifying and extracting meaningful information from documents.", "relevance": "This is the core task the model presented in the section aims to achieve.", "parent_title": "Document Metadata Extraction Model", "parent_node_type": "semantic_unit"}, "nodes": [], "node_id": "0003"}, {"title": "Web Documents", "start_index": 1, "end_index": 1, "text": "Web documents are available in various forms, most of which do not carry additional semantics. This paper\n\npresents a model for general document metadata extraction. The model, which combines segmentation by keywords and pattern matching techniques, was implemented using PHP , MySQL, JavaScript and HTML.", "summary": "Documents that are accessible via the World Wide Web.", "node_type": "keyword", "_text_locked": true, "metadata": {"term": "Web Documents", "context": "Documents that are accessible via the World Wide Web.", "relevance": "These are the primary data sources the extraction model is designed to process.", "parent_title": "Document Metadata Extraction Model", "parent_node_type": "semantic_unit"}, "nodes": [], "node_id": "0004"}, {"title": "Additional Semantics", "start_index": 1, "end_index": 1, "text": "Web documents are available in various forms, most of which do not carry additional semantics. This paper\n\npresents a model for general document metadata extraction. The model, which combines segmentation by keywords and pattern matching techniques, was implemented using PHP , MySQL, JavaScript and HTML.", "summary": "Extra layers of meaning or structured information beyond the basic content of a document.", "node_type": "keyword", "_text_locked": true, "metadata": {"term": "Additional Semantics", "context": "Extra layers of meaning or structured information beyond the basic content of a document.", "relevance": "The lack of this in web documents highlights the need for the proposed extraction model.", "parent_title": "Document Metadata Extraction Model", "parent_node_type": "semantic_unit"}, "nodes": [], "node_id": "0005"}, {"title": "Segmentation by Keywords", "start_index": 1, "end_index": 1, "text": "Web documents are available in various forms, most of which do not carry additional semantics. This paper\n\npresents a model for general document metadata extraction. The model, which combines segmentation by keywords and pattern matching techniques, was implemented using PHP , MySQL, JavaScript and HTML.", "summary": "A technique used to divide a document into sections based on the presence of specific keywords.", "node_type": "keyword", "_text_locked": true, "metadata": {"term": "Segmentation by Keywords", "context": "A technique used to divide a document into sections based on the presence of specific keywords.", "relevance": "This is one of the key methodologies employed by the document metadata extraction model.", "parent_title": "Document Metadata Extraction Model", "parent_node_type": "semantic_unit"}, "nodes": [], "node_id": "0006"}, {"title": "Pattern Matching", "start_index": 1, "end_index": 1, "text": "Web documents are available in various forms, most of which do not carry additional semantics. This paper\n\npresents a model for general document metadata extraction. The model, which combines segmentation by keywords and pattern matching techniques, was implemented using PHP , MySQL, JavaScript and HTML.", "summary": "A technique for identifying specific sequences of characters or data within a larger body of text.", "node_type": "keyword", "_text_locked": true, "metadata": {"term": "Pattern Matching", "context": "A technique for identifying specific sequences of characters or data within a larger body of text.", "relevance": "This is the other primary technique used in conjunction with keyword segmentation for extraction.", "parent_title": "Document Metadata Extraction Model", "parent_node_type": "semantic_unit"}, "nodes": [], "node_id": "0007"}, {"title": "PHP", "start_index": 1, "end_index": 1, "text": "Web documents are available in various forms, most of which do not carry additional semantics. This paper\n\npresents a model for general document metadata extraction. The model, which combines segmentation by keywords and pattern matching techniques, was implemented using PHP , MySQL, JavaScript and HTML.", "summary": "A widely used open-source general-purpose scripting language that is especially suited for web development.", "node_type": "keyword", "_text_locked": true, "metadata": {"term": "PHP", "context": "A widely used open-source general-purpose scripting language that is especially suited for web development.", "relevance": "This is one of the programming languages used in the implementation of the extraction model.", "parent_title": "Document Metadata Extraction Model", "parent_node_type": "semantic_unit"}, "nodes": [], "node_id": "0008"}, {"title": "MySQL", "start_index": 1, "end_index": 1, "text": "Web documents are available in various forms, most of which do not carry additional semantics. This paper\n\npresents a model for general document metadata extraction. The model, which combines segmentation by keywords and pattern matching techniques, was implemented using PHP , MySQL, JavaScript and HTML.", "summary": "An open-source relational database management system.", "node_type": "keyword", "_text_locked": true, "metadata": {"term": "MySQL", "context": "An open-source relational database management system.", "relevance": "This is the database technology used in the implementation of the extraction model.", "parent_title": "Document Metadata Extraction Model", "parent_node_type": "semantic_unit"}, "nodes": [], "node_id": "0009"}, {"title": "JavaScript", "start_index": 1, "end_index": 1, "text": "Web documents are available in various forms, most of which do not carry additional semantics. This paper\n\npresents a model for general document metadata extraction. The model, which combines segmentation by keywords and pattern matching techniques, was implemented using PHP , MySQL, JavaScript and HTML.", "summary": "A programming language that is one of the core technologies of the World Wide Web.", "node_type": "keyword", "_text_locked": true, "metadata": {"term": "JavaScript", "context": "A programming language that is one of the core technologies of the World Wide Web.", "relevance": "This is one of the programming languages used in the implementation of the extraction model.", "parent_title": "Document Metadata Extraction Model", "parent_node_type": "semantic_unit"}, "nodes": [], "node_id": "0010"}, {"title": "HTML", "start_index": 1, "end_index": 1, "text": "Web documents are available in various forms, most of which do not carry additional semantics. This paper\n\npresents a model for general document metadata extraction. The model, which combines segmentation by keywords and pattern matching techniques, was implemented using PHP , MySQL, JavaScript and HTML.", "summary": "The standard markup language for documents designed to be displayed in a web browser.", "node_type": "keyword", "_text_locked": true, "metadata": {"term": "HTML", "context": "The standard markup language for documents designed to be displayed in a web browser.", "relevance": "This is a core web technology used in the implementation of the extraction model.", "parent_title": "Document Metadata Extraction Model", "parent_node_type": "semantic_unit"}, "nodes": [], "node_id": "0011"}], "node_id": "0002"}, {"title": "System Testing and Evaluation", "start_index": 1, "end_index": 1, "text": "The system was tested with 40 randomly selected PDF documents (mainly theses). An evaluation of the sys-\n\ntem was done using standard criteria measures namely precision, recall, accuracy and F-measure. The", "summary": "The system was tested with 40 randomly selected PDF documents, primarily theses. Evaluation was performed using standard criteria measures: precision, recall, accuracy, and F-measure.", "node_type": "semantic_unit", "metadata": {"semantic_type": "characterization", "start_paragraph": 2, "end_paragraph": 3, "original_title": "System Testing and Evaluation"}, "nodes": [{"title": "System Testing", "start_index": 1, "end_index": 1, "text": "The system was tested with 40 randomly selected PDF documents (mainly theses). An evaluation of the sys-\n\ntem was done using standard criteria measures namely precision, recall, accuracy and F-measure. The", "summary": "The process of evaluating a system to determine if it meets specified requirements.", "node_type": "keyword", "_text_locked": true, "metadata": {"term": "System Testing", "context": "The process of evaluating a system to determine if it meets specified requirements.", "relevance": "This is the main subject of the section, defining the scope of the evaluation.", "parent_title": "System Testing and Evaluation", "parent_node_type": "semantic_unit"}, "nodes": [], "node_id": "0013"}, {"title": "Evaluation Criteria", "start_index": 1, "end_index": 1, "text": "The system was tested with 40 randomly selected PDF documents (mainly theses). An evaluation of the sys-\n\ntem was done using standard criteria measures namely precision, recall, accuracy and F-measure. The", "summary": "Standard measures used to assess the performance of a system.", "node_type": "keyword", "_text_locked": true, "metadata": {"term": "Evaluation Criteria", "context": "Standard measures used to assess the performance of a system.", "relevance": "These are the specific metrics by which the system's effectiveness is judged.", "parent_title": "System Testing and Evaluation", "parent_node_type": "semantic_unit"}, "nodes": [], "node_id": "0014"}, {"title": "Precision", "start_index": 1, "end_index": 1, "text": "The system was tested with 40 randomly selected PDF documents (mainly theses). An evaluation of the sys-\n\ntem was done using standard criteria measures namely precision, recall, accuracy and F-measure. The", "summary": "A measure of how many of the retrieved items are relevant.", "node_type": "keyword", "_text_locked": true, "metadata": {"term": "Precision", "context": "A measure of how many of the retrieved items are relevant.", "relevance": "It is a key metric used to evaluate the accuracy of the system's output.", "parent_title": "System Testing and Evaluation", "parent_node_type": "semantic_unit"}, "nodes": [], "node_id": "0015"}, {"title": "Recall", "start_index": 1, "end_index": 1, "text": "The system was tested with 40 randomly selected PDF documents (mainly theses). An evaluation of the sys-\n\ntem was done using standard criteria measures namely precision, recall, accuracy and F-measure. The", "summary": "A measure of how many of the relevant items were successfully retrieved.", "node_type": "keyword", "_text_locked": true, "metadata": {"term": "Recall", "context": "A measure of how many of the relevant items were successfully retrieved.", "relevance": "It is a key metric used to evaluate the completeness of the system's output.", "parent_title": "System Testing and Evaluation", "parent_node_type": "semantic_unit"}, "nodes": [], "node_id": "0016"}, {"title": "Accuracy", "start_index": 1, "end_index": 1, "text": "The system was tested with 40 randomly selected PDF documents (mainly theses). An evaluation of the sys-\n\ntem was done using standard criteria measures namely precision, recall, accuracy and F-measure. The", "summary": "The overall correctness of the system's predictions or classifications.", "node_type": "keyword", "_text_locked": true, "metadata": {"term": "Accuracy", "context": "The overall correctness of the system's predictions or classifications.", "relevance": "It provides a general measure of the system's performance across all cases.", "parent_title": "System Testing and Evaluation", "parent_node_type": "semantic_unit"}, "nodes": [], "node_id": "0017"}, {"title": "F-measure", "start_index": 1, "end_index": 1, "text": "The system was tested with 40 randomly selected PDF documents (mainly theses). An evaluation of the sys-\n\ntem was done using standard criteria measures namely precision, recall, accuracy and F-measure. The", "summary": "The harmonic mean of precision and recall, providing a single score for performance.", "node_type": "keyword", "_text_locked": true, "metadata": {"term": "F-measure", "context": "The harmonic mean of precision and recall, providing a single score for performance.", "relevance": "It offers a balanced evaluation of the system by combining precision and recall.", "parent_title": "System Testing and Evaluation", "parent_node_type": "semantic_unit"}, "nodes": [], "node_id": "0018"}, {"title": "PDF Documents", "start_index": 1, "end_index": 1, "text": "The system was tested with 40 randomly selected PDF documents (mainly theses). An evaluation of the sys-\n\ntem was done using standard criteria measures namely precision, recall, accuracy and F-measure. The", "summary": "The type of input data used for testing the system, specifically theses.", "node_type": "keyword", "_text_locked": true, "metadata": {"term": "PDF Documents", "context": "The type of input data used for testing the system, specifically theses.", "relevance": "This specifies the nature of the data on which the system's performance was assessed.", "parent_title": "System Testing and Evaluation", "parent_node_type": "semantic_unit"}, "nodes": [], "node_id": "0019"}, {"title": "Randomly Selected", "start_index": 1, "end_index": 1, "text": "The system was tested with 40 randomly selected PDF documents (mainly theses). An evaluation of the sys-\n\ntem was done using standard criteria measures namely precision, recall, accuracy and F-measure. The", "summary": "Indicates that the test documents were chosen without bias from the available set.", "node_type": "keyword", "_text_locked": true, "metadata": {"term": "Randomly Selected", "context": "Indicates that the test documents were chosen without bias from the available set.", "relevance": "This describes the methodology for selecting the test data, ensuring a representative sample.", "parent_title": "System Testing and Evaluation", "parent_node_type": "semantic_unit"}, "nodes": [], "node_id": "0020"}], "node_id": "0012"}, {"title": "Results and Future Work", "start_index": 1, "end_index": 1, "text": "results show that the model is relatively effective for the task of metadata extraction, especially for theses and dissertations. A combination of machine learning with these rule-based methods will be explored in the\n\nfuture for better results.", "summary": "The results indicate the model's effectiveness for metadata extraction, particularly for theses and dissertations. Future work will explore combining machine learning with rule-based methods for improved outcomes.", "node_type": "semantic_unit", "metadata": {"semantic_type": "analysis", "start_paragraph": 4, "end_paragraph": 5, "original_title": "Results and Future Work"}, "nodes": [{"title": "metadata extraction", "start_index": 1, "end_index": 1, "text": "results show that the model is relatively effective for the task of metadata extraction, especially for theses and dissertations. A combination of machine learning with these rule-based methods will be explored in the\n\nfuture for better results.", "summary": "The process of automatically identifying and extracting descriptive information from data.", "node_type": "keyword", "_text_locked": true, "metadata": {"term": "metadata extraction", "context": "The process of automatically identifying and extracting descriptive information from data.", "relevance": "This is the core task the model is evaluated on in this section.", "parent_title": "Results and Future Work", "parent_node_type": "semantic_unit"}, "nodes": [], "node_id": "0022"}, {"title": "theses and dissertations", "start_index": 1, "end_index": 1, "text": "results show that the model is relatively effective for the task of metadata extraction, especially for theses and dissertations. A combination of machine learning with these rule-based methods will be explored in the\n\nfuture for better results.", "summary": "Academic documents that represent significant research work.", "node_type": "keyword", "_text_locked": true, "metadata": {"term": "theses and dissertations", "context": "Academic documents that represent significant research work.", "relevance": "These document types are specifically highlighted as areas where the model performs well.", "parent_title": "Results and Future Work", "parent_node_type": "semantic_unit"}, "nodes": [], "node_id": "0023"}, {"title": "machine learning", "start_index": 1, "end_index": 1, "text": "results show that the model is relatively effective for the task of metadata extraction, especially for theses and dissertations. A combination of machine learning with these rule-based methods will be explored in the\n\nfuture for better results.", "summary": "A type of artificial intelligence that allows systems to learn from data without explicit programming.", "node_type": "keyword", "_text_locked": true, "metadata": {"term": "machine learning", "context": "A type of artificial intelligence that allows systems to learn from data without explicit programming.", "relevance": "One of the methodologies that will be explored further for improved results.", "parent_title": "Results and Future Work", "parent_node_type": "semantic_unit"}, "nodes": [], "node_id": "0024"}, {"title": "rule-based methods", "start_index": 1, "end_index": 1, "text": "results show that the model is relatively effective for the task of metadata extraction, especially for theses and dissertations. A combination of machine learning with these rule-based methods will be explored in the\n\nfuture for better results.", "summary": "Approaches that use predefined rules to process information or make decisions.", "node_type": "keyword", "_text_locked": true, "metadata": {"term": "rule-based methods", "context": "Approaches that use predefined rules to process information or make decisions.", "relevance": "A current methodology that, when combined with machine learning, is expected to yield better outcomes.", "parent_title": "Results and Future Work", "parent_node_type": "semantic_unit"}, "nodes": [], "node_id": "0025"}], "node_id": "0021"}], "node_id": "0001"}, {"title": "Keywords", "start_index": 1, "end_index": 1, "text": "Keywords: keywords; metadata; rules; segmentation; theses", "summary": "Lists the keywords associated with the document: keywords, metadata, rules, segmentation, theses.", "node_type": "semantic_unit", "metadata": {"semantic_type": "materials", "start_paragraph": 13, "end_paragraph": 13, "original_title": "Keywords"}, "nodes": [], "node_id": "0026"}, {"title": "Introduction to Automated Document Structure Extraction", "start_index": 1, "end_index": 1, "text": "The availability of large, web accessible, heterogeneous repositories of electronic documents is\n\nincreasing rapidly [1]. Most of this information is in the form of unstructured text, making the infor -\n\nmation hard to query [2]. Defining metadata for such documents will be useful for searching, brows-ing, and filtering. Ideally, metadata is defined by the authors of documents and is then used by various systems. However, people seldom define document metadata by themselves, even when they have convenient metadata definition tools [3]. Hence, automatically extracting metadata from the bodies of documents is an important research issue.\n\nAutomated document structure extraction has a number of benefits. Firstly, it makes automated\n\nmark-up possible. This helps to preserve information which might be required from the docu -\n\nment in the future. In addition, documents with logical structure can be presented differently for different devices. This flexibility in presentation is very useful to handle different devices. For example, a document can be presented differently in a PDA and in a web browser. Keeping docu -\n\nment logical structure also allows different users to have different access to a document. Some users may have unlimited access to a document while other users may have some limitations, for example, a textbook in which a professor has access to the answers as well as questions and a\n\nCorrespondence to: Bolanle Adefowoke Ojokoh, Department of Computer Science, P.M.B. 704, Akure,\n\nNigeria. Email: bolanleojokoh@yahoo.com", "summary": "This section introduces the problem of increasing web document repositories and the difficulty in querying unstructured text. It highlights the benefits of automated document structure extraction, such as automated mark-up, preservation of information, and flexible presentation for different devices and users.", "node_type": "semantic_unit", "metadata": {"semantic_type": "procedure", "start_paragraph": 15, "end_paragraph": 23, "original_title": "Introduction to Automated Document Structure Extraction"}, "nodes": [{"title": "Motivation: The Need for Automated Metadata Extraction", "start_index": 1, "end_index": 1, "text": "The availability of large, web accessible, heterogeneous repositories of electronic documents is\n\nincreasing rapidly [1]. Most of this information is in the form of unstructured text, making the infor -\n\nmation hard to query [2]. Defining metadata for such documents will be useful for searching, brows-ing, and filtering. Ideally, metadata is defined by the authors of documents and is then used by various systems. However, people seldom define document metadata by themselves, even when they have convenient metadata definition tools [3]. Hence, automatically extracting metadata from the bodies of documents is an important research issue.", "summary": "Highlights the rapid growth of unstructured electronic documents and the difficulty in querying them. It emphasizes the importance of automated metadata extraction due to the reluctance of users to define metadata manually.", "node_type": "semantic_unit", "metadata": {"semantic_type": "motivation", "start_paragraph": 0, "end_paragraph": 2, "original_title": "Motivation: The Need for Automated Metadata Extraction"}, "nodes": [{"title": "Motivation for Automatic Metadata Extraction", "start_index": 1, "end_index": 1, "text": "The availability of large, web accessible, heterogeneous repositories of electronic documents is\n\nincreasing rapidly [1]. Most of this information is in the form of unstructured text, making the infor -\n\nmation hard to query [2]. Defining metadata for such documents will be useful for searching, brows-ing, and filtering. Ideally, metadata is defined by the authors of documents and is then used by various systems. However, people seldom define document metadata by themselves, even when they have convenient metadata definition tools [3]. Hence, automatically extracting metadata from the bodies of documents is an important research issue.", "summary": "Highlights the rapid growth of unstructured electronic documents and the difficulty in querying them. It emphasizes the need for automatic metadata extraction due to the reluctance of users to define metadata manually.", "node_type": "semantic_unit", "metadata": {"semantic_type": "motivation", "start_paragraph": 0, "end_paragraph": 2, "original_title": "Motivation for Automatic Metadata Extraction"}, "nodes": [{"title": "Heterogeneous repositories", "start_index": 1, "end_index": 1, "text": "The availability of large, web accessible, heterogeneous repositories of electronic documents is\n\nincreasing rapidly [1]. Most of this information is in the form of unstructured text, making the infor -\n\nmation hard to query [2]. Defining metadata for such documents will be useful for searching, brows-ing, and filtering. Ideally, metadata is defined by the authors of documents and is then used by various systems. However, people seldom define document metadata by themselves, even when they have convenient metadata definition tools [3]. Hence, automatically extracting metadata from the bodies of documents is an important research issue.", "summary": "Collections of electronic documents that are diverse and accessible via the web.", "node_type": "keyword", "_text_locked": true, "metadata": {"term": "Heterogeneous repositories", "context": "Collections of electronic documents that are diverse and accessible via the web.", "relevance": "This highlights the scale and complexity of the data landscape that necessitates metadata.", "parent_title": "Motivation for Automatic Metadata Extraction", "parent_node_type": "semantic_unit"}, "nodes": [], "node_id": "0030"}, {"title": "Unstructured text", "start_index": 1, "end_index": 1, "text": "The availability of large, web accessible, heterogeneous repositories of electronic documents is\n\nincreasing rapidly [1]. Most of this information is in the form of unstructured text, making the infor -\n\nmation hard to query [2]. Defining metadata for such documents will be useful for searching, brows-ing, and filtering. Ideally, metadata is defined by the authors of documents and is then used by various systems. However, people seldom define document metadata by themselves, even when they have convenient metadata definition tools [3]. Hence, automatically extracting metadata from the bodies of documents is an important research issue.", "summary": "Information that does not have a predefined data model or is not organized in a pre-defined manner.", "node_type": "keyword", "_text_locked": true, "metadata": {"term": "Unstructured text", "context": "Information that does not have a predefined data model or is not organized in a pre-defined manner.", "relevance": "This is the primary challenge that makes information hard to query and necessitates metadata extraction.", "parent_title": "Motivation for Automatic Metadata Extraction", "parent_node_type": "semantic_unit"}, "nodes": [], "node_id": "0031"}, {"title": "Document metadata", "start_index": 1, "end_index": 1, "text": "The availability of large, web accessible, heterogeneous repositories of electronic documents is\n\nincreasing rapidly [1]. Most of this information is in the form of unstructured text, making the infor -\n\nmation hard to query [2]. Defining metadata for such documents will be useful for searching, brows-ing, and filtering. Ideally, metadata is defined by the authors of documents and is then used by various systems. However, people seldom define document metadata by themselves, even when they have convenient metadata definition tools [3]. Hence, automatically extracting metadata from the bodies of documents is an important research issue.", "summary": "Data that describes other data, in this case, information about electronic documents.", "node_type": "keyword", "_text_locked": true, "metadata": {"term": "Document metadata", "context": "Data that describes other data, in this case, information about electronic documents.", "relevance": "This is the target information that the section aims to define and extract for improved document management.", "parent_title": "Motivation for Automatic Metadata Extraction", "parent_node_type": "semantic_unit"}, "nodes": [], "node_id": "0032"}, {"title": "Searching, browsing, and filtering", "start_index": 1, "end_index": 1, "text": "The availability of large, web accessible, heterogeneous repositories of electronic documents is\n\nincreasing rapidly [1]. Most of this information is in the form of unstructured text, making the infor -\n\nmation hard to query [2]. Defining metadata for such documents will be useful for searching, brows-ing, and filtering. Ideally, metadata is defined by the authors of documents and is then used by various systems. However, people seldom define document metadata by themselves, even when they have convenient metadata definition tools [3]. Hence, automatically extracting metadata from the bodies of documents is an important research issue.", "summary": "Key operations for information retrieval and management that are facilitated by metadata.", "node_type": "keyword", "_text_locked": true, "metadata": {"term": "Searching, browsing, and filtering", "context": "Key operations for information retrieval and management that are facilitated by metadata.", "relevance": "These are the primary use cases that demonstrate the utility of metadata.", "parent_title": "Motivation for Automatic Metadata Extraction", "parent_node_type": "semantic_unit"}, "nodes": [], "node_id": "0033"}, {"title": "Automatic metadata extraction", "start_index": 1, "end_index": 1, "text": "The availability of large, web accessible, heterogeneous repositories of electronic documents is\n\nincreasing rapidly [1]. Most of this information is in the form of unstructured text, making the infor -\n\nmation hard to query [2]. Defining metadata for such documents will be useful for searching, brows-ing, and filtering. Ideally, metadata is defined by the authors of documents and is then used by various systems. However, people seldom define document metadata by themselves, even when they have convenient metadata definition tools [3]. Hence, automatically extracting metadata from the bodies of documents is an important research issue.", "summary": "The process of deriving descriptive information about documents without manual input.", "node_type": "keyword", "_text_locked": true, "metadata": {"term": "Automatic metadata extraction", "context": "The process of deriving descriptive information about documents without manual input.", "relevance": "This is the central research problem and the focus of the section's motivation.", "parent_title": "Motivation for Automatic Metadata Extraction", "parent_node_type": "semantic_unit"}, "nodes": [], "node_id": "0034"}], "node_id": "0029"}], "node_id": "0028"}, {"title": "Benefits of Automated Document Structure Extraction", "start_index": 1, "end_index": 1, "text": "Automated document structure extraction has a number of benefits. Firstly, it makes automated\n\nmark-up possible. This helps to preserve information which might be required from the docu -\n\nment in the future. In addition, documents with logical structure can be presented differently for different devices. This flexibility in presentation is very useful to handle different devices. For example, a document can be presented differently in a PDA and in a web browser. Keeping docu -\n\nment logical structure also allows different users to have different access to a document. Some users may have unlimited access to a document while other users may have some limitations, for example, a textbook in which a professor has access to the answers as well as questions and a", "summary": "Explains the advantages of automated document structure extraction, including enabling automated mark-up, preserving information for future use, and allowing flexible presentation across different devices and user access levels.", "node_type": "semantic_unit", "metadata": {"semantic_type": "contribution", "start_paragraph": 3, "end_paragraph": 6, "original_title": "Benefits of Automated Document Structure Extraction"}, "nodes": [{"title": "Benefits of Automated Document Structure Extraction", "start_index": 1, "end_index": 1, "text": "Automated document structure extraction has a number of benefits. Firstly, it makes automated\n\nmark-up possible. This helps to preserve information which might be required from the docu -\n\nment in the future. In addition, documents with logical structure can be presented differently for different devices. This flexibility in presentation is very useful to handle different devices. For example, a document can be presented differently in a PDA and in a web browser. Keeping docu -\n\nment logical structure also allows different users to have different access to a document. Some users may have unlimited access to a document while other users may have some limitations, for example, a textbook in which a professor has access to the answers as well as questions and a", "summary": "This section highlights the advantages of automated document structure extraction, including enabling automated mark-up for information preservation, flexible presentation across different devices, and differentiated user access to document content.", "node_type": "semantic_unit", "metadata": {"semantic_type": "motivation", "start_paragraph": 0, "end_paragraph": 3, "original_title": "Benefits of Automated Document Structure Extraction"}, "nodes": [{"title": "Automated document structure extraction", "start_index": 1, "end_index": 1, "text": "Automated document structure extraction has a number of benefits. Firstly, it makes automated\n\nmark-up possible. This helps to preserve information which might be required from the docu -\n\nment in the future. In addition, documents with logical structure can be presented differently for different devices. This flexibility in presentation is very useful to handle different devices. For example, a document can be presented differently in a PDA and in a web browser. Keeping docu -\n\nment logical structure also allows different users to have different access to a document. Some users may have unlimited access to a document while other users may have some limitations, for example, a textbook in which a professor has access to the answers as well as questions and a", "summary": "The process of using technology to identify and tag the structural elements within a document.", "node_type": "keyword", "_text_locked": true, "metadata": {"term": "Automated document structure extraction", "context": "The process of using technology to identify and tag the structural elements within a document.", "relevance": "This is the core topic of the section, and its benefits are being discussed.", "parent_title": "Benefits of Automated Document Structure Extraction", "parent_node_type": "semantic_unit"}, "nodes": [], "node_id": "0037"}, {"title": "Automated mark-up", "start_index": 1, "end_index": 1, "text": "Automated document structure extraction has a number of benefits. Firstly, it makes automated\n\nmark-up possible. This helps to preserve information which might be required from the docu -\n\nment in the future. In addition, documents with logical structure can be presented differently for different devices. This flexibility in presentation is very useful to handle different devices. For example, a document can be presented differently in a PDA and in a web browser. Keeping docu -\n\nment logical structure also allows different users to have different access to a document. Some users may have unlimited access to a document while other users may have some limitations, for example, a textbook in which a professor has access to the answers as well as questions and a", "summary": "The automatic application of tags or labels to document content based on its structure.", "node_type": "keyword", "_text_locked": true, "metadata": {"term": "Automated mark-up", "context": "The automatic application of tags or labels to document content based on its structure.", "relevance": "This is a direct benefit of automated document structure extraction, enabling better information preservation.", "parent_title": "Benefits of Automated Document Structure Extraction", "parent_node_type": "semantic_unit"}, "nodes": [], "node_id": "0038"}, {"title": "Information preservation", "start_index": 1, "end_index": 1, "text": "Automated document structure extraction has a number of benefits. Firstly, it makes automated\n\nmark-up possible. This helps to preserve information which might be required from the docu -\n\nment in the future. In addition, documents with logical structure can be presented differently for different devices. This flexibility in presentation is very useful to handle different devices. For example, a document can be presented differently in a PDA and in a web browser. Keeping docu -\n\nment logical structure also allows different users to have different access to a document. Some users may have unlimited access to a document while other users may have some limitations, for example, a textbook in which a professor has access to the answers as well as questions and a", "summary": "Ensuring that important data within a document is maintained and accessible for future use.", "node_type": "keyword", "_text_locked": true, "metadata": {"term": "Information preservation", "context": "Ensuring that important data within a document is maintained and accessible for future use.", "relevance": "This highlights a key advantage of automated mark-up, which is facilitated by structure extraction.", "parent_title": "Benefits of Automated Document Structure Extraction", "parent_node_type": "semantic_unit"}, "nodes": [], "node_id": "0039"}, {"title": "Logical structure", "start_index": 1, "end_index": 1, "text": "Automated document structure extraction has a number of benefits. Firstly, it makes automated\n\nmark-up possible. This helps to preserve information which might be required from the docu -\n\nment in the future. In addition, documents with logical structure can be presented differently for different devices. This flexibility in presentation is very useful to handle different devices. For example, a document can be presented differently in a PDA and in a web browser. Keeping docu -\n\nment logical structure also allows different users to have different access to a document. Some users may have unlimited access to a document while other users may have some limitations, for example, a textbook in which a professor has access to the answers as well as questions and a", "summary": "The organized and hierarchical arrangement of content within a document.", "node_type": "keyword", "_text_locked": true, "metadata": {"term": "Logical structure", "context": "The organized and hierarchical arrangement of content within a document.", "relevance": "This is a fundamental concept that enables flexible presentation and user access.", "parent_title": "Benefits of Automated Document Structure Extraction", "parent_node_type": "semantic_unit"}, "nodes": [], "node_id": "0040"}, {"title": "Flexibility in presentation", "start_index": 1, "end_index": 1, "text": "Automated document structure extraction has a number of benefits. Firstly, it makes automated\n\nmark-up possible. This helps to preserve information which might be required from the docu -\n\nment in the future. In addition, documents with logical structure can be presented differently for different devices. This flexibility in presentation is very useful to handle different devices. For example, a document can be presented differently in a PDA and in a web browser. Keeping docu -\n\nment logical structure also allows different users to have different access to a document. Some users may have unlimited access to a document while other users may have some limitations, for example, a textbook in which a professor has access to the answers as well as questions and a", "summary": "The ability to display document content in various ways tailored to different devices or platforms.", "node_type": "keyword", "_text_locked": true, "metadata": {"term": "Flexibility in presentation", "context": "The ability to display document content in various ways tailored to different devices or platforms.", "relevance": "This is a significant benefit derived from a document's logical structure, improving user experience.", "parent_title": "Benefits of Automated Document Structure Extraction", "parent_node_type": "semantic_unit"}, "nodes": [], "node_id": "0041"}, {"title": "Different devices", "start_index": 1, "end_index": 1, "text": "Automated document structure extraction has a number of benefits. Firstly, it makes automated\n\nmark-up possible. This helps to preserve information which might be required from the docu -\n\nment in the future. In addition, documents with logical structure can be presented differently for different devices. This flexibility in presentation is very useful to handle different devices. For example, a document can be presented differently in a PDA and in a web browser. Keeping docu -\n\nment logical structure also allows different users to have different access to a document. Some users may have unlimited access to a document while other users may have some limitations, for example, a textbook in which a professor has access to the answers as well as questions and a", "summary": "Various electronic tools used to access and view documents, such as PDAs and web browsers.", "node_type": "keyword", "_text_locked": true, "metadata": {"term": "Different devices", "context": "Various electronic tools used to access and view documents, such as PDAs and web browsers.", "relevance": "This illustrates the practical application of flexible presentation enabled by document structure.", "parent_title": "Benefits of Automated Document Structure Extraction", "parent_node_type": "semantic_unit"}, "nodes": [], "node_id": "0042"}, {"title": "User access", "start_index": 1, "end_index": 1, "text": "Automated document structure extraction has a number of benefits. Firstly, it makes automated\n\nmark-up possible. This helps to preserve information which might be required from the docu -\n\nment in the future. In addition, documents with logical structure can be presented differently for different devices. This flexibility in presentation is very useful to handle different devices. For example, a document can be presented differently in a PDA and in a web browser. Keeping docu -\n\nment logical structure also allows different users to have different access to a document. Some users may have unlimited access to a document while other users may have some limitations, for example, a textbook in which a professor has access to the answers as well as questions and a", "summary": "The ability of different individuals to view or interact with a document, potentially with varying permissions.", "node_type": "keyword", "_text_locked": true, "metadata": {"term": "User access", "context": "The ability of different individuals to view or interact with a document, potentially with varying permissions.", "relevance": "This demonstrates another key benefit of maintaining a document's logical structure, allowing for personalized access.", "parent_title": "Benefits of Automated Document Structure Extraction", "parent_node_type": "semantic_unit"}, "nodes": [], "node_id": "0043"}], "node_id": "0036"}], "node_id": "0035"}], "node_id": "0027"}, {"title": "Introduction", "start_index": 1, "end_index": 2, "node_id": "0044", "text": "Journal of Information Science, 35 (5) 2009, pp. 563â€“570 Â© The Authors, 2009. Reprints and Permissions:  \nhttp://www.sagepub.co.uk/journalspermissions.nav, DOI: 10.1177/0165551509105195 563Automated document \nmetadata extraction\nBolanle Adefowoke Ojokoh, Olumide Sunday Adewale and \nSamuel Oluwole Falaki\nDepartment of Computer Science, Federal University of Technology, Nigeria\nAbstract.\nWeb documents are available in various forms, most of which do not carry additional semantics. This paper \npresents a model for general document metadata extraction. The model, which combines segmentation by keywords and pattern matching techniques, was implemented using PHP , MySQL, JavaScript and HTML. \nThe system was tested with 40 randomly selected PDF documents (mainly theses). An evaluation of the sys-\ntem was done using standard criteria measures namely precision, recall, accuracy and F-measure. The \nresults show that the model is relatively effective for the task of metadata extraction, especially for theses and dissertations. A combination of machine learning with these rule-based methods will be explored in the \nfuture for better results.\nKeywords: keywords; metadata; rules; segmentation; theses\n1. Introduction\nThe availability of large, web accessible, heterogeneous repositories of electronic documents is \nincreasing rapidly [1]. Most of this information is in the form of unstructured text, making the infor -\nmation hard to query [2]. Defining metadata for such documents will be useful for searching, brows-ing, and filtering. Ideally, metadata is defined by the authors of documents and is then used by various systems. However, people seldom define document metadata by themselves, even when they have convenient metadata definition tools [3]. Hence, automatically extracting metadata from the bodies of documents is an important research issue.\nAutomated document structure extraction has a number of benefits. Firstly, it makes automated \nmark-up possible. This helps to preserve information which might be required from the docu -\nment in the future. In addition, documents with logical structure can be presented differently for different devices. This flexibility in presentation is very useful to handle different devices. For example, a document can be presented differently in a PDA and in a web browser. Keeping docu -\nment logical structure also allows different users to have different access to a document. Some users may have unlimited access to a document while other users may have some limitations, for example, a textbook in which a professor has access to the answers as well as questions and a \nCorrespondence to: Bolanle Adefowoke Ojokoh, Department of Computer Science, P.M.B. 704, Akure, \nNigeria. Email: bolanleojokoh@yahoo.comBolanle Adefowoke Ojokoh et al.\nJournal of Information Science, 35 (5) 2009, pp. 563â€“570 Â© CILIP, DOI: 10.1177/0165551509105195 564student can access questions only. Finally, document logical structure helps resource discovery. \nWith logical structure, a document can be searched in other ways instead of full text and metadata searches. For example, a document can be searched in a specific section, such as the introduction. It also allows search by some complex objects such as equations. Building tools for automatic metadata extraction and representation significantly improves the amount of metadata available, the quality of metadata extracted, and the efficiency and speed of the metadata extraction process [4, 5]. This paper focuses on presenting an approach for general metadata extraction from docu -\nments, with emphasis on theses. Metadata such as Title, Table of Contents, Abstract, Acknowledgement, Preface, Introduction, Conclusion and References are extracted from docu -\nments which could be in PDF, Word or Text formats.\nThe remainder of this paper is organized as follows: Section 2 presents a number of recent meta-\ndata extraction-related researches. An overview of the proposed approach for document metadata extraction is presented in Section 3. Section 4 gives the implementation and evaluation results while Section 5 presents the conclusion and further research directions.\n2. Review of related studies\nMetadata is, most generally, data that describes other data to enhance their usefulness in content exploration [6]. Several methods have been used for automatic metadata extraction from documents; regular expressions, rule-based parsers and machine learning are the most popular [4]. Liddy et al. [7] and Yilmazel et al. [8] developed rule-based systems founded on natural language processing technologies to extract metadata from educational materials. Mao et al. [9] performed metadata extraction using rule-based methods, particularly using rules based on formatting information which would not be possible with text files. Using a machine learning approach, Hu and colleagues [10] extracted titles from general documents. Han et al. [4] carried out metadata extraction. They viewed the problem as that of classifying the lines in a document into the categories of metadata and proposed using Support Vector Machines (SVM) as the classifier. They mainly used linguistic information as features. They reported high extraction accuracy from research papers in terms of precision and recall. Peng and McCallum [11] also conducted information extraction from research papers. They employed a Conditional Random Fields (CRF) model. Ojokoh et al. [12] used Hidden Markov Models (HMM) to implement the task of metadata extraction from some sets of tagged bib-liographic references and particularly contributed to improving the smoothing technique suggested by earlier researchers. Most of these researches, however, focused on extraction from research papers that have most of the metadata to be extracted located on the first page of the paper [10]. Moreover, most of them carried out the task of metadata extraction for just a single metadata, such as author names or titles, only [13, 14]. This research combines the idea of extracting the structure of documents using keywords with regular expressions to extract metadata from documents.\n3. Document metadata extraction architecture\nThe developed system is made up of six components, four modules (Converter, Segmentation Engine, Parser and Browser), each carrying out its own function towards the task of metadata extrac-tion, and the Input and Output of the system. Equations (1)â€“(13) describe these components, their functions and relationship mathematically.\nThe Document Metadata Extractor, D is a 6-tuple (I, C, S, P, B, O)\nD = (I, C, S, P, B, O)  (1)\nwhere I is the Input, C is the Converter, S is the Segmentation Engine, P is the Parser, B is the \nBrowser and O is the Output.\n(i) I:p (2)"}], "text": "Journal of Information Science, 35 (5) 2009, pp. 563â€“570 Â© The Authors, 2009. Reprints and Permissions:  \nhttp://www.sagepub.co.uk/journalspermissions.nav, DOI: 10.1177/0165551509105195 563Automated document \nmetadata extraction\nBolanle Adefowoke Ojokoh, Olumide Sunday Adewale and \nSamuel Oluwole Falaki\nDepartment of Computer Science, Federal University of Technology, Nigeria\nAbstract.\nWeb documents are available in various forms, most of which do not carry additional semantics. This paper \npresents a model for general document metadata extraction. The model, which combines segmentation by keywords and pattern matching techniques, was implemented using PHP , MySQL, JavaScript and HTML. \nThe system was tested with 40 randomly selected PDF documents (mainly theses). An evaluation of the sys-\ntem was done using standard criteria measures namely precision, recall, accuracy and F-measure. The \nresults show that the model is relatively effective for the task of metadata extraction, especially for theses and dissertations. A combination of machine learning with these rule-based methods will be explored in the \nfuture for better results.\nKeywords: keywords; metadata; rules; segmentation; theses\n1. Introduction\nThe availability of large, web accessible, heterogeneous repositories of electronic documents is \nincreasing rapidly [1]. Most of this information is in the form of unstructured text, making the infor -\nmation hard to query [2]. Defining metadata for such documents will be useful for searching, brows-ing, and filtering. Ideally, metadata is defined by the authors of documents and is then used by various systems. However, people seldom define document metadata by themselves, even when they have convenient metadata definition tools [3]. Hence, automatically extracting metadata from the bodies of documents is an important research issue.\nAutomated document structure extraction has a number of benefits. Firstly, it makes automated \nmark-up possible. This helps to preserve information which might be required from the docu -\nment in the future. In addition, documents with logical structure can be presented differently for different devices. This flexibility in presentation is very useful to handle different devices. For example, a document can be presented differently in a PDA and in a web browser. Keeping docu -\nment logical structure also allows different users to have different access to a document. Some users may have unlimited access to a document while other users may have some limitations, for example, a textbook in which a professor has access to the answers as well as questions and a \nCorrespondence to: Bolanle Adefowoke Ojokoh, Department of Computer Science, P.M.B. 704, Akure, \nNigeria. Email: bolanleojokoh@yahoo.com", "node_id": "0000"}, {"title": "Review of related studies", "start_index": 2, "end_index": 3, "text": "Bolanle Adefowoke Ojokoh et al.\nJournal of Information Science, 35 (5) 2009, pp. 563â€“570 Â© CILIP, DOI: 10.1177/0165551509105195 564student can access questions only. Finally, document logical structure helps resource discovery. \nWith logical structure, a document can be searched in other ways instead of full text and metadata searches. For example, a document can be searched in a specific section, such as the introduction. It also allows search by some complex objects such as equations. Building tools for automatic metadata extraction and representation significantly improves the amount of metadata available, the quality of metadata extracted, and the efficiency and speed of the metadata extraction process [4, 5]. This paper focuses on presenting an approach for general metadata extraction from docu -\nments, with emphasis on theses. Metadata such as Title, Table of Contents, Abstract, Acknowledgement, Preface, Introduction, Conclusion and References are extracted from docu -\nments which could be in PDF, Word or Text formats.\nThe remainder of this paper is organized as follows: Section 2 presents a number of recent meta-\ndata extraction-related researches. An overview of the proposed approach for document metadata extraction is presented in Section 3. Section 4 gives the implementation and evaluation results while Section 5 presents the conclusion and further research directions.\n2. Review of related studies\nMetadata is, most generally, data that describes other data to enhance their usefulness in content exploration [6]. Several methods have been used for automatic metadata extraction from documents; regular expressions, rule-based parsers and machine learning are the most popular [4]. Liddy et al. [7] and Yilmazel et al. [8] developed rule-based systems founded on natural language processing technologies to extract metadata from educational materials. Mao et al. [9] performed metadata extraction using rule-based methods, particularly using rules based on formatting information which would not be possible with text files. Using a machine learning approach, Hu and colleagues [10] extracted titles from general documents. Han et al. [4] carried out metadata extraction. They viewed the problem as that of classifying the lines in a document into the categories of metadata and proposed using Support Vector Machines (SVM) as the classifier. They mainly used linguistic information as features. They reported high extraction accuracy from research papers in terms of precision and recall. Peng and McCallum [11] also conducted information extraction from research papers. They employed a Conditional Random Fields (CRF) model. Ojokoh et al. [12] used Hidden Markov Models (HMM) to implement the task of metadata extraction from some sets of tagged bib-liographic references and particularly contributed to improving the smoothing technique suggested by earlier researchers. Most of these researches, however, focused on extraction from research papers that have most of the metadata to be extracted located on the first page of the paper [10]. Moreover, most of them carried out the task of metadata extraction for just a single metadata, such as author names or titles, only [13, 14]. This research combines the idea of extracting the structure of documents using keywords with regular expressions to extract metadata from documents.\n3. Document metadata extraction architecture\nThe developed system is made up of six components, four modules (Converter, Segmentation Engine, Parser and Browser), each carrying out its own function towards the task of metadata extrac-tion, and the Input and Output of the system. Equations (1)â€“(13) describe these components, their functions and relationship mathematically.\nThe Document Metadata Extractor, D is a 6-tuple (I, C, S, P, B, O)\nD = (I, C, S, P, B, O)  (1)\nwhere I is the Input, C is the Converter, S is the Segmentation Engine, P is the Parser, B is the \nBrowser and O is the Output.\n(i) I:p (2)Bolanle Adefowoke Ojokoh et al.\nJournal of Information Science, 35 (5) 2009, pp. 563â€“570 Â© CILIP, DOI: 10.1177/0165551509105195 565where p is the uploaded document needing conversion.\n(ii) Cp â†’ t  (3)\nand\nt = {b1, b2, ..., bn} (4)\nwhere t is the text document and bn refers to block n in the document.\n(iii) S is a 2-tuple (M, G) (5)\nwhere M refers to the map function and G refers to the group function.\n(a) M: bi â†’ sk (6)\nwhere sk refers to the set of identified pattern strings\n(b) G: {bi | sk = si, ..., n} where i â‰  k (7)\nStep (b) is repeated until all grouping is done.\nâˆƒbn\ni: t Â· n is the number of groups in which bi occurs\n(iv) P: merge bi1,..,n â†’ bi (8)\nthen,\nE: (bi * mdi * si) â†’ {mdi,bi} (9)\nmd âˆˆ {abstract, tableofcontents, introduction, references} (10)\nwhere E is the extract function and md refers to the set of extracted metadata.\nTitle extraction is done with a different method as follows:\ntitle âˆˆ {[Aâ€“Z] * |first 1â€“100 characters|1st three lines (11)\n(vi) âˆ€mdi extracted, B displays O âˆˆ {title, mdi, bi} (12)\nT:(D:u, mdi, ...4, bi, ...n)  (13)\nwhere T is the store function and D is the database.\nThis research work used an approach implementing the model combining segmentation by keyword \ntogether with the use of regular expressions, as presented earlier, to extract some set of metadata \nfrom documents. Title extraction is another challenging task that may not be easily done using only segmentation by keyword as titles of documents are not usually labelled. In this research some sets of rules were proposed for title extraction. Figure 1 describes the architecture of the document meta-data extractor.\nSegmentation is the generation of hierarchy of logical divisions from a document. This layout segmen -\ntation captures the divisions of the documentâ€™s logical structure. It can be done in three ways [15]:\nâ€¢ Segmentation by spacing: by using spacing information, scanned images are separated into sev-\neral areas which can be text, figure/table, or formulae areas.\nâ€¢ Segmentation by style difference: for each text area, the average size of the characters contained in \nthe area is calculated. The size of a character can be determined by its height. Also boldness can be \ncalculated by the horizontal width of a character. In an area where the styles (bold, italic and size) of lines are obviously different from those of other lines, they are separately segmented.\nâ€¢ Segmentation by keywords: in an area, where a special keyword (e.g. abstract, references) comes at \nthe beginning of a line, basically the area is segmented before the line as used in this research. This method is most relevant for this research because there are generally certain keywords specifically used in documents.", "node_id": "0045"}, {"title": "Document metadata extraction architecture", "start_index": 3, "end_index": 3, "nodes": [{"title": "Document Conversion Model", "start_index": 3, "end_index": 3, "text": "Bolanle Adefowoke Ojokoh et al.\n\nJournal of Information Science, 35 (5) 2009, pp. 563â€“570 Â© CILIP, DOI: 10.1177/0165551509105195 565where p is the uploaded document needing conversion.\n\n(ii) Cp â†’ t  (3)\n\nand\n\nt = {b1, b2, ..., bn} (4)\n\nwhere t is the text document and bn refers to block n in the document.\n\n(iii) S is a 2-tuple (M, G) (5)\n\nwhere M refers to the map function and G refers to the group function.\n\n(a) M: bi â†’ sk (6)\n\nwhere sk refers to the set of identified pattern strings\n\n(b) G: {bi | sk = si, ..., n} where i â‰  k (7)\n\nStep (b) is repeated until all grouping is done.\n\nâˆƒbn\n\ni: t Â· n is the number of groups in which bi occurs\n\n(iv) P: merge bi1,..,n â†’ bi (8)\n\nthen,\n\nE: (bi * mdi * si) â†’ {mdi,bi} (9)\n\nmd âˆˆ {abstract, tableofcontents, introduction, references} (10)\n\nwhere E is the extract function and md refers to the set of extracted metadata.\n\nTitle extraction is done with a different method as follows:\n\ntitle âˆˆ {[Aâ€“Z] * |first 1â€“100 characters|1st three lines (11)\n\n(vi) âˆ€mdi extracted, B displays O âˆˆ {title, mdi, bi} (12)\n\nT:(D:u, mdi, ...4, bi, ...n)  (13)\n\nwhere T is the store function and D is the database.", "summary": "This section details a model for document conversion, outlining functions for mapping, grouping, merging, and extracting metadata such as abstract, table of contents, introduction, and references. It also describes a specific method for title extraction.", "node_type": "semantic_unit", "metadata": {"semantic_type": "procedure", "start_paragraph": 0, "end_paragraph": 23, "original_title": "Document Conversion Model"}, "nodes": [{"title": "Document Conversion Process", "start_index": 3, "end_index": 3, "text": "Bolanle Adefowoke Ojokoh et al.\n\nJournal of Information Science, 35 (5) 2009, pp. 563â€“570 Â© CILIP, DOI: 10.1177/0165551509105195 565where p is the uploaded document needing conversion.\n\n(ii) Cp â†’ t  (3)\n\nand\n\nt = {b1, b2, ..., bn} (4)\n\nwhere t is the text document and bn refers to block n in the document.\n\n(iii) S is a 2-tuple (M, G) (5)\n\nwhere M refers to the map function and G refers to the group function.\n\n(a) M: bi â†’ sk (6)\n\nwhere sk refers to the set of identified pattern strings\n\n(b) G: {bi | sk = si, ..., n} where i â‰  k (7)\n\nStep (b) is repeated until all grouping is done.\n\nâˆƒbn\n\ni: t Â· n is the number of groups in which bi occurs\n\n(iv) P: merge bi1,..,n â†’ bi (8)\n\nthen,\n\nE: (bi * mdi * si) â†’ {mdi,bi} (9)\n\nmd âˆˆ {abstract, tableofcontents, introduction, references} (10)\n\nwhere E is the extract function and md refers to the set of extracted metadata.\n\nTitle extraction is done with a different method as follows:\n\ntitle âˆˆ {[Aâ€“Z] * |first 1â€“100 characters|1st three lines (11)\n\n(vi) âˆ€mdi extracted, B displays O âˆˆ {title, mdi, bi} (12)\n\nT:(D:u, mdi, ...4, bi, ...n)  (13)\n\nwhere T is the store function and D is the database.", "summary": "This section details a multi-step process for converting uploaded documents into a structured text format. It involves mapping document blocks, grouping them based on identified patterns, merging blocks, and extracting metadata such as abstract, table of contents, introduction, and references. A specific method for title extraction is also described, followed by storing the processed information in a database.", "node_type": "semantic_unit", "metadata": {"semantic_type": "procedure", "start_paragraph": 0, "end_paragraph": 23, "original_title": "Document Conversion Process"}, "nodes": [{"title": "Document Conversion Process", "start_index": 3, "end_index": 3, "text": "Bolanle Adefowoke Ojokoh et al.\n\nJournal of Information Science, 35 (5) 2009, pp. 563â€“570 Â© CILIP, DOI: 10.1177/0165551509105195 565where p is the uploaded document needing conversion.\n\n(ii) Cp â†’ t  (3)\n\nand\n\nt = {b1, b2, ..., bn} (4)\n\nwhere t is the text document and bn refers to block n in the document.\n\n(iii) S is a 2-tuple (M, G) (5)\n\nwhere M refers to the map function and G refers to the group function.\n\n(a) M: bi â†’ sk (6)\n\nwhere sk refers to the set of identified pattern strings\n\n(b) G: {bi | sk = si, ..., n} where i â‰  k (7)\n\nStep (b) is repeated until all grouping is done.\n\nâˆƒbn\n\ni: t Â· n is the number of groups in which bi occurs\n\n(iv) P: merge bi1,..,n â†’ bi (8)\n\nthen,\n\nE: (bi * mdi * si) â†’ {mdi,bi} (9)\n\nmd âˆˆ {abstract, tableofcontents, introduction, references} (10)\n\nwhere E is the extract function and md refers to the set of extracted metadata.\n\nTitle extraction is done with a different method as follows:\n\ntitle âˆˆ {[Aâ€“Z] * |first 1â€“100 characters|1st three lines (11)\n\n(vi) âˆ€mdi extracted, B displays O âˆˆ {title, mdi, bi} (12)\n\nT:(D:u, mdi, ...4, bi, ...n)  (13)\n\nwhere T is the store function and D is the database.", "summary": "This section details a multi-step process for converting uploaded documents into a structured text format. It involves mapping document blocks, grouping them based on identified patterns, merging blocks, and extracting metadata such as abstract, table of contents, introduction, and references. A specific method for title extraction is also described, followed by storing the processed information in a database.", "node_type": "semantic_unit", "metadata": {"semantic_type": "procedure", "start_paragraph": 0, "end_paragraph": 23, "original_title": "Document Conversion Process"}, "nodes": [{"title": "Document Conversion Process", "start_index": 3, "end_index": 3, "text": "Bolanle Adefowoke Ojokoh et al.\n\nJournal of Information Science, 35 (5) 2009, pp. 563â€“570 Â© CILIP, DOI: 10.1177/0165551509105195 565where p is the uploaded document needing conversion.\n\n(ii) Cp â†’ t  (3)\n\nand\n\nt = {b1, b2, ..., bn} (4)\n\nwhere t is the text document and bn refers to block n in the document.\n\n(iii) S is a 2-tuple (M, G) (5)\n\nwhere M refers to the map function and G refers to the group function.\n\n(a) M: bi â†’ sk (6)\n\nwhere sk refers to the set of identified pattern strings\n\n(b) G: {bi | sk = si, ..., n} where i â‰  k (7)\n\nStep (b) is repeated until all grouping is done.\n\nâˆƒbn\n\ni: t Â· n is the number of groups in which bi occurs\n\n(iv) P: merge bi1,..,n â†’ bi (8)\n\nthen,\n\nE: (bi * mdi * si) â†’ {mdi,bi} (9)\n\nmd âˆˆ {abstract, tableofcontents, introduction, references} (10)\n\nwhere E is the extract function and md refers to the set of extracted metadata.\n\nTitle extraction is done with a different method as follows:\n\ntitle âˆˆ {[Aâ€“Z] * |first 1â€“100 characters|1st three lines (11)\n\n(vi) âˆ€mdi extracted, B displays O âˆˆ {title, mdi, bi} (12)\n\nT:(D:u, mdi, ...4, bi, ...n)  (13)\n\nwhere T is the store function and D is the database.", "summary": "The overall methodology described for transforming an uploaded document into a structured text format.", "node_type": "keyword", "_text_locked": true, "metadata": {"term": "Document Conversion Process", "context": "The overall methodology described for transforming an uploaded document into a structured text format.", "relevance": "This is the central theme and process being detailed in the section.", "parent_title": "Document Conversion Process", "parent_node_type": "semantic_unit"}, "nodes": [], "node_id": "0050"}, {"title": "Map Function (M)", "start_index": 3, "end_index": 3, "text": "Bolanle Adefowoke Ojokoh et al.\n\nJournal of Information Science, 35 (5) 2009, pp. 563â€“570 Â© CILIP, DOI: 10.1177/0165551509105195 565where p is the uploaded document needing conversion.\n\n(ii) Cp â†’ t  (3)\n\nand\n\nt = {b1, b2, ..., bn} (4)\n\nwhere t is the text document and bn refers to block n in the document.\n\n(iii) S is a 2-tuple (M, G) (5)\n\nwhere M refers to the map function and G refers to the group function.\n\n(a) M: bi â†’ sk (6)\n\nwhere sk refers to the set of identified pattern strings\n\n(b) G: {bi | sk = si, ..., n} where i â‰  k (7)\n\nStep (b) is repeated until all grouping is done.\n\nâˆƒbn\n\ni: t Â· n is the number of groups in which bi occurs\n\n(iv) P: merge bi1,..,n â†’ bi (8)\n\nthen,\n\nE: (bi * mdi * si) â†’ {mdi,bi} (9)\n\nmd âˆˆ {abstract, tableofcontents, introduction, references} (10)\n\nwhere E is the extract function and md refers to the set of extracted metadata.\n\nTitle extraction is done with a different method as follows:\n\ntitle âˆˆ {[Aâ€“Z] * |first 1â€“100 characters|1st three lines (11)\n\n(vi) âˆ€mdi extracted, B displays O âˆˆ {title, mdi, bi} (12)\n\nT:(D:u, mdi, ...4, bi, ...n)  (13)\n\nwhere T is the store function and D is the database.", "summary": "A function that maps blocks of a text document to sets of identified pattern strings.", "node_type": "keyword", "_text_locked": true, "metadata": {"term": "Map Function (M)", "context": "A function that maps blocks of a text document to sets of identified pattern strings.", "relevance": "This function is a core component of the grouping step in the conversion process.", "parent_title": "Document Conversion Process", "parent_node_type": "semantic_unit"}, "nodes": [], "node_id": "0051"}, {"title": "Group Function (G)", "start_index": 3, "end_index": 3, "text": "Bolanle Adefowoke Ojokoh et al.\n\nJournal of Information Science, 35 (5) 2009, pp. 563â€“570 Â© CILIP, DOI: 10.1177/0165551509105195 565where p is the uploaded document needing conversion.\n\n(ii) Cp â†’ t  (3)\n\nand\n\nt = {b1, b2, ..., bn} (4)\n\nwhere t is the text document and bn refers to block n in the document.\n\n(iii) S is a 2-tuple (M, G) (5)\n\nwhere M refers to the map function and G refers to the group function.\n\n(a) M: bi â†’ sk (6)\n\nwhere sk refers to the set of identified pattern strings\n\n(b) G: {bi | sk = si, ..., n} where i â‰  k (7)\n\nStep (b) is repeated until all grouping is done.\n\nâˆƒbn\n\ni: t Â· n is the number of groups in which bi occurs\n\n(iv) P: merge bi1,..,n â†’ bi (8)\n\nthen,\n\nE: (bi * mdi * si) â†’ {mdi,bi} (9)\n\nmd âˆˆ {abstract, tableofcontents, introduction, references} (10)\n\nwhere E is the extract function and md refers to the set of extracted metadata.\n\nTitle extraction is done with a different method as follows:\n\ntitle âˆˆ {[Aâ€“Z] * |first 1â€“100 characters|1st three lines (11)\n\n(vi) âˆ€mdi extracted, B displays O âˆˆ {title, mdi, bi} (12)\n\nT:(D:u, mdi, ...4, bi, ...n)  (13)\n\nwhere T is the store function and D is the database.", "summary": "A function that groups blocks of text based on shared pattern strings.", "node_type": "keyword", "_text_locked": true, "metadata": {"term": "Group Function (G)", "context": "A function that groups blocks of text based on shared pattern strings.", "relevance": "This function is crucial for organizing and segmenting the document content.", "parent_title": "Document Conversion Process", "parent_node_type": "semantic_unit"}, "nodes": [], "node_id": "0052"}, {"title": "Extracted Metadata (md)", "start_index": 3, "end_index": 3, "text": "Bolanle Adefowoke Ojokoh et al.\n\nJournal of Information Science, 35 (5) 2009, pp. 563â€“570 Â© CILIP, DOI: 10.1177/0165551509105195 565where p is the uploaded document needing conversion.\n\n(ii) Cp â†’ t  (3)\n\nand\n\nt = {b1, b2, ..., bn} (4)\n\nwhere t is the text document and bn refers to block n in the document.\n\n(iii) S is a 2-tuple (M, G) (5)\n\nwhere M refers to the map function and G refers to the group function.\n\n(a) M: bi â†’ sk (6)\n\nwhere sk refers to the set of identified pattern strings\n\n(b) G: {bi | sk = si, ..., n} where i â‰  k (7)\n\nStep (b) is repeated until all grouping is done.\n\nâˆƒbn\n\ni: t Â· n is the number of groups in which bi occurs\n\n(iv) P: merge bi1,..,n â†’ bi (8)\n\nthen,\n\nE: (bi * mdi * si) â†’ {mdi,bi} (9)\n\nmd âˆˆ {abstract, tableofcontents, introduction, references} (10)\n\nwhere E is the extract function and md refers to the set of extracted metadata.\n\nTitle extraction is done with a different method as follows:\n\ntitle âˆˆ {[Aâ€“Z] * |first 1â€“100 characters|1st three lines (11)\n\n(vi) âˆ€mdi extracted, B displays O âˆˆ {title, mdi, bi} (12)\n\nT:(D:u, mdi, ...4, bi, ...n)  (13)\n\nwhere T is the store function and D is the database.", "summary": "Specific types of information like abstract, table of contents, introduction, and references extracted from the document.", "node_type": "keyword", "_text_locked": true, "metadata": {"term": "Extracted Metadata (md)", "context": "Specific types of information like abstract, table of contents, introduction, and references extracted from the document.", "relevance": "These are key pieces of information that are identified and preserved during conversion.", "parent_title": "Document Conversion Process", "parent_node_type": "semantic_unit"}, "nodes": [], "node_id": "0053"}, {"title": "Extract Function (E)", "start_index": 3, "end_index": 3, "text": "Bolanle Adefowoke Ojokoh et al.\n\nJournal of Information Science, 35 (5) 2009, pp. 563â€“570 Â© CILIP, DOI: 10.1177/0165551509105195 565where p is the uploaded document needing conversion.\n\n(ii) Cp â†’ t  (3)\n\nand\n\nt = {b1, b2, ..., bn} (4)\n\nwhere t is the text document and bn refers to block n in the document.\n\n(iii) S is a 2-tuple (M, G) (5)\n\nwhere M refers to the map function and G refers to the group function.\n\n(a) M: bi â†’ sk (6)\n\nwhere sk refers to the set of identified pattern strings\n\n(b) G: {bi | sk = si, ..., n} where i â‰  k (7)\n\nStep (b) is repeated until all grouping is done.\n\nâˆƒbn\n\ni: t Â· n is the number of groups in which bi occurs\n\n(iv) P: merge bi1,..,n â†’ bi (8)\n\nthen,\n\nE: (bi * mdi * si) â†’ {mdi,bi} (9)\n\nmd âˆˆ {abstract, tableofcontents, introduction, references} (10)\n\nwhere E is the extract function and md refers to the set of extracted metadata.\n\nTitle extraction is done with a different method as follows:\n\ntitle âˆˆ {[Aâ€“Z] * |first 1â€“100 characters|1st three lines (11)\n\n(vi) âˆ€mdi extracted, B displays O âˆˆ {title, mdi, bi} (12)\n\nT:(D:u, mdi, ...4, bi, ...n)  (13)\n\nwhere T is the store function and D is the database.", "summary": "A function that merges document blocks and extracts metadata.", "node_type": "keyword", "_text_locked": true, "metadata": {"term": "Extract Function (E)", "context": "A function that merges document blocks and extracts metadata.", "relevance": "This function is responsible for the final assembly of structured document components.", "parent_title": "Document Conversion Process", "parent_node_type": "semantic_unit"}, "nodes": [], "node_id": "0054"}, {"title": "Title Extraction", "start_index": 3, "end_index": 3, "text": "Bolanle Adefowoke Ojokoh et al.\n\nJournal of Information Science, 35 (5) 2009, pp. 563â€“570 Â© CILIP, DOI: 10.1177/0165551509105195 565where p is the uploaded document needing conversion.\n\n(ii) Cp â†’ t  (3)\n\nand\n\nt = {b1, b2, ..., bn} (4)\n\nwhere t is the text document and bn refers to block n in the document.\n\n(iii) S is a 2-tuple (M, G) (5)\n\nwhere M refers to the map function and G refers to the group function.\n\n(a) M: bi â†’ sk (6)\n\nwhere sk refers to the set of identified pattern strings\n\n(b) G: {bi | sk = si, ..., n} where i â‰  k (7)\n\nStep (b) is repeated until all grouping is done.\n\nâˆƒbn\n\ni: t Â· n is the number of groups in which bi occurs\n\n(iv) P: merge bi1,..,n â†’ bi (8)\n\nthen,\n\nE: (bi * mdi * si) â†’ {mdi,bi} (9)\n\nmd âˆˆ {abstract, tableofcontents, introduction, references} (10)\n\nwhere E is the extract function and md refers to the set of extracted metadata.\n\nTitle extraction is done with a different method as follows:\n\ntitle âˆˆ {[Aâ€“Z] * |first 1â€“100 characters|1st three lines (11)\n\n(vi) âˆ€mdi extracted, B displays O âˆˆ {title, mdi, bi} (12)\n\nT:(D:u, mdi, ...4, bi, ...n)  (13)\n\nwhere T is the store function and D is the database.", "summary": "A specific method used to identify and extract the document's title based on character patterns and line position.", "node_type": "keyword", "_text_locked": true, "metadata": {"term": "Title Extraction", "context": "A specific method used to identify and extract the document's title based on character patterns and line position.", "relevance": "Highlights a specialized sub-process within the broader document conversion.", "parent_title": "Document Conversion Process", "parent_node_type": "semantic_unit"}, "nodes": [], "node_id": "0055"}, {"title": "Store Function (T)", "start_index": 3, "end_index": 3, "text": "Bolanle Adefowoke Ojokoh et al.\n\nJournal of Information Science, 35 (5) 2009, pp. 563â€“570 Â© CILIP, DOI: 10.1177/0165551509105195 565where p is the uploaded document needing conversion.\n\n(ii) Cp â†’ t  (3)\n\nand\n\nt = {b1, b2, ..., bn} (4)\n\nwhere t is the text document and bn refers to block n in the document.\n\n(iii) S is a 2-tuple (M, G) (5)\n\nwhere M refers to the map function and G refers to the group function.\n\n(a) M: bi â†’ sk (6)\n\nwhere sk refers to the set of identified pattern strings\n\n(b) G: {bi | sk = si, ..., n} where i â‰  k (7)\n\nStep (b) is repeated until all grouping is done.\n\nâˆƒbn\n\ni: t Â· n is the number of groups in which bi occurs\n\n(iv) P: merge bi1,..,n â†’ bi (8)\n\nthen,\n\nE: (bi * mdi * si) â†’ {mdi,bi} (9)\n\nmd âˆˆ {abstract, tableofcontents, introduction, references} (10)\n\nwhere E is the extract function and md refers to the set of extracted metadata.\n\nTitle extraction is done with a different method as follows:\n\ntitle âˆˆ {[Aâ€“Z] * |first 1â€“100 characters|1st three lines (11)\n\n(vi) âˆ€mdi extracted, B displays O âˆˆ {title, mdi, bi} (12)\n\nT:(D:u, mdi, ...4, bi, ...n)  (13)\n\nwhere T is the store function and D is the database.", "summary": "A function that stores the extracted metadata, title, and document blocks into a database.", "node_type": "keyword", "_text_locked": true, "metadata": {"term": "Store Function (T)", "context": "A function that stores the extracted metadata, title, and document blocks into a database.", "relevance": "This function represents the final step of persisting the converted document information.", "parent_title": "Document Conversion Process", "parent_node_type": "semantic_unit"}, "nodes": [], "node_id": "0056"}, {"title": "Database (D)", "start_index": 3, "end_index": 3, "text": "Bolanle Adefowoke Ojokoh et al.\n\nJournal of Information Science, 35 (5) 2009, pp. 563â€“570 Â© CILIP, DOI: 10.1177/0165551509105195 565where p is the uploaded document needing conversion.\n\n(ii) Cp â†’ t  (3)\n\nand\n\nt = {b1, b2, ..., bn} (4)\n\nwhere t is the text document and bn refers to block n in the document.\n\n(iii) S is a 2-tuple (M, G) (5)\n\nwhere M refers to the map function and G refers to the group function.\n\n(a) M: bi â†’ sk (6)\n\nwhere sk refers to the set of identified pattern strings\n\n(b) G: {bi | sk = si, ..., n} where i â‰  k (7)\n\nStep (b) is repeated until all grouping is done.\n\nâˆƒbn\n\ni: t Â· n is the number of groups in which bi occurs\n\n(iv) P: merge bi1,..,n â†’ bi (8)\n\nthen,\n\nE: (bi * mdi * si) â†’ {mdi,bi} (9)\n\nmd âˆˆ {abstract, tableofcontents, introduction, references} (10)\n\nwhere E is the extract function and md refers to the set of extracted metadata.\n\nTitle extraction is done with a different method as follows:\n\ntitle âˆˆ {[Aâ€“Z] * |first 1â€“100 characters|1st three lines (11)\n\n(vi) âˆ€mdi extracted, B displays O âˆˆ {title, mdi, bi} (12)\n\nT:(D:u, mdi, ...4, bi, ...n)  (13)\n\nwhere T is the store function and D is the database.", "summary": "The final destination where the processed document components are stored.", "node_type": "keyword", "_text_locked": true, "metadata": {"term": "Database (D)", "context": "The final destination where the processed document components are stored.", "relevance": "Indicates the end-point of the document conversion workflow.", "parent_title": "Document Conversion Process", "parent_node_type": "semantic_unit"}, "nodes": [], "node_id": "0057"}], "node_id": "0049"}], "node_id": "0048"}], "node_id": "0047"}, {"title": "Metadata Extraction Approach", "start_index": 3, "end_index": 3, "text": "This research work used an approach implementing the model combining segmentation by keyword\n\ntogether with the use of regular expressions, as presented earlier, to extract some set of metadata\n\nfrom documents. Title extraction is another challenging task that may not be easily done using only segmentation by keyword as titles of documents are not usually labelled. In this research some sets of rules were proposed for title extraction. Figure 1 describes the architecture of the document meta-data extractor.", "summary": "This part describes the research's approach to metadata extraction, combining keyword-based segmentation with regular expressions. It highlights the challenge of title extraction and mentions proposed rules for it, referencing a figure for the architecture.", "node_type": "semantic_unit", "metadata": {"semantic_type": "procedure", "start_paragraph": 24, "end_paragraph": 26, "original_title": "Metadata Extraction Approach"}, "nodes": [{"title": "Document Metadata Extraction Approach", "start_index": 3, "end_index": 3, "text": "This research work used an approach implementing the model combining segmentation by keyword\n\ntogether with the use of regular expressions, as presented earlier, to extract some set of metadata\n\nfrom documents. Title extraction is another challenging task that may not be easily done using only segmentation by keyword as titles of documents are not usually labelled. In this research some sets of rules were proposed for title extraction. Figure 1 describes the architecture of the document meta-data extractor.", "summary": "This section describes the approach used for extracting metadata from documents, combining keyword segmentation with regular expressions. It also addresses the challenge of title extraction and proposes a set of rules for it, with a reference to a figure illustrating the architecture.", "node_type": "semantic_unit", "metadata": {"semantic_type": "procedure", "start_paragraph": 0, "end_paragraph": 2, "original_title": "Document Metadata Extraction Approach"}, "nodes": [{"title": "Document Metadata Extraction Approach", "start_index": 3, "end_index": 3, "text": "This research work used an approach implementing the model combining segmentation by keyword\n\ntogether with the use of regular expressions, as presented earlier, to extract some set of metadata\n\nfrom documents. Title extraction is another challenging task that may not be easily done using only segmentation by keyword as titles of documents are not usually labelled. In this research some sets of rules were proposed for title extraction. Figure 1 describes the architecture of the document meta-data extractor.", "summary": "This section describes the approach used for extracting metadata from documents, combining keyword segmentation with regular expressions. It also addresses the challenge of title extraction and proposes a set of rules for it, with a reference to a figure illustrating the architecture.", "node_type": "semantic_unit", "metadata": {"semantic_type": "procedure", "start_paragraph": 0, "end_paragraph": 2, "original_title": "Document Metadata Extraction Approach"}, "nodes": [{"title": "Document Metadata Extraction", "start_index": 3, "end_index": 3, "text": "This research work used an approach implementing the model combining segmentation by keyword\n\ntogether with the use of regular expressions, as presented earlier, to extract some set of metadata\n\nfrom documents. Title extraction is another challenging task that may not be easily done using only segmentation by keyword as titles of documents are not usually labelled. In this research some sets of rules were proposed for title extraction. Figure 1 describes the architecture of the document meta-data extractor.", "summary": "The process of identifying and extracting specific pieces of information (metadata) from documents.", "node_type": "keyword", "_text_locked": true, "metadata": {"term": "Document Metadata Extraction", "context": "The process of identifying and extracting specific pieces of information (metadata) from documents.", "relevance": "This is the core task and objective of the research work described in the section.", "parent_title": "Document Metadata Extraction Approach", "parent_node_type": "semantic_unit"}, "nodes": [], "node_id": "0061"}, {"title": "Segmentation by Keyword", "start_index": 3, "end_index": 3, "text": "This research work used an approach implementing the model combining segmentation by keyword\n\ntogether with the use of regular expressions, as presented earlier, to extract some set of metadata\n\nfrom documents. Title extraction is another challenging task that may not be easily done using only segmentation by keyword as titles of documents are not usually labelled. In this research some sets of rules were proposed for title extraction. Figure 1 describes the architecture of the document meta-data extractor.", "summary": "A method that uses specific keywords to identify and segment parts of a document.", "node_type": "keyword", "_text_locked": true, "metadata": {"term": "Segmentation by Keyword", "context": "A method that uses specific keywords to identify and segment parts of a document.", "relevance": "This is a primary technique used in the proposed approach for metadata extraction.", "parent_title": "Document Metadata Extraction Approach", "parent_node_type": "semantic_unit"}, "nodes": [], "node_id": "0062"}, {"title": "Regular Expressions", "start_index": 3, "end_index": 3, "text": "This research work used an approach implementing the model combining segmentation by keyword\n\ntogether with the use of regular expressions, as presented earlier, to extract some set of metadata\n\nfrom documents. Title extraction is another challenging task that may not be easily done using only segmentation by keyword as titles of documents are not usually labelled. In this research some sets of rules were proposed for title extraction. Figure 1 describes the architecture of the document meta-data extractor.", "summary": "A sequence of characters that defines a search pattern, used for pattern matching within strings.", "node_type": "keyword", "_text_locked": true, "metadata": {"term": "Regular Expressions", "context": "A sequence of characters that defines a search pattern, used for pattern matching within strings.", "relevance": "This is a complementary technique used alongside segmentation by keyword for metadata extraction.", "parent_title": "Document Metadata Extraction Approach", "parent_node_type": "semantic_unit"}, "nodes": [], "node_id": "0063"}, {"title": "Title Extraction", "start_index": 3, "end_index": 3, "text": "This research work used an approach implementing the model combining segmentation by keyword\n\ntogether with the use of regular expressions, as presented earlier, to extract some set of metadata\n\nfrom documents. Title extraction is another challenging task that may not be easily done using only segmentation by keyword as titles of documents are not usually labelled. In this research some sets of rules were proposed for title extraction. Figure 1 describes the architecture of the document meta-data extractor.", "summary": "The specific challenge of identifying and extracting the title from a document.", "node_type": "keyword", "_text_locked": true, "metadata": {"term": "Title Extraction", "context": "The specific challenge of identifying and extracting the title from a document.", "relevance": "This highlights a particular difficulty addressed by the proposed rules within the research.", "parent_title": "Document Metadata Extraction Approach", "parent_node_type": "semantic_unit"}, "nodes": [], "node_id": "0064"}, {"title": "Rules for Title Extraction", "start_index": 3, "end_index": 3, "text": "This research work used an approach implementing the model combining segmentation by keyword\n\ntogether with the use of regular expressions, as presented earlier, to extract some set of metadata\n\nfrom documents. Title extraction is another challenging task that may not be easily done using only segmentation by keyword as titles of documents are not usually labelled. In this research some sets of rules were proposed for title extraction. Figure 1 describes the architecture of the document meta-data extractor.", "summary": "A set of predefined guidelines or logic developed to identify document titles.", "node_type": "keyword", "_text_locked": true, "metadata": {"term": "Rules for Title Extraction", "context": "A set of predefined guidelines or logic developed to identify document titles.", "relevance": "These rules are a key component of the solution proposed for the title extraction problem.", "parent_title": "Document Metadata Extraction Approach", "parent_node_type": "semantic_unit"}, "nodes": [], "node_id": "0065"}, {"title": "Document Meta-data Extractor Architecture", "start_index": 3, "end_index": 3, "text": "This research work used an approach implementing the model combining segmentation by keyword\n\ntogether with the use of regular expressions, as presented earlier, to extract some set of metadata\n\nfrom documents. Title extraction is another challenging task that may not be easily done using only segmentation by keyword as titles of documents are not usually labelled. In this research some sets of rules were proposed for title extraction. Figure 1 describes the architecture of the document meta-data extractor.", "summary": "The overall structural design and components of the system used for extracting metadata.", "node_type": "keyword", "_text_locked": true, "metadata": {"term": "Document Meta-data Extractor Architecture", "context": "The overall structural design and components of the system used for extracting metadata.", "relevance": "This represents the system's design, which is visually described and central to the implementation.", "parent_title": "Document Metadata Extraction Approach", "parent_node_type": "semantic_unit"}, "nodes": [], "node_id": "0066"}], "node_id": "0060"}], "node_id": "0059"}], "node_id": "0058"}, {"title": "Segmentation Methods", "start_index": 3, "end_index": 3, "text": "Segmentation is the generation of hierarchy of logical divisions from a document. This layout segmen -\n\ntation captures the divisions of the documentâ€™s logical structure. It can be done in three ways [15]:\n\nâ€¢ Segmentation by spacing: by using spacing information, scanned images are separated into sev-\n\neral areas which can be text, figure/table, or formulae areas.\n\nâ€¢ Segmentation by style difference: for each text area, the average size of the characters contained in\n\nthe area is calculated. The size of a character can be determined by its height. Also boldness can be\n\ncalculated by the horizontal width of a character. In an area where the styles (bold, italic and size) of lines are obviously different from those of other lines, they are separately segmented.\n\nâ€¢ Segmentation by keywords: in an area, where a special keyword (e.g. abstract, references) comes at\n\nthe beginning of a line, basically the area is segmented before the line as used in this research. This method is most relevant for this research because there are generally certain keywords specifically used in documents.", "summary": "This section explains document segmentation as the generation of logical divisions. It describes three methods: segmentation by spacing, by style difference (considering character size and boldness), and by keywords, emphasizing the relevance of keyword segmentation for this research.", "node_type": "semantic_unit", "metadata": {"semantic_type": "procedure", "start_paragraph": 27, "end_paragraph": 35, "original_title": "Segmentation Methods"}, "nodes": [{"title": "Document Segmentation Overview", "start_index": 3, "end_index": 3, "text": "Segmentation is the generation of hierarchy of logical divisions from a document. This layout segmen -\n\ntation captures the divisions of the documentâ€™s logical structure. It can be done in three ways [15]:", "summary": "Introduces the concept of document segmentation and its purpose in creating a logical hierarchy of divisions. Mentions three general approaches.", "node_type": "semantic_unit", "metadata": {"semantic_type": "procedure", "start_paragraph": 0, "end_paragraph": 1, "original_title": "Document Segmentation Overview"}, "nodes": [{"title": "Document Segmentation", "start_index": 3, "end_index": 3, "text": "Segmentation is the generation of hierarchy of logical divisions from a document. This layout segmen -\n\ntation captures the divisions of the documentâ€™s logical structure. It can be done in three ways [15]:", "summary": "The process of creating a hierarchical structure of logical divisions within a document.", "node_type": "keyword", "_text_locked": true, "metadata": {"term": "Document Segmentation", "context": "The process of creating a hierarchical structure of logical divisions within a document.", "relevance": "This is the core concept of the section, defining the main topic.", "parent_title": "Document Segmentation Overview", "parent_node_type": "semantic_unit"}, "nodes": [], "node_id": "0069"}, {"title": "Logical Divisions", "start_index": 3, "end_index": 3, "text": "Segmentation is the generation of hierarchy of logical divisions from a document. This layout segmen -\n\ntation captures the divisions of the documentâ€™s logical structure. It can be done in three ways [15]:", "summary": "The distinct parts or sections that make up the logical structure of a document.", "node_type": "keyword", "_text_locked": true, "metadata": {"term": "Logical Divisions", "context": "The distinct parts or sections that make up the logical structure of a document.", "relevance": "These are the elements that document segmentation aims to identify and organize.", "parent_title": "Document Segmentation Overview", "parent_node_type": "semantic_unit"}, "nodes": [], "node_id": "0070"}, {"title": "Document Hierarchy", "start_index": 3, "end_index": 3, "text": "Segmentation is the generation of hierarchy of logical divisions from a document. This layout segmen -\n\ntation captures the divisions of the documentâ€™s logical structure. It can be done in three ways [15]:", "summary": "An organized structure representing the relationships between different parts of a document.", "node_type": "keyword", "_text_locked": true, "metadata": {"term": "Document Hierarchy", "context": "An organized structure representing the relationships between different parts of a document.", "relevance": "Segmentation generates this hierarchy, which is crucial for understanding document organization.", "parent_title": "Document Segmentation Overview", "parent_node_type": "semantic_unit"}, "nodes": [], "node_id": "0071"}, {"title": "Layout Segmentation", "start_index": 3, "end_index": 3, "text": "Segmentation is the generation of hierarchy of logical divisions from a document. This layout segmen -\n\ntation captures the divisions of the documentâ€™s logical structure. It can be done in three ways [15]:", "summary": "A type of segmentation that focuses on capturing the divisions within a document's logical structure.", "node_type": "keyword", "_text_locked": true, "metadata": {"term": "Layout Segmentation", "context": "A type of segmentation that focuses on capturing the divisions within a document's logical structure.", "relevance": "This specifies a particular approach or focus within the broader concept of document segmentation.", "parent_title": "Document Segmentation Overview", "parent_node_type": "semantic_unit"}, "nodes": [], "node_id": "0072"}], "node_id": "0068"}, {"title": "Segmentation by Spacing", "start_index": 3, "end_index": 3, "text": "â€¢ Segmentation by spacing: by using spacing information, scanned images are separated into sev-\n\neral areas which can be text, figure/table, or formulae areas.", "summary": "Explains the method of segmenting documents based on spacing information to differentiate between text, figures, tables, and formulas.", "node_type": "semantic_unit", "metadata": {"semantic_type": "procedure", "start_paragraph": 2, "end_paragraph": 3, "original_title": "Segmentation by Spacing"}, "nodes": [{"title": "Segmentation by spacing", "start_index": 3, "end_index": 3, "text": "â€¢ Segmentation by spacing: by using spacing information, scanned images are separated into sev-\n\neral areas which can be text, figure/table, or formulae areas.", "summary": "A method to separate scanned images into distinct areas based on spacing information.", "node_type": "keyword", "_text_locked": true, "metadata": {"term": "Segmentation by spacing", "context": "A method to separate scanned images into distinct areas based on spacing information.", "relevance": "This is the primary technique discussed in the section for image analysis.", "parent_title": "Segmentation by Spacing", "parent_node_type": "semantic_unit"}, "nodes": [], "node_id": "0074"}, {"title": "Scanned images", "start_index": 3, "end_index": 3, "text": "â€¢ Segmentation by spacing: by using spacing information, scanned images are separated into sev-\n\neral areas which can be text, figure/table, or formulae areas.", "summary": "Digital representations of documents or pages obtained through a scanning process.", "node_type": "keyword", "_text_locked": true, "metadata": {"term": "Scanned images", "context": "Digital representations of documents or pages obtained through a scanning process.", "relevance": "The input data that is being processed and segmented in this method.", "parent_title": "Segmentation by Spacing", "parent_node_type": "semantic_unit"}, "nodes": [], "node_id": "0075"}, {"title": "Text areas", "start_index": 3, "end_index": 3, "text": "â€¢ Segmentation by spacing: by using spacing information, scanned images are separated into sev-\n\neral areas which can be text, figure/table, or formulae areas.", "summary": "Regions within an image identified as containing written characters.", "node_type": "keyword", "_text_locked": true, "metadata": {"term": "Text areas", "context": "Regions within an image identified as containing written characters.", "relevance": "One of the key types of areas that segmentation aims to isolate.", "parent_title": "Segmentation by Spacing", "parent_node_type": "semantic_unit"}, "nodes": [], "node_id": "0076"}, {"title": "Figure/table areas", "start_index": 3, "end_index": 3, "text": "â€¢ Segmentation by spacing: by using spacing information, scanned images are separated into sev-\n\neral areas which can be text, figure/table, or formulae areas.", "summary": "Regions within an image identified as containing graphical elements or tabular data.", "node_type": "keyword", "_text_locked": true, "metadata": {"term": "Figure/table areas", "context": "Regions within an image identified as containing graphical elements or tabular data.", "relevance": "Another important type of area that segmentation distinguishes.", "parent_title": "Segmentation by Spacing", "parent_node_type": "semantic_unit"}, "nodes": [], "node_id": "0077"}, {"title": "Formulae areas", "start_index": 3, "end_index": 3, "text": "â€¢ Segmentation by spacing: by using spacing information, scanned images are separated into sev-\n\neral areas which can be text, figure/table, or formulae areas.", "summary": "Regions within an image identified as containing mathematical equations or expressions.", "node_type": "keyword", "_text_locked": true, "metadata": {"term": "Formulae areas", "context": "Regions within an image identified as containing mathematical equations or expressions.", "relevance": "A specific and often challenging type of area that segmentation can identify.", "parent_title": "Segmentation by Spacing", "parent_node_type": "semantic_unit"}, "nodes": [], "node_id": "0078"}], "node_id": "0073"}, {"title": "Segmentation by Style Difference", "start_index": 3, "end_index": 3, "text": "â€¢ Segmentation by style difference: for each text area, the average size of the characters contained in\n\nthe area is calculated. The size of a character can be determined by its height. Also boldness can be\n\ncalculated by the horizontal width of a character. In an area where the styles (bold, italic and size) of lines are obviously different from those of other lines, they are separately segmented.", "summary": "Details the technique of segmenting text areas based on differences in character styles such as size, boldness, and italics.", "node_type": "semantic_unit", "metadata": {"semantic_type": "procedure", "start_paragraph": 4, "end_paragraph": 6, "original_title": "Segmentation by Style Difference"}, "nodes": [{"title": "Segmentation by Style Difference", "start_index": 3, "end_index": 3, "text": "â€¢ Segmentation by style difference: for each text area, the average size of the characters contained in\n\nthe area is calculated. The size of a character can be determined by its height. Also boldness can be\n\ncalculated by the horizontal width of a character. In an area where the styles (bold, italic and size) of lines are obviously different from those of other lines, they are separately segmented.", "summary": "This section describes a method for segmenting text areas based on differences in character style, including size, boldness, and italicization. It details the calculation of average character size and boldness within an area to identify distinct stylistic groups.", "node_type": "semantic_unit", "metadata": {"semantic_type": "analysis", "start_paragraph": 0, "end_paragraph": 2, "original_title": "Segmentation by Style Difference"}, "nodes": [{"title": "Segmentation by style difference", "start_index": 3, "end_index": 3, "text": "â€¢ Segmentation by style difference: for each text area, the average size of the characters contained in\n\nthe area is calculated. The size of a character can be determined by its height. Also boldness can be\n\ncalculated by the horizontal width of a character. In an area where the styles (bold, italic and size) of lines are obviously different from those of other lines, they are separately segmented.", "summary": "A method to divide text areas based on variations in character styles.", "node_type": "keyword", "_text_locked": true, "metadata": {"term": "Segmentation by style difference", "context": "A method to divide text areas based on variations in character styles.", "relevance": "This is the primary methodology discussed in the section for text segmentation.", "parent_title": "Segmentation by Style Difference", "parent_node_type": "semantic_unit"}, "nodes": [], "node_id": "0081"}, {"title": "Character size", "start_index": 3, "end_index": 3, "text": "â€¢ Segmentation by style difference: for each text area, the average size of the characters contained in\n\nthe area is calculated. The size of a character can be determined by its height. Also boldness can be\n\ncalculated by the horizontal width of a character. In an area where the styles (bold, italic and size) of lines are obviously different from those of other lines, they are separately segmented.", "summary": "The physical dimensions of a character, primarily determined by its height.", "node_type": "keyword", "_text_locked": true, "metadata": {"term": "Character size", "context": "The physical dimensions of a character, primarily determined by its height.", "relevance": "A key metric used to differentiate and segment text areas.", "parent_title": "Segmentation by Style Difference", "parent_node_type": "semantic_unit"}, "nodes": [], "node_id": "0082"}, {"title": "Character boldness", "start_index": 3, "end_index": 3, "text": "â€¢ Segmentation by style difference: for each text area, the average size of the characters contained in\n\nthe area is calculated. The size of a character can be determined by its height. Also boldness can be\n\ncalculated by the horizontal width of a character. In an area where the styles (bold, italic and size) of lines are obviously different from those of other lines, they are separately segmented.", "summary": "The thickness or darkness of a character, often determined by its horizontal width.", "node_type": "keyword", "_text_locked": true, "metadata": {"term": "Character boldness", "context": "The thickness or darkness of a character, often determined by its horizontal width.", "relevance": "Another style attribute used in conjunction with size for segmentation.", "parent_title": "Segmentation by Style Difference", "parent_node_type": "semantic_unit"}, "nodes": [], "node_id": "0083"}, {"title": "Line styles", "start_index": 3, "end_index": 3, "text": "â€¢ Segmentation by style difference: for each text area, the average size of the characters contained in\n\nthe area is calculated. The size of a character can be determined by its height. Also boldness can be\n\ncalculated by the horizontal width of a character. In an area where the styles (bold, italic and size) of lines are obviously different from those of other lines, they are separately segmented.", "summary": "The visual attributes of text lines, including bold, italic, and size.", "node_type": "keyword", "_text_locked": true, "metadata": {"term": "Line styles", "context": "The visual attributes of text lines, including bold, italic, and size.", "relevance": "These are the specific stylistic elements that trigger segmentation.", "parent_title": "Segmentation by Style Difference", "parent_node_type": "semantic_unit"}, "nodes": [], "node_id": "0084"}, {"title": "Text area segmentation", "start_index": 3, "end_index": 3, "text": "â€¢ Segmentation by style difference: for each text area, the average size of the characters contained in\n\nthe area is calculated. The size of a character can be determined by its height. Also boldness can be\n\ncalculated by the horizontal width of a character. In an area where the styles (bold, italic and size) of lines are obviously different from those of other lines, they are separately segmented.", "summary": "The process of dividing a larger text region into smaller, distinct parts.", "node_type": "keyword", "_text_locked": true, "metadata": {"term": "Text area segmentation", "context": "The process of dividing a larger text region into smaller, distinct parts.", "relevance": "The overall goal of the methodology described in the section.", "parent_title": "Segmentation by Style Difference", "parent_node_type": "semantic_unit"}, "nodes": [], "node_id": "0085"}], "node_id": "0080"}], "node_id": "0079"}, {"title": "Segmentation by Keywords", "start_index": 3, "end_index": 3, "text": "â€¢ Segmentation by keywords: in an area, where a special keyword (e.g. abstract, references) comes at\n\nthe beginning of a line, basically the area is segmented before the line as used in this research. This method is most relevant for this research because there are generally certain keywords specifically used in documents.", "summary": "Describes segmentation using specific keywords that appear at the beginning of lines, highlighting its relevance due to the presence of such keywords in documents.", "node_type": "semantic_unit", "metadata": {"semantic_type": "procedure", "start_paragraph": 7, "end_paragraph": 8, "original_title": "Segmentation by Keywords"}, "nodes": [{"title": "Segmentation by keywords", "start_index": 3, "end_index": 3, "text": "â€¢ Segmentation by keywords: in an area, where a special keyword (e.g. abstract, references) comes at\n\nthe beginning of a line, basically the area is segmented before the line as used in this research. This method is most relevant for this research because there are generally certain keywords specifically used in documents.", "summary": "A method where an area is segmented before a line that begins with a special keyword.", "node_type": "keyword", "_text_locked": true, "metadata": {"term": "Segmentation by keywords", "context": "A method where an area is segmented before a line that begins with a special keyword.", "relevance": "This is the primary methodology discussed and applied in this section.", "parent_title": "Segmentation by Keywords", "parent_node_type": "semantic_unit"}, "nodes": [], "node_id": "0087"}, {"title": "Special keyword", "start_index": 3, "end_index": 3, "text": "â€¢ Segmentation by keywords: in an area, where a special keyword (e.g. abstract, references) comes at\n\nthe beginning of a line, basically the area is segmented before the line as used in this research. This method is most relevant for this research because there are generally certain keywords specifically used in documents.", "summary": "A predefined word, such as 'abstract' or 'references', that signals the start of a new section.", "node_type": "keyword", "_text_locked": true, "metadata": {"term": "Special keyword", "context": "A predefined word, such as 'abstract' or 'references', that signals the start of a new section.", "relevance": "These keywords are the triggers for the segmentation process.", "parent_title": "Segmentation by Keywords", "parent_node_type": "semantic_unit"}, "nodes": [], "node_id": "0088"}, {"title": "Area segmentation", "start_index": 3, "end_index": 3, "text": "â€¢ Segmentation by keywords: in an area, where a special keyword (e.g. abstract, references) comes at\n\nthe beginning of a line, basically the area is segmented before the line as used in this research. This method is most relevant for this research because there are generally certain keywords specifically used in documents.", "summary": "The process of dividing a document or text into distinct regions based on specific criteria.", "node_type": "keyword", "_text_locked": true, "metadata": {"term": "Area segmentation", "context": "The process of dividing a document or text into distinct regions based on specific criteria.", "relevance": "This is the outcome and purpose of using keywords for segmentation.", "parent_title": "Segmentation by Keywords", "parent_node_type": "semantic_unit"}, "nodes": [], "node_id": "0089"}, {"title": "Document structure", "start_index": 3, "end_index": 3, "text": "â€¢ Segmentation by keywords: in an area, where a special keyword (e.g. abstract, references) comes at\n\nthe beginning of a line, basically the area is segmented before the line as used in this research. This method is most relevant for this research because there are generally certain keywords specifically used in documents.", "summary": "The inherent organization and layout of a document, often including standard sections.", "node_type": "keyword", "_text_locked": true, "metadata": {"term": "Document structure", "context": "The inherent organization and layout of a document, often including standard sections.", "relevance": "Understanding document structure is crucial for effective keyword-based segmentation.", "parent_title": "Segmentation by Keywords", "parent_node_type": "semantic_unit"}, "nodes": [], "node_id": "0090"}], "node_id": "0086"}], "node_id": "0067"}, {"title": "Segmentation", "start_index": 3, "end_index": 5, "node_id": "0091", "text": "Bolanle Adefowoke Ojokoh et al.\nJournal of Information Science, 35 (5) 2009, pp. 563â€“570 Â© CILIP, DOI: 10.1177/0165551509105195 565where p is the uploaded document needing conversion.\n(ii) Cp â†’ t  (3)\nand\nt = {b1, b2, ..., bn} (4)\nwhere t is the text document and bn refers to block n in the document.\n(iii) S is a 2-tuple (M, G) (5)\nwhere M refers to the map function and G refers to the group function.\n(a) M: bi â†’ sk (6)\nwhere sk refers to the set of identified pattern strings\n(b) G: {bi | sk = si, ..., n} where i â‰  k (7)\nStep (b) is repeated until all grouping is done.\nâˆƒbn\ni: t Â· n is the number of groups in which bi occurs\n(iv) P: merge bi1,..,n â†’ bi (8)\nthen,\nE: (bi * mdi * si) â†’ {mdi,bi} (9)\nmd âˆˆ {abstract, tableofcontents, introduction, references} (10)\nwhere E is the extract function and md refers to the set of extracted metadata.\nTitle extraction is done with a different method as follows:\ntitle âˆˆ {[Aâ€“Z] * |first 1â€“100 characters|1st three lines (11)\n(vi) âˆ€mdi extracted, B displays O âˆˆ {title, mdi, bi} (12)\nT:(D:u, mdi, ...4, bi, ...n)  (13)\nwhere T is the store function and D is the database.\nThis research work used an approach implementing the model combining segmentation by keyword \ntogether with the use of regular expressions, as presented earlier, to extract some set of metadata \nfrom documents. Title extraction is another challenging task that may not be easily done using only segmentation by keyword as titles of documents are not usually labelled. In this research some sets of rules were proposed for title extraction. Figure 1 describes the architecture of the document meta-data extractor.\nSegmentation is the generation of hierarchy of logical divisions from a document. This layout segmen -\ntation captures the divisions of the documentâ€™s logical structure. It can be done in three ways [15]:\nâ€¢ Segmentation by spacing: by using spacing information, scanned images are separated into sev-\neral areas which can be text, figure/table, or formulae areas.\nâ€¢ Segmentation by style difference: for each text area, the average size of the characters contained in \nthe area is calculated. The size of a character can be determined by its height. Also boldness can be \ncalculated by the horizontal width of a character. In an area where the styles (bold, italic and size) of lines are obviously different from those of other lines, they are separately segmented.\nâ€¢ Segmentation by keywords: in an area, where a special keyword (e.g. abstract, references) comes at \nthe beginning of a line, basically the area is segmented before the line as used in this research. This method is most relevant for this research because there are generally certain keywords specifically used in documents.Bolanle Adefowoke Ojokoh et al.\nJournal of Information Science, 35 (5) 2009, pp. 563â€“570 Â© CILIP, DOI: 10.1177/0165551509105195 566The segmentation algorithm proposed by Summers [1] was used for the purpose of logical struc-\nture extraction. This research names the algorithm used here as segmentation by keyword. It adopts \nsome relevant techniques from Summersâ€™s algorithm which is embedded in the entire algorithm used for document metadata extraction as follows:\nâ€¢ Algorithm 1: Creating document input and converting uploaded file by typing document URL or locating from folder and converting document to text format\nâ€¢ Algorithm 2: Segmenting the document by keywords.\nDivide the text document into blocks.\nRepresent each block by an appropriate string of indentation alphabet characters.Find sets of blocks that form repeating patterns.Find runs of isolated blocks that conform to patterns found elsewhere.Group together the blocks in each element of each pattern and group the isolated block forming \nthe next level of the tree surrounding blocks.\nRepeat (*) in order until no changes are generated.Group together the elements of each pattern forming another tree level.Repeat until no new changes are generated.Electronic\ndocuments\nParserFile\nConverter\nMetadataSegmentation\nEngineBrowser\nFig. 1. Document metadata extractor architecture.Bolanle Adefowoke Ojokoh et al.\nJournal of Information Science, 35 (5) 2009, pp. 563â€“570 Â© CILIP, DOI: 10.1177/0165551509105195 567â€¢ Algorithm 3: Extracting document metadata.\nLocate the keywords associated with metadata.\nLocate the block of document corresponding to the keyword(s) identified.Extract keyword found in the document alongside the block of document.â€¢ Algorithm 4: Displaying and storing result of extraction.\nDisplay metadata and extracted block of document in the browser window.Store the extracted metadata and block in the database.\nThe keywords used in the grouping include: Table of Contents, Abstract, Preface, Chapter 1(One), \nIntroduction, Conclusion, References, Bibliography, Citation and Appendix (A/1). They were used with their respective regular expressions used to match them.\n4. System implementation and evaluation\nThe document metadata extractor receives an uploaded document and converts it to text. On click-ing on any of the metadata listed on the left side of the browser window as hyperlinks, the extractor scans through the document and displays the corresponding content of the document. \nThe document metadata extractor was tested over a set of randomly selected theses, dissertations \nand a few technical reports downloaded from the web. Theses were, however, the main focus of the experiments (about 80% of the sample).\nThe evaluation of the system was done using the following criteria: recall, precision, accuracy, \nand F-measure [as defined in equations (14)â€“(17)].\nAn exact performance comparison may not be possible, because of differences in the documents \nused for testing the different systems [16]. However, attempts are made to refer to related work and how the results compare with theirs. The results of the experimental evaluation of the reference metadata extractor are presented as follows.\n \nPrecision =A\nA+C (14)\n Recall =A\nA+B (15)\n Accuracy =A+D\nA+B+C+D (16)\n F/C0measur e=2/C3Precision /C3Recall\nPrecis ion+Recall (17)\nwhere A is the number of correctly extracted fields, B is the number of fields with existing, but not \nextracted data, C is the number of fields with wrongly extracted data, while D is the number of fields \nwith not existing and not extracted data.\nThe test for automatic extraction correctness was based on a manual verification of the correct-\nness of the extracted metadata against the original document. Due to such manual verification, which was lengthy and tedious, the sample size was limited to 40 documents.\nTables 1â€“4 summarize the overall precision, recall, accuracy and F-measure results respectively."}], "text": "Bolanle Adefowoke Ojokoh et al.\nJournal of Information Science, 35 (5) 2009, pp. 563â€“570 Â© CILIP, DOI: 10.1177/0165551509105195 565where p is the uploaded document needing conversion.\n(ii) Cp â†’ t  (3)\nand\nt = {b1, b2, ..., bn} (4)\nwhere t is the text document and bn refers to block n in the document.\n(iii) S is a 2-tuple (M, G) (5)\nwhere M refers to the map function and G refers to the group function.\n(a) M: bi â†’ sk (6)\nwhere sk refers to the set of identified pattern strings\n(b) G: {bi | sk = si, ..., n} where i â‰  k (7)\nStep (b) is repeated until all grouping is done.\nâˆƒbn\ni: t Â· n is the number of groups in which bi occurs\n(iv) P: merge bi1,..,n â†’ bi (8)\nthen,\nE: (bi * mdi * si) â†’ {mdi,bi} (9)\nmd âˆˆ {abstract, tableofcontents, introduction, references} (10)\nwhere E is the extract function and md refers to the set of extracted metadata.\nTitle extraction is done with a different method as follows:\ntitle âˆˆ {[Aâ€“Z] * |first 1â€“100 characters|1st three lines (11)\n(vi) âˆ€mdi extracted, B displays O âˆˆ {title, mdi, bi} (12)\nT:(D:u, mdi, ...4, bi, ...n)  (13)\nwhere T is the store function and D is the database.\nThis research work used an approach implementing the model combining segmentation by keyword \ntogether with the use of regular expressions, as presented earlier, to extract some set of metadata \nfrom documents. Title extraction is another challenging task that may not be easily done using only segmentation by keyword as titles of documents are not usually labelled. In this research some sets of rules were proposed for title extraction. Figure 1 describes the architecture of the document meta-data extractor.\nSegmentation is the generation of hierarchy of logical divisions from a document. This layout segmen -\ntation captures the divisions of the documentâ€™s logical structure. It can be done in three ways [15]:\nâ€¢ Segmentation by spacing: by using spacing information, scanned images are separated into sev-\neral areas which can be text, figure/table, or formulae areas.\nâ€¢ Segmentation by style difference: for each text area, the average size of the characters contained in \nthe area is calculated. The size of a character can be determined by its height. Also boldness can be \ncalculated by the horizontal width of a character. In an area where the styles (bold, italic and size) of lines are obviously different from those of other lines, they are separately segmented.\nâ€¢ Segmentation by keywords: in an area, where a special keyword (e.g. abstract, references) comes at \nthe beginning of a line, basically the area is segmented before the line as used in this research. This method is most relevant for this research because there are generally certain keywords specifically used in documents.", "node_id": "0046"}, {"title": "System implementation and evaluation", "start_index": 5, "end_index": 7, "text": "Bolanle Adefowoke Ojokoh et al.\nJournal of Information Science, 35 (5) 2009, pp. 563â€“570 Â© CILIP, DOI: 10.1177/0165551509105195 567â€¢ Algorithm 3: Extracting document metadata.\nLocate the keywords associated with metadata.\nLocate the block of document corresponding to the keyword(s) identified.Extract keyword found in the document alongside the block of document.â€¢ Algorithm 4: Displaying and storing result of extraction.\nDisplay metadata and extracted block of document in the browser window.Store the extracted metadata and block in the database.\nThe keywords used in the grouping include: Table of Contents, Abstract, Preface, Chapter 1(One), \nIntroduction, Conclusion, References, Bibliography, Citation and Appendix (A/1). They were used with their respective regular expressions used to match them.\n4. System implementation and evaluation\nThe document metadata extractor receives an uploaded document and converts it to text. On click-ing on any of the metadata listed on the left side of the browser window as hyperlinks, the extractor scans through the document and displays the corresponding content of the document. \nThe document metadata extractor was tested over a set of randomly selected theses, dissertations \nand a few technical reports downloaded from the web. Theses were, however, the main focus of the experiments (about 80% of the sample).\nThe evaluation of the system was done using the following criteria: recall, precision, accuracy, \nand F-measure [as defined in equations (14)â€“(17)].\nAn exact performance comparison may not be possible, because of differences in the documents \nused for testing the different systems [16]. However, attempts are made to refer to related work and how the results compare with theirs. The results of the experimental evaluation of the reference metadata extractor are presented as follows.\n \nPrecision =A\nA+C (14)\n Recall =A\nA+B (15)\n Accuracy =A+D\nA+B+C+D (16)\n F/C0measur e=2/C3Precision /C3Recall\nPrecis ion+Recall (17)\nwhere A is the number of correctly extracted fields, B is the number of fields with existing, but not \nextracted data, C is the number of fields with wrongly extracted data, while D is the number of fields \nwith not existing and not extracted data.\nThe test for automatic extraction correctness was based on a manual verification of the correct-\nness of the extracted metadata against the original document. Due to such manual verification, which was lengthy and tedious, the sample size was limited to 40 documents.\nTables 1â€“4 summarize the overall precision, recall, accuracy and F-measure results respectively.Bolanle Adefowoke Ojokoh et al.\nJournal of Information Science, 35 (5) 2009, pp. 563â€“570 Â© CILIP, DOI: 10.1177/0165551509105195 568Table 1 \nMetadata extraction precision over 40 theses and related documents\n Precision\nTitle 0.75\nTable of Contents 0.73\nPreface 0.86\nAbstract 0.77\nAcknowledgment 0.64\nIntroduction 0.68\nConclusion 0.90\nReferences 1.0\n \nTable 2 \nMetadata extraction recall over 40 theses and related documents\n Recall\nTitle 0.75\nTable of Contents 0.81\nPreface 1.0\nAbstract 0.92\nAcknowledgment 0.90\nIntroduction 0.68\nConclusion 0.68\nReferences 0.91\n \nTable 3 \nMetadata extraction accuracy over 40 theses and related documents\n Accuracy\nTitle 0.75\nTable of Contents 0.68\nPreface 0.98\nAbstract 0.78\nAcknowledgment 0.70\nIntroduction 0.60\nConclusion 0.70\nReferences 0.93\n \nTable 4 \nMetadata extraction F-measure over 40 theses and related documents\n F-measure\nTitle 0.75\nTable of Contents 0.77\nPreface 0.92\nAbstract 0.84\nAcknowledgment 0.75\nIntroduction 0.68\nConclusion 0.77\nReferences 0.95\n Bolanle Adefowoke Ojokoh et al.\nJournal of Information Science, 35 (5) 2009, pp. 563â€“570 Â© CILIP, DOI: 10.1177/0165551509105195 569From the results, â€˜Referencesâ€™ was extracted with the highest precision. Its extraction is also rela-\ntively high compared to others in terms of recall, accuracy and F-measure. This could be largely due \nto the fact that they appear, in most cases, at the end of the document.\nMost of the â€˜Prefaceâ€™ extraction cases fall under the not existing and not extracted cases because \nvery few of the documents (only six) contained a preface. As a result, recall and accuracy were high-\nest for â€˜Prefaceâ€™.\nâ€˜Introductionâ€™ was extracted generally with the least values in terms of the evaluation criteria \n(0.68 for precision, recall and F-measure and 0.60 for accuracy). â€˜Conclusionâ€™ extraction was low too \nin terms of accuracy, although relatively high in precision (0.90). Reasons for these could be attrib-uted to the fact that in many cases introductions and conclusions exist in some theses (sometimes in every chapter), and sometimes too, other keywords that might not be recognized by the system are attached to them. In addition, some patterns not embedded in the rule-based system might be encountered leading to incorrect extraction.\nâ€˜Abstractâ€™ extraction was performed with relatively high recall and F-measure. The precision and \naccuracy of its extraction was mostly affected negatively because in a few theses, the abstract part was not specifically labelled â€˜Abstractâ€™ or was not labelled at all.\nâ€˜Table of Contentsâ€™ was extracted with relatively high recall, but with fair precision and F-measure. \nThe accuracy with which it was extracted was a bit low, because in some cases, the system extracted some other parts, which were not actually part of the table of contents, with it.\nâ€˜Titleâ€™ extraction was particularly challenging as a result of the fact that titles of documents are \nnot usually labelled as such. Nevertheless, the task was done with consistent precision, recall, accu-racy and F-measure showing the effectiveness of the rule-based system. During the evaluation, it \nwas also discovered that, for most of the wrongly extracted cases for titles, the information extracted was still relevant, for instance when the authorsâ€™ names or institution of study were extracted.\nSome of the studies with presented results include the work of Hu et al. [10] who extracted title \nfrom Word documents with precision and recall of 0.810 and 0.837, respectively, and precision and recall of 0.875 and 0.895 from PowerPoint documents, respectively in an experiment on intranet data using machine learning technique.\nSome systems whose work could be fairly compared to this system include that of Berkowitz and \nElkhadiri [17] who extracted authors and titles from documents; they reported recall of 25.96% for exact extraction of author names; for 24.99% of the papers they managed to extract either part of the author name(s), or the name(s) plus extra text. All these focused on extraction of a single metadata. Giuffrida and colleagues [14] extracted title, author, affiliation, author-to-affiliation mapping and table of contents from Postscript files using a knowledge-based approach obtaining 92%, 87%, 75%, 71% and 76% accuracy respectively. Hence, the methods proposed by this research for general documents metadata extraction with particular emphasis on theses can handle the task with rela-tively high efficiency. Compared to existing systems, it extracts more metadata, and with relatively comparable effectiveness.\n5. Conclusions and further research directions\nThis paper describes a method for general metadata extraction from general documents using a combination of the segmentation by keyword algorithm and regular expressions. Extraction of title is done using a different set of rules, implemented before segmentation by keyword is carried out because title extraction is often not affected by keywords. The rules used for title extraction proved consistently effective for theses and dissertations. The proposed model for extracting other metadata was tested on some randomly downloaded theses and related documents and used to extract Abstract, Preface, Table of Contents, Introduction, Conclusion, References and Acknowledgments. The experimental results show that the extraction was done with a relatively high degree of precision, recall and accuracy except for â€˜Introductionâ€™ and â€˜Conclusionâ€™ with low recall because of the usual existence of multiples of them in theses documents. Compared to existing systems, this system ", "nodes": [{"title": "Algorithm and System Implementation", "start_index": 5, "end_index": 5, "text": "Bolanle Adefowoke Ojokoh et al.\nJournal of Information Science, 35 (5) 2009, pp. 563â€“570 Â© CILIP, DOI: 10.1177/0165551509105195 567â€¢ Algorithm 3: Extracting document metadata.\nLocate the keywords associated with metadata.\nLocate the block of document corresponding to the keyword(s) identified.Extract keyword found in the document alongside the block of document.â€¢ Algorithm 4: Displaying and storing result of extraction.\nDisplay metadata and extracted block of document in the browser window.Store the extracted metadata and block in the database.\nThe keywords used in the grouping include: Table of Contents, Abstract, Preface, Chapter 1(One), \nIntroduction, Conclusion, References, Bibliography, Citation and Appendix (A/1). They were used with their respective regular expressions used to match them.\n4. System implementation and evaluation\nThe document metadata extractor receives an uploaded document and converts it to text. On click-ing on any of the metadata listed on the left side of the browser window as hyperlinks, the extractor scans through the document and displays the corresponding content of the document. \nThe document metadata extractor was tested over a set of randomly selected theses, dissertations \nand a few technical reports downloaded from the web. Theses were, however, the main focus of the experiments (about 80% of the sample).\nThe evaluation of the system was done using the following criteria: recall, precision, accuracy, \nand F-measure [as defined in equations (14)â€“(17)].\nAn exact performance comparison may not be possible, because of differences in the documents \nused for testing the different systems [16]. However, attempts are made to refer to related work and how the results compare with theirs. The results of the experimental evaluation of the reference metadata extractor are presented as follows.\n \nPrecision =A\nA+C (14)\n Recall =A\nA+B (15)\n Accuracy =A+D\nA+B+C+D (16)\n F/C0measur e=2/C3Precision /C3Recall\nPrecis ion+Recall (17)\nwhere A is the number of correctly extracted fields, B is the number of fields with existing, but not \nextracted data, C is the number of fields with wrongly extracted data, while D is the number of fields \nwith not existing and not extracted data.\nThe test for automatic extraction correctness was based on a manual verification of the correct-\nness of the extracted metadata against the original document. Due to such manual verification, which was lengthy and tedious, the sample size was limited to 40 documents.\nTables 1â€“4 summarize the overall precision, recall, accuracy and F-measure results respectively.", "summary": "This section details the algorithms used for metadata extraction and storage, and describes the implementation of the document metadata extractor system. It also outlines the evaluation criteria and the manual verification process.", "node_type": "semantic_unit", "metadata": {"semantic_type": "procedure", "start_paragraph": 0, "end_paragraph": 0, "original_title": "Algorithm and System Implementation"}, "nodes": [{"title": "Algorithm for Metadata Extraction", "start_index": 5, "end_index": 5, "text": "Journal of Information Science, 35 (5) 2009, pp. 563â€“570 Â© CILIP, DOI: 10.1177/0165551509105195 567â€¢ Algorithm 3: Extracting document metadata.\n\nLocate the keywords associated with metadata.\n\nLocate the block of document corresponding to the keyword(s) identified.Extract keyword found in the document alongside the block of document.â€¢ Algorithm 4: Displaying and storing result of extraction.\n\nDisplay metadata and extracted block of document in the browser window.Store the extracted metadata and block in the database.", "summary": "Describes algorithms for extracting document metadata by locating keywords and associated blocks, and then displaying and storing the results.", "node_type": "semantic_unit", "metadata": {"semantic_type": "procedure", "start_paragraph": 1, "end_paragraph": 4, "original_title": "Algorithm for Metadata Extraction"}, "nodes": [{"title": "Metadata Extraction Algorithm", "start_index": 5, "end_index": 5, "text": "Journal of Information Science, 35 (5) 2009, pp. 563â€“570 Â© CILIP, DOI: 10.1177/0165551509105195 567â€¢ Algorithm 3: Extracting document metadata.\n\nLocate the keywords associated with metadata.", "summary": "This section describes Algorithm 3 for extracting document metadata by locating keywords and associated metadata. It details the process of identifying keywords and extracting the corresponding document blocks.", "node_type": "semantic_unit", "metadata": {"semantic_type": "procedure", "start_paragraph": 0, "end_paragraph": 1, "original_title": "Metadata Extraction Algorithm"}, "nodes": [{"title": "Metadata Extraction Algorithm", "start_index": 5, "end_index": 5, "text": "Journal of Information Science, 35 (5) 2009, pp. 563â€“570 Â© CILIP, DOI: 10.1177/0165551509105195 567â€¢ Algorithm 3: Extracting document metadata.\n\nLocate the keywords associated with metadata.", "summary": "A specific algorithm designed for the purpose of extracting metadata from documents.", "node_type": "keyword", "_text_locked": true, "metadata": {"term": "Metadata Extraction Algorithm", "context": "A specific algorithm designed for the purpose of extracting metadata from documents.", "relevance": "This is the central topic of the section, defining the core process being discussed.", "parent_title": "Metadata Extraction Algorithm", "parent_node_type": "semantic_unit"}, "nodes": [], "node_id": "0096"}, {"title": "Document Metadata", "start_index": 5, "end_index": 5, "text": "Journal of Information Science, 35 (5) 2009, pp. 563â€“570 Â© CILIP, DOI: 10.1177/0165551509105195 567â€¢ Algorithm 3: Extracting document metadata.\n\nLocate the keywords associated with metadata.", "summary": "Data that describes other data, in this case, information about a document.", "node_type": "keyword", "_text_locked": true, "metadata": {"term": "Document Metadata", "context": "Data that describes other data, in this case, information about a document.", "relevance": "The primary subject matter that the algorithm is designed to identify and extract.", "parent_title": "Metadata Extraction Algorithm", "parent_node_type": "semantic_unit"}, "nodes": [], "node_id": "0097"}, {"title": "Algorithm 3", "start_index": 5, "end_index": 5, "text": "Journal of Information Science, 35 (5) 2009, pp. 563â€“570 Â© CILIP, DOI: 10.1177/0165551509105195 567â€¢ Algorithm 3: Extracting document metadata.\n\nLocate the keywords associated with metadata.", "summary": "A specific numbered algorithm presented within the text for metadata extraction.", "node_type": "keyword", "_text_locked": true, "metadata": {"term": "Algorithm 3", "context": "A specific numbered algorithm presented within the text for metadata extraction.", "relevance": "Represents a concrete implementation or example of the metadata extraction process discussed.", "parent_title": "Metadata Extraction Algorithm", "parent_node_type": "semantic_unit"}, "nodes": [], "node_id": "0098"}, {"title": "Journal of Information Science", "start_index": 5, "end_index": 5, "text": "Journal of Information Science, 35 (5) 2009, pp. 563â€“570 Â© CILIP, DOI: 10.1177/0165551509105195 567â€¢ Algorithm 3: Extracting document metadata.\n\nLocate the keywords associated with metadata.", "summary": "A publication where this research or article is featured.", "node_type": "keyword", "_text_locked": true, "metadata": {"term": "Journal of Information Science", "context": "A publication where this research or article is featured.", "relevance": "Provides the academic context and source of the information presented.", "parent_title": "Metadata Extraction Algorithm", "parent_node_type": "semantic_unit"}, "nodes": [], "node_id": "0099"}], "node_id": "0095"}, {"title": "Result Display and Storage Algorithm", "start_index": 5, "end_index": 5, "text": "Locate the block of document corresponding to the keyword(s) identified.Extract keyword found in the document alongside the block of document.â€¢ Algorithm 4: Displaying and storing result of extraction.\n\nDisplay metadata and extracted block of document in the browser window.Store the extracted metadata and block in the database.", "summary": "This section outlines Algorithm 4 for displaying and storing the results of the extraction process. It covers displaying the metadata and extracted document blocks in a browser and storing them in a database.", "node_type": "semantic_unit", "metadata": {"semantic_type": "procedure", "start_paragraph": 2, "end_paragraph": 3, "original_title": "Result Display and Storage Algorithm"}, "nodes": [{"title": "Document Block Location", "start_index": 5, "end_index": 5, "text": "Locate the block of document corresponding to the keyword(s) identified.Extract keyword found in the document alongside the block of document.â€¢ Algorithm 4: Displaying and storing result of extraction.\n\nDisplay metadata and extracted block of document in the browser window.Store the extracted metadata and block in the database.", "summary": "The process of finding the specific part of a document related to identified keywords.", "node_type": "keyword", "_text_locked": true, "metadata": {"term": "Document Block Location", "context": "The process of finding the specific part of a document related to identified keywords.", "relevance": "This is the initial step in the algorithm for processing extracted information.", "parent_title": "Result Display and Storage Algorithm", "parent_node_type": "semantic_unit"}, "nodes": [], "node_id": "0101"}, {"title": "Keyword Extraction", "start_index": 5, "end_index": 5, "text": "Locate the block of document corresponding to the keyword(s) identified.Extract keyword found in the document alongside the block of document.â€¢ Algorithm 4: Displaying and storing result of extraction.\n\nDisplay metadata and extracted block of document in the browser window.Store the extracted metadata and block in the database.", "summary": "The process of identifying and pulling out significant keywords from a document.", "node_type": "keyword", "_text_locked": true, "metadata": {"term": "Keyword Extraction", "context": "The process of identifying and pulling out significant keywords from a document.", "relevance": "This is a fundamental operation that precedes the display and storage of results.", "parent_title": "Result Display and Storage Algorithm", "parent_node_type": "semantic_unit"}, "nodes": [], "node_id": "0102"}, {"title": "Algorithm 4", "start_index": 5, "end_index": 5, "text": "Locate the block of document corresponding to the keyword(s) identified.Extract keyword found in the document alongside the block of document.â€¢ Algorithm 4: Displaying and storing result of extraction.\n\nDisplay metadata and extracted block of document in the browser window.Store the extracted metadata and block in the database.", "summary": "A specific algorithm designed for displaying and storing the results of an extraction process.", "node_type": "keyword", "_text_locked": true, "metadata": {"term": "Algorithm 4", "context": "A specific algorithm designed for displaying and storing the results of an extraction process.", "relevance": "This algorithm is the central methodology described in the section.", "parent_title": "Result Display and Storage Algorithm", "parent_node_type": "semantic_unit"}, "nodes": [], "node_id": "0103"}, {"title": "Display Metadata", "start_index": 5, "end_index": 5, "text": "Locate the block of document corresponding to the keyword(s) identified.Extract keyword found in the document alongside the block of document.â€¢ Algorithm 4: Displaying and storing result of extraction.\n\nDisplay metadata and extracted block of document in the browser window.Store the extracted metadata and block in the database.", "summary": "Presenting information about the extracted data in a user interface, such as a browser window.", "node_type": "keyword", "_text_locked": true, "metadata": {"term": "Display Metadata", "context": "Presenting information about the extracted data in a user interface, such as a browser window.", "relevance": "This is one of the primary outputs of the described algorithm.", "parent_title": "Result Display and Storage Algorithm", "parent_node_type": "semantic_unit"}, "nodes": [], "node_id": "0104"}, {"title": "Extracted Document Block", "start_index": 5, "end_index": 5, "text": "Locate the block of document corresponding to the keyword(s) identified.Extract keyword found in the document alongside the block of document.â€¢ Algorithm 4: Displaying and storing result of extraction.\n\nDisplay metadata and extracted block of document in the browser window.Store the extracted metadata and block in the database.", "summary": "The specific segment of a document that contains the relevant information identified by keywords.", "node_type": "keyword", "_text_locked": true, "metadata": {"term": "Extracted Document Block", "context": "The specific segment of a document that contains the relevant information identified by keywords.", "relevance": "This is the core content that is displayed and stored.", "parent_title": "Result Display and Storage Algorithm", "parent_node_type": "semantic_unit"}, "nodes": [], "node_id": "0105"}, {"title": "Store Extracted Metadata", "start_index": 5, "end_index": 5, "text": "Locate the block of document corresponding to the keyword(s) identified.Extract keyword found in the document alongside the block of document.â€¢ Algorithm 4: Displaying and storing result of extraction.\n\nDisplay metadata and extracted block of document in the browser window.Store the extracted metadata and block in the database.", "summary": "Saving the descriptive information about the extracted data into a database.", "node_type": "keyword", "_text_locked": true, "metadata": {"term": "Store Extracted Metadata", "context": "Saving the descriptive information about the extracted data into a database.", "relevance": "This ensures the persistence and accessibility of the extraction results.", "parent_title": "Result Display and Storage Algorithm", "parent_node_type": "semantic_unit"}, "nodes": [], "node_id": "0106"}, {"title": "Store Document Block", "start_index": 5, "end_index": 5, "text": "Locate the block of document corresponding to the keyword(s) identified.Extract keyword found in the document alongside the block of document.â€¢ Algorithm 4: Displaying and storing result of extraction.\n\nDisplay metadata and extracted block of document in the browser window.Store the extracted metadata and block in the database.", "summary": "Persisting the actual extracted text segments within a database.", "node_type": "keyword", "_text_locked": true, "metadata": {"term": "Store Document Block", "context": "Persisting the actual extracted text segments within a database.", "relevance": "This action makes the extracted content available for future use or analysis.", "parent_title": "Result Display and Storage Algorithm", "parent_node_type": "semantic_unit"}, "nodes": [], "node_id": "0107"}, {"title": "Browser Window Display", "start_index": 5, "end_index": 5, "text": "Locate the block of document corresponding to the keyword(s) identified.Extract keyword found in the document alongside the block of document.â€¢ Algorithm 4: Displaying and storing result of extraction.\n\nDisplay metadata and extracted block of document in the browser window.Store the extracted metadata and block in the database.", "summary": "The user interface where the extracted information (metadata and document blocks) is presented to the user.", "node_type": "keyword", "_text_locked": true, "metadata": {"term": "Browser Window Display", "context": "The user interface where the extracted information (metadata and document blocks) is presented to the user.", "relevance": "This is the immediate output channel for the algorithm's results.", "parent_title": "Result Display and Storage Algorithm", "parent_node_type": "semantic_unit"}, "nodes": [], "node_id": "0108"}, {"title": "Database Storage", "start_index": 5, "end_index": 5, "text": "Locate the block of document corresponding to the keyword(s) identified.Extract keyword found in the document alongside the block of document.â€¢ Algorithm 4: Displaying and storing result of extraction.\n\nDisplay metadata and extracted block of document in the browser window.Store the extracted metadata and block in the database.", "summary": "The backend system used for permanently saving the extracted metadata and document blocks.", "node_type": "keyword", "_text_locked": true, "metadata": {"term": "Database Storage", "context": "The backend system used for permanently saving the extracted metadata and document blocks.", "relevance": "This provides a mechanism for long-term data management and retrieval.", "parent_title": "Result Display and Storage Algorithm", "parent_node_type": "semantic_unit"}, "nodes": [], "node_id": "0109"}], "node_id": "0100"}], "node_id": "0094"}, {"title": "Keywords for Grouping", "start_index": 5, "end_index": 5, "text": "The keywords used in the grouping include: Table of Contents, Abstract, Preface, Chapter 1(One),\n\nIntroduction, Conclusion, References, Bibliography, Citation and Appendix (A/1). They were used with their respective regular expressions used to match them.", "summary": "Lists the keywords used for document grouping, such as Table of Contents, Abstract, and Introduction, along with their corresponding regular expressions.", "node_type": "semantic_unit", "metadata": {"semantic_type": "materials", "start_paragraph": 5, "end_paragraph": 6, "original_title": "Keywords for Grouping"}, "nodes": [{"title": "Table of Contents", "start_index": 5, "end_index": 5, "text": "The keywords used in the grouping include: Table of Contents, Abstract, Preface, Chapter 1(One),\n\nIntroduction, Conclusion, References, Bibliography, Citation and Appendix (A/1). They were used with their respective regular expressions used to match them.", "summary": "A list of the sections and their corresponding page numbers in a document.", "node_type": "keyword", "_text_locked": true, "metadata": {"term": "Table of Contents", "context": "A list of the sections and their corresponding page numbers in a document.", "relevance": "This is a structural element used for organizing and navigating the document.", "parent_title": "Keywords for Grouping", "parent_node_type": "semantic_unit"}, "nodes": [], "node_id": "0111"}, {"title": "Abstract", "start_index": 5, "end_index": 5, "text": "The keywords used in the grouping include: Table of Contents, Abstract, Preface, Chapter 1(One),\n\nIntroduction, Conclusion, References, Bibliography, Citation and Appendix (A/1). They were used with their respective regular expressions used to match them.", "summary": "A brief summary of the main points of a document.", "node_type": "keyword", "_text_locked": true, "metadata": {"term": "Abstract", "context": "A brief summary of the main points of a document.", "relevance": "This keyword represents a key section that provides an overview of the content.", "parent_title": "Keywords for Grouping", "parent_node_type": "semantic_unit"}, "nodes": [], "node_id": "0112"}, {"title": "Preface", "start_index": 5, "end_index": 5, "text": "The keywords used in the grouping include: Table of Contents, Abstract, Preface, Chapter 1(One),\n\nIntroduction, Conclusion, References, Bibliography, Citation and Appendix (A/1). They were used with their respective regular expressions used to match them.", "summary": "An introductory statement in a book or other work.", "node_type": "keyword", "_text_locked": true, "metadata": {"term": "Preface", "context": "An introductory statement in a book or other work.", "relevance": "This keyword identifies an introductory section that may contain background information.", "parent_title": "Keywords for Grouping", "parent_node_type": "semantic_unit"}, "nodes": [], "node_id": "0113"}, {"title": "Chapter 1 (One)", "start_index": 5, "end_index": 5, "text": "The keywords used in the grouping include: Table of Contents, Abstract, Preface, Chapter 1(One),\n\nIntroduction, Conclusion, References, Bibliography, Citation and Appendix (A/1). They were used with their respective regular expressions used to match them.", "summary": "The first main division of a book or document.", "node_type": "keyword", "_text_locked": true, "metadata": {"term": "Chapter 1 (One)", "context": "The first main division of a book or document.", "relevance": "This keyword represents the start of the main body of content.", "parent_title": "Keywords for Grouping", "parent_node_type": "semantic_unit"}, "nodes": [], "node_id": "0114"}, {"title": "Introduction", "start_index": 5, "end_index": 5, "text": "The keywords used in the grouping include: Table of Contents, Abstract, Preface, Chapter 1(One),\n\nIntroduction, Conclusion, References, Bibliography, Citation and Appendix (A/1). They were used with their respective regular expressions used to match them.", "summary": "The action of introducing something or the state of being introduced.", "node_type": "keyword", "_text_locked": true, "metadata": {"term": "Introduction", "context": "The action of introducing something or the state of being introduced.", "relevance": "This keyword signifies the section that sets the stage for the document's topic.", "parent_title": "Keywords for Grouping", "parent_node_type": "semantic_unit"}, "nodes": [], "node_id": "0115"}, {"title": "Conclusion", "start_index": 5, "end_index": 5, "text": "The keywords used in the grouping include: Table of Contents, Abstract, Preface, Chapter 1(One),\n\nIntroduction, Conclusion, References, Bibliography, Citation and Appendix (A/1). They were used with their respective regular expressions used to match them.", "summary": "A summary of the main points of a document or argument.", "node_type": "keyword", "_text_locked": true, "metadata": {"term": "Conclusion", "context": "A summary of the main points of a document or argument.", "relevance": "This keyword represents the section that summarizes the findings or arguments.", "parent_title": "Keywords for Grouping", "parent_node_type": "semantic_unit"}, "nodes": [], "node_id": "0116"}, {"title": "References", "start_index": 5, "end_index": 5, "text": "The keywords used in the grouping include: Table of Contents, Abstract, Preface, Chapter 1(One),\n\nIntroduction, Conclusion, References, Bibliography, Citation and Appendix (A/1). They were used with their respective regular expressions used to match them.", "summary": "A list of sources cited in a document.", "node_type": "keyword", "_text_locked": true, "metadata": {"term": "References", "context": "A list of sources cited in a document.", "relevance": "This keyword identifies a crucial section for academic integrity and further reading.", "parent_title": "Keywords for Grouping", "parent_node_type": "semantic_unit"}, "nodes": [], "node_id": "0117"}, {"title": "Bibliography", "start_index": 5, "end_index": 5, "text": "The keywords used in the grouping include: Table of Contents, Abstract, Preface, Chapter 1(One),\n\nIntroduction, Conclusion, References, Bibliography, Citation and Appendix (A/1). They were used with their respective regular expressions used to match them.", "summary": "A list of books or other works referred to in a scholarly article or book.", "node_type": "keyword", "_text_locked": true, "metadata": {"term": "Bibliography", "context": "A list of books or other works referred to in a scholarly article or book.", "relevance": "This keyword is similar to References and indicates sources used in the document.", "parent_title": "Keywords for Grouping", "parent_node_type": "semantic_unit"}, "nodes": [], "node_id": "0118"}, {"title": "Citation", "start_index": 5, "end_index": 5, "text": "The keywords used in the grouping include: Table of Contents, Abstract, Preface, Chapter 1(One),\n\nIntroduction, Conclusion, References, Bibliography, Citation and Appendix (A/1). They were used with their respective regular expressions used to match them.", "summary": "A reference to a source of information.", "node_type": "keyword", "_text_locked": true, "metadata": {"term": "Citation", "context": "A reference to a source of information.", "relevance": "This keyword relates to the practice of acknowledging sources, fundamental to academic writing.", "parent_title": "Keywords for Grouping", "parent_node_type": "semantic_unit"}, "nodes": [], "node_id": "0119"}, {"title": "Appendix (A/1)", "start_index": 5, "end_index": 5, "text": "The keywords used in the grouping include: Table of Contents, Abstract, Preface, Chapter 1(One),\n\nIntroduction, Conclusion, References, Bibliography, Citation and Appendix (A/1). They were used with their respective regular expressions used to match them.", "summary": "Supplementary material at the end of a document.", "node_type": "keyword", "_text_locked": true, "metadata": {"term": "Appendix (A/1)", "context": "Supplementary material at the end of a document.", "relevance": "This keyword points to additional information that supports the main text.", "parent_title": "Keywords for Grouping", "parent_node_type": "semantic_unit"}, "nodes": [], "node_id": "0120"}, {"title": "Regular expressions", "start_index": 5, "end_index": 5, "text": "The keywords used in the grouping include: Table of Contents, Abstract, Preface, Chapter 1(One),\n\nIntroduction, Conclusion, References, Bibliography, Citation and Appendix (A/1). They were used with their respective regular expressions used to match them.", "summary": "A sequence of characters that defines a search pattern.", "node_type": "keyword", "_text_locked": true, "metadata": {"term": "Regular expressions", "context": "A sequence of characters that defines a search pattern.", "relevance": "This technical term explains the method used to match the keywords.", "parent_title": "Keywords for Grouping", "parent_node_type": "semantic_unit"}, "nodes": [], "node_id": "0121"}], "node_id": "0110"}, {"title": "System Implementation Overview", "start_index": 5, "end_index": 5, "text": "4. System implementation and evaluation\n\nThe document metadata extractor receives an uploaded document and converts it to text. On click-ing on any of the metadata listed on the left side of the browser window as hyperlinks, the extractor scans through the document and displays the corresponding content of the document.", "summary": "Details the implementation of the document metadata extractor, which converts uploaded documents to text and displays content based on metadata hyperlinks.", "node_type": "semantic_unit", "metadata": {"semantic_type": "experimental_setup", "start_paragraph": 7, "end_paragraph": 8, "original_title": "System Implementation Overview"}, "nodes": [{"title": "System implementation", "start_index": 5, "end_index": 5, "text": "4. System implementation and evaluation\n\nThe document metadata extractor receives an uploaded document and converts it to text. On click-ing on any of the metadata listed on the left side of the browser window as hyperlinks, the extractor scans through the document and displays the corresponding content of the document.", "summary": "The process of putting a designed system into operation.", "node_type": "keyword", "_text_locked": true, "metadata": {"term": "System implementation", "context": "The process of putting a designed system into operation.", "relevance": "This term is central to the section's title and overall theme.", "parent_title": "System Implementation Overview", "parent_node_type": "semantic_unit"}, "nodes": [], "node_id": "0123"}, {"title": "Document metadata extractor", "start_index": 5, "end_index": 5, "text": "4. System implementation and evaluation\n\nThe document metadata extractor receives an uploaded document and converts it to text. On click-ing on any of the metadata listed on the left side of the browser window as hyperlinks, the extractor scans through the document and displays the corresponding content of the document.", "summary": "A system component that extracts and processes metadata from documents.", "node_type": "keyword", "_text_locked": true, "metadata": {"term": "Document metadata extractor", "context": "A system component that extracts and processes metadata from documents.", "relevance": "This is the primary technical component described in the section.", "parent_title": "System Implementation Overview", "parent_node_type": "semantic_unit"}, "nodes": [], "node_id": "0124"}, {"title": "Uploaded document", "start_index": 5, "end_index": 5, "text": "4. System implementation and evaluation\n\nThe document metadata extractor receives an uploaded document and converts it to text. On click-ing on any of the metadata listed on the left side of the browser window as hyperlinks, the extractor scans through the document and displays the corresponding content of the document.", "summary": "A file that has been submitted to the system for processing.", "node_type": "keyword", "_text_locked": true, "metadata": {"term": "Uploaded document", "context": "A file that has been submitted to the system for processing.", "relevance": "Represents the input data for the metadata extractor.", "parent_title": "System Implementation Overview", "parent_node_type": "semantic_unit"}, "nodes": [], "node_id": "0125"}, {"title": "Text conversion", "start_index": 5, "end_index": 5, "text": "4. System implementation and evaluation\n\nThe document metadata extractor receives an uploaded document and converts it to text. On click-ing on any of the metadata listed on the left side of the browser window as hyperlinks, the extractor scans through the document and displays the corresponding content of the document.", "summary": "The process of transforming a document into a plain text format.", "node_type": "keyword", "_text_locked": true, "metadata": {"term": "Text conversion", "context": "The process of transforming a document into a plain text format.", "relevance": "A key function performed by the metadata extractor.", "parent_title": "System Implementation Overview", "parent_node_type": "semantic_unit"}, "nodes": [], "node_id": "0126"}, {"title": "Metadata", "start_index": 5, "end_index": 5, "text": "4. System implementation and evaluation\n\nThe document metadata extractor receives an uploaded document and converts it to text. On click-ing on any of the metadata listed on the left side of the browser window as hyperlinks, the extractor scans through the document and displays the corresponding content of the document.", "summary": "Data that provides information about other data.", "node_type": "keyword", "_text_locked": true, "metadata": {"term": "Metadata", "context": "Data that provides information about other data.", "relevance": "The extracted information that the system organizes and displays.", "parent_title": "System Implementation Overview", "parent_node_type": "semantic_unit"}, "nodes": [], "node_id": "0127"}, {"title": "Browser window", "start_index": 5, "end_index": 5, "text": "4. System implementation and evaluation\n\nThe document metadata extractor receives an uploaded document and converts it to text. On click-ing on any of the metadata listed on the left side of the browser window as hyperlinks, the extractor scans through the document and displays the corresponding content of the document.", "summary": "The graphical user interface where web content is displayed.", "node_type": "keyword", "_text_locked": true, "metadata": {"term": "Browser window", "context": "The graphical user interface where web content is displayed.", "relevance": "The environment where the user interacts with the system's output.", "parent_title": "System Implementation Overview", "parent_node_type": "semantic_unit"}, "nodes": [], "node_id": "0128"}, {"title": "Hyperlinks", "start_index": 5, "end_index": 5, "text": "4. System implementation and evaluation\n\nThe document metadata extractor receives an uploaded document and converts it to text. On click-ing on any of the metadata listed on the left side of the browser window as hyperlinks, the extractor scans through the document and displays the corresponding content of the document.", "summary": "Clickable links that navigate to specific content or resources.", "node_type": "keyword", "_text_locked": true, "metadata": {"term": "Hyperlinks", "context": "Clickable links that navigate to specific content or resources.", "relevance": "The mechanism by which users select and view specific metadata.", "parent_title": "System Implementation Overview", "parent_node_type": "semantic_unit"}, "nodes": [], "node_id": "0129"}, {"title": "Scans document", "start_index": 5, "end_index": 5, "text": "4. System implementation and evaluation\n\nThe document metadata extractor receives an uploaded document and converts it to text. On click-ing on any of the metadata listed on the left side of the browser window as hyperlinks, the extractor scans through the document and displays the corresponding content of the document.", "summary": "The action of the extractor searching through the document's content.", "node_type": "keyword", "_text_locked": true, "metadata": {"term": "Scans document", "context": "The action of the extractor searching through the document's content.", "relevance": "Describes the operational behavior of the extractor when a metadata link is clicked.", "parent_title": "System Implementation Overview", "parent_node_type": "semantic_unit"}, "nodes": [], "node_id": "0130"}, {"title": "Corresponding content", "start_index": 5, "end_index": 5, "text": "4. System implementation and evaluation\n\nThe document metadata extractor receives an uploaded document and converts it to text. On click-ing on any of the metadata listed on the left side of the browser window as hyperlinks, the extractor scans through the document and displays the corresponding content of the document.", "summary": "The specific information within the document related to the selected metadata.", "node_type": "keyword", "_text_locked": true, "metadata": {"term": "Corresponding content", "context": "The specific information within the document related to the selected metadata.", "relevance": "Highlights what is retrieved and presented to the user.", "parent_title": "System Implementation Overview", "parent_node_type": "semantic_unit"}, "nodes": [], "node_id": "0131"}], "node_id": "0122"}, {"title": "Experimental Sample Description", "start_index": 5, "end_index": 5, "text": "The document metadata extractor was tested over a set of randomly selected theses, dissertations\n\nand a few technical reports downloaded from the web. Theses were, however, the main focus of the experiments (about 80% of the sample).", "summary": "Describes the types of documents used for testing, including theses, dissertations, and technical reports, with a focus on theses (80% of the sample).", "node_type": "semantic_unit", "metadata": {"semantic_type": "materials", "start_paragraph": 9, "end_paragraph": 10, "original_title": "Experimental Sample Description"}, "nodes": [{"title": "Document metadata extractor", "start_index": 5, "end_index": 5, "text": "The document metadata extractor was tested over a set of randomly selected theses, dissertations\n\nand a few technical reports downloaded from the web. Theses were, however, the main focus of the experiments (about 80% of the sample).", "summary": "A tool designed to extract metadata from documents.", "node_type": "keyword", "_text_locked": true, "metadata": {"term": "Document metadata extractor", "context": "A tool designed to extract metadata from documents.", "relevance": "This is the primary subject of the experimental testing described in the section.", "parent_title": "Experimental Sample Description", "parent_node_type": "semantic_unit"}, "nodes": [], "node_id": "0133"}, {"title": "Experimental sample", "start_index": 5, "end_index": 5, "text": "The document metadata extractor was tested over a set of randomly selected theses, dissertations\n\nand a few technical reports downloaded from the web. Theses were, however, the main focus of the experiments (about 80% of the sample).", "summary": "The collection of documents used for testing the extractor.", "node_type": "keyword", "_text_locked": true, "metadata": {"term": "Experimental sample", "context": "The collection of documents used for testing the extractor.", "relevance": "Defines the dataset upon which the performance of the extractor was evaluated.", "parent_title": "Experimental Sample Description", "parent_node_type": "semantic_unit"}, "nodes": [], "node_id": "0134"}, {"title": "Randomly selected theses", "start_index": 5, "end_index": 5, "text": "The document metadata extractor was tested over a set of randomly selected theses, dissertations\n\nand a few technical reports downloaded from the web. Theses were, however, the main focus of the experiments (about 80% of the sample).", "summary": "Academic documents chosen without a specific pattern from a larger pool.", "node_type": "keyword", "_text_locked": true, "metadata": {"term": "Randomly selected theses", "context": "Academic documents chosen without a specific pattern from a larger pool.", "relevance": "Formed a significant portion of the experimental sample, indicating their importance in the test set.", "parent_title": "Experimental Sample Description", "parent_node_type": "semantic_unit"}, "nodes": [], "node_id": "0135"}, {"title": "Dissertations", "start_index": 5, "end_index": 5, "text": "The document metadata extractor was tested over a set of randomly selected theses, dissertations\n\nand a few technical reports downloaded from the web. Theses were, however, the main focus of the experiments (about 80% of the sample).", "summary": "Long-form academic documents detailing research, similar to theses.", "node_type": "keyword", "_text_locked": true, "metadata": {"term": "Dissertations", "context": "Long-form academic documents detailing research, similar to theses.", "relevance": "Were part of the experimental sample, contributing to the diversity of the test documents.", "parent_title": "Experimental Sample Description", "parent_node_type": "semantic_unit"}, "nodes": [], "node_id": "0136"}, {"title": "Technical reports", "start_index": 5, "end_index": 5, "text": "The document metadata extractor was tested over a set of randomly selected theses, dissertations\n\nand a few technical reports downloaded from the web. Theses were, however, the main focus of the experiments (about 80% of the sample).", "summary": "Documents that present findings of a research or technical project.", "node_type": "keyword", "_text_locked": true, "metadata": {"term": "Technical reports", "context": "Documents that present findings of a research or technical project.", "relevance": "Were included in the experimental sample, adding another type of document for testing.", "parent_title": "Experimental Sample Description", "parent_node_type": "semantic_unit"}, "nodes": [], "node_id": "0137"}, {"title": "Theses focus", "start_index": 5, "end_index": 5, "text": "The document metadata extractor was tested over a set of randomly selected theses, dissertations\n\nand a few technical reports downloaded from the web. Theses were, however, the main focus of the experiments (about 80% of the sample).", "summary": "The primary emphasis of the experimental testing.", "node_type": "keyword", "_text_locked": true, "metadata": {"term": "Theses focus", "context": "The primary emphasis of the experimental testing.", "relevance": "Highlights that theses constituted the majority of the sample, influencing the experimental design and results.", "parent_title": "Experimental Sample Description", "parent_node_type": "semantic_unit"}, "nodes": [], "node_id": "0138"}], "node_id": "0132"}, {"title": "Evaluation Criteria", "start_index": 5, "end_index": 5, "text": "The evaluation of the system was done using the following criteria: recall, precision, accuracy,\n\nand F-measure [as defined in equations (14)â€“(17)].", "summary": "Outlines the criteria used for system evaluation: recall, precision, accuracy, and F-measure, referencing specific equations.", "node_type": "semantic_unit", "metadata": {"semantic_type": "analysis", "start_paragraph": 11, "end_paragraph": 12, "original_title": "Evaluation Criteria"}, "nodes": [{"title": "Evaluation Criteria", "start_index": 5, "end_index": 5, "text": "The evaluation of the system was done using the following criteria: recall, precision, accuracy,\n\nand F-measure [as defined in equations (14)â€“(17)].", "summary": "Standards used to assess the performance of the system.", "node_type": "keyword", "_text_locked": true, "metadata": {"term": "Evaluation Criteria", "context": "Standards used to assess the performance of the system.", "relevance": "This is the central theme of the section, defining how the system's effectiveness is measured.", "parent_title": "Evaluation Criteria", "parent_node_type": "semantic_unit"}, "nodes": [], "node_id": "0140"}, {"title": "Recall", "start_index": 5, "end_index": 5, "text": "The evaluation of the system was done using the following criteria: recall, precision, accuracy,\n\nand F-measure [as defined in equations (14)â€“(17)].", "summary": "A metric measuring the proportion of actual positives that were correctly identified.", "node_type": "keyword", "_text_locked": true, "metadata": {"term": "Recall", "context": "A metric measuring the proportion of actual positives that were correctly identified.", "relevance": "It is a key performance indicator used in the system's evaluation.", "parent_title": "Evaluation Criteria", "parent_node_type": "semantic_unit"}, "nodes": [], "node_id": "0141"}, {"title": "Precision", "start_index": 5, "end_index": 5, "text": "The evaluation of the system was done using the following criteria: recall, precision, accuracy,\n\nand F-measure [as defined in equations (14)â€“(17)].", "summary": "A metric measuring the proportion of true positives among all positive identifications.", "node_type": "keyword", "_text_locked": true, "metadata": {"term": "Precision", "context": "A metric measuring the proportion of true positives among all positive identifications.", "relevance": "It is a key performance indicator used in the system's evaluation.", "parent_title": "Evaluation Criteria", "parent_node_type": "semantic_unit"}, "nodes": [], "node_id": "0142"}, {"title": "Accuracy", "start_index": 5, "end_index": 5, "text": "The evaluation of the system was done using the following criteria: recall, precision, accuracy,\n\nand F-measure [as defined in equations (14)â€“(17)].", "summary": "A metric measuring the proportion of correct predictions out of the total predictions made.", "node_type": "keyword", "_text_locked": true, "metadata": {"term": "Accuracy", "context": "A metric measuring the proportion of correct predictions out of the total predictions made.", "relevance": "It is a key performance indicator used in the system's evaluation.", "parent_title": "Evaluation Criteria", "parent_node_type": "semantic_unit"}, "nodes": [], "node_id": "0143"}, {"title": "F-measure", "start_index": 5, "end_index": 5, "text": "The evaluation of the system was done using the following criteria: recall, precision, accuracy,\n\nand F-measure [as defined in equations (14)â€“(17)].", "summary": "The harmonic mean of precision and recall, providing a single score for performance.", "node_type": "keyword", "_text_locked": true, "metadata": {"term": "F-measure", "context": "The harmonic mean of precision and recall, providing a single score for performance.", "relevance": "It is a key performance indicator used in the system's evaluation, balancing precision and recall.", "parent_title": "Evaluation Criteria", "parent_node_type": "semantic_unit"}, "nodes": [], "node_id": "0144"}, {"title": "Equations (14)-(17)", "start_index": 5, "end_index": 5, "text": "The evaluation of the system was done using the following criteria: recall, precision, accuracy,\n\nand F-measure [as defined in equations (14)â€“(17)].", "summary": "Specific mathematical formulas defining the evaluation metrics.", "node_type": "keyword", "_text_locked": true, "metadata": {"term": "Equations (14)-(17)", "context": "Specific mathematical formulas defining the evaluation metrics.", "relevance": "These equations provide the precise technical definitions for the evaluation criteria used.", "parent_title": "Evaluation Criteria", "parent_node_type": "semantic_unit"}, "nodes": [], "node_id": "0145"}], "node_id": "0139"}, {"title": "Comparison with Related Work", "start_index": 5, "end_index": 5, "text": "An exact performance comparison may not be possible, because of differences in the documents\n\nused for testing the different systems [16]. However, attempts are made to refer to related work and how the results compare with theirs. The results of the experimental evaluation of the reference metadata extractor are presented as follows.", "summary": "Acknowledges potential difficulties in direct performance comparison due to differing test documents and refers to related work for comparative analysis.", "node_type": "semantic_unit", "metadata": {"semantic_type": "analysis", "start_paragraph": 13, "end_paragraph": 14, "original_title": "Comparison with Related Work"}, "nodes": [{"title": "performance comparison", "start_index": 5, "end_index": 5, "text": "An exact performance comparison may not be possible, because of differences in the documents\n\nused for testing the different systems [16]. However, attempts are made to refer to related work and how the results compare with theirs. The results of the experimental evaluation of the reference metadata extractor are presented as follows.", "summary": "Evaluating and contrasting the results of different systems.", "node_type": "keyword", "_text_locked": true, "metadata": {"term": "performance comparison", "context": "Evaluating and contrasting the results of different systems.", "relevance": "This section aims to compare the performance of the reference metadata extractor with related work.", "parent_title": "Comparison with Related Work", "parent_node_type": "semantic_unit"}, "nodes": [], "node_id": "0147"}, {"title": "related work", "start_index": 5, "end_index": 5, "text": "An exact performance comparison may not be possible, because of differences in the documents\n\nused for testing the different systems [16]. However, attempts are made to refer to related work and how the results compare with theirs. The results of the experimental evaluation of the reference metadata extractor are presented as follows.", "summary": "Previous studies or systems that are similar to the current research.", "node_type": "keyword", "_text_locked": true, "metadata": {"term": "related work", "context": "Previous studies or systems that are similar to the current research.", "relevance": "The section discusses how the current system's results relate to existing literature.", "parent_title": "Comparison with Related Work", "parent_node_type": "semantic_unit"}, "nodes": [], "node_id": "0148"}, {"title": "experimental evaluation", "start_index": 5, "end_index": 5, "text": "An exact performance comparison may not be possible, because of differences in the documents\n\nused for testing the different systems [16]. However, attempts are made to refer to related work and how the results compare with theirs. The results of the experimental evaluation of the reference metadata extractor are presented as follows.", "summary": "The process of testing and assessing a system's performance through experiments.", "node_type": "keyword", "_text_locked": true, "metadata": {"term": "experimental evaluation", "context": "The process of testing and assessing a system's performance through experiments.", "relevance": "This is the method used to generate the results presented in this section.", "parent_title": "Comparison with Related Work", "parent_node_type": "semantic_unit"}, "nodes": [], "node_id": "0149"}, {"title": "reference metadata extractor", "start_index": 5, "end_index": 5, "text": "An exact performance comparison may not be possible, because of differences in the documents\n\nused for testing the different systems [16]. However, attempts are made to refer to related work and how the results compare with theirs. The results of the experimental evaluation of the reference metadata extractor are presented as follows.", "summary": "The specific system or tool being evaluated in this study.", "node_type": "keyword", "_text_locked": true, "metadata": {"term": "reference metadata extractor", "context": "The specific system or tool being evaluated in this study.", "relevance": "This is the primary subject of the experimental evaluation discussed.", "parent_title": "Comparison with Related Work", "parent_node_type": "semantic_unit"}, "nodes": [], "node_id": "0150"}, {"title": "documents used for testing", "start_index": 5, "end_index": 5, "text": "An exact performance comparison may not be possible, because of differences in the documents\n\nused for testing the different systems [16]. However, attempts are made to refer to related work and how the results compare with theirs. The results of the experimental evaluation of the reference metadata extractor are presented as follows.", "summary": "The specific set of data employed to evaluate the performance of different systems.", "node_type": "keyword", "_text_locked": true, "metadata": {"term": "documents used for testing", "context": "The specific set of data employed to evaluate the performance of different systems.", "relevance": "Differences in these documents are highlighted as a reason for potential performance comparison difficulties.", "parent_title": "Comparison with Related Work", "parent_node_type": "semantic_unit"}, "nodes": [], "node_id": "0151"}], "node_id": "0146"}, {"title": "Performance Metrics Definitions", "start_index": 5, "end_index": 5, "text": "Precision =A\n\nA+C (14)\n\nRecall =A\n\nA+B (15)\n\nAccuracy =A+D\n\nA+B+C+D (16)\n\nF/C0measur e=2/C3Precision /C3Recall\n\nPrecis ion+Recall (17)\n\nwhere A is the number of correctly extracted fields, B is the number of fields with existing, but not\n\nextracted data, C is the number of fields with wrongly extracted data, while D is the number of fields\n\nwith not existing and not extracted data.", "summary": "Provides detailed definitions and equations for precision, recall, accuracy, and F-measure, including explanations of the variables A, B, C, and D.", "node_type": "semantic_unit", "metadata": {"semantic_type": "analysis", "start_paragraph": 15, "end_paragraph": 25, "original_title": "Performance Metrics Definitions"}, "nodes": [{"title": "Definitions of Metrics", "start_index": 5, "end_index": 5, "text": "Precision =A\n\nA+C (14)\n\nRecall =A\n\nA+B (15)\n\nAccuracy =A+D\n\nA+B+C+D (16)\n\nF/C0measur e=2/C3Precision /C3Recall\n\nPrecis ion+Recall (17)\n\nwhere A is the number of correctly extracted fields, B is the number of fields with existing, but not\n\nextracted data, C is the number of fields with wrongly extracted data, while D is the number of fields\n\nwith not existing and not extracted data.", "summary": "This section defines various metrics used for evaluation, including Precision, Recall, Accuracy, and F-measure. It also details the components (A, B, C, D) used in these calculations.", "node_type": "semantic_unit", "metadata": {"semantic_type": "analysis", "start_paragraph": 0, "end_paragraph": 10, "original_title": "Definitions of Metrics"}, "nodes": [{"title": "Precision", "start_index": 5, "end_index": 5, "text": "Precision =A\n\nA+C (14)\n\nRecall =A\n\nA+B (15)\n\nAccuracy =A+D\n\nA+B+C+D (16)\n\nF/C0measur e=2/C3Precision /C3Recall\n\nPrecis ion+Recall (17)\n\nwhere A is the number of correctly extracted fields, B is the number of fields with existing, but not\n\nextracted data, C is the number of fields with wrongly extracted data, while D is the number of fields\n\nwith not existing and not extracted data.", "summary": "Precision measures the proportion of correctly extracted fields out of all extracted fields.", "node_type": "keyword", "_text_locked": true, "metadata": {"term": "Precision", "context": "Precision measures the proportion of correctly extracted fields out of all extracted fields.", "relevance": "It is a key metric for evaluating the performance of extraction tasks.", "parent_title": "Definitions of Metrics", "parent_node_type": "semantic_unit"}, "nodes": [], "node_id": "0154"}, {"title": "Recall", "start_index": 5, "end_index": 5, "text": "Precision =A\n\nA+C (14)\n\nRecall =A\n\nA+B (15)\n\nAccuracy =A+D\n\nA+B+C+D (16)\n\nF/C0measur e=2/C3Precision /C3Recall\n\nPrecis ion+Recall (17)\n\nwhere A is the number of correctly extracted fields, B is the number of fields with existing, but not\n\nextracted data, C is the number of fields with wrongly extracted data, while D is the number of fields\n\nwith not existing and not extracted data.", "summary": "Recall measures the proportion of correctly extracted fields out of all actual existing fields.", "node_type": "keyword", "_text_locked": true, "metadata": {"term": "Recall", "context": "Recall measures the proportion of correctly extracted fields out of all actual existing fields.", "relevance": "It is another key metric for evaluating the performance of extraction tasks.", "parent_title": "Definitions of Metrics", "parent_node_type": "semantic_unit"}, "nodes": [], "node_id": "0155"}, {"title": "Accuracy", "start_index": 5, "end_index": 5, "text": "Precision =A\n\nA+C (14)\n\nRecall =A\n\nA+B (15)\n\nAccuracy =A+D\n\nA+B+C+D (16)\n\nF/C0measur e=2/C3Precision /C3Recall\n\nPrecis ion+Recall (17)\n\nwhere A is the number of correctly extracted fields, B is the number of fields with existing, but not\n\nextracted data, C is the number of fields with wrongly extracted data, while D is the number of fields\n\nwith not existing and not extracted data.", "summary": "Accuracy measures the proportion of all correctly classified fields (extracted or not extracted) out of all fields.", "node_type": "keyword", "_text_locked": true, "metadata": {"term": "Accuracy", "context": "Accuracy measures the proportion of all correctly classified fields (extracted or not extracted) out of all fields.", "relevance": "It provides an overall measure of correctness for the extraction process.", "parent_title": "Definitions of Metrics", "parent_node_type": "semantic_unit"}, "nodes": [], "node_id": "0156"}, {"title": "F-measure", "start_index": 5, "end_index": 5, "text": "Precision =A\n\nA+C (14)\n\nRecall =A\n\nA+B (15)\n\nAccuracy =A+D\n\nA+B+C+D (16)\n\nF/C0measur e=2/C3Precision /C3Recall\n\nPrecis ion+Recall (17)\n\nwhere A is the number of correctly extracted fields, B is the number of fields with existing, but not\n\nextracted data, C is the number of fields with wrongly extracted data, while D is the number of fields\n\nwith not existing and not extracted data.", "summary": "The F-measure is the harmonic mean of Precision and Recall, providing a single score that balances both metrics.", "node_type": "keyword", "_text_locked": true, "metadata": {"term": "F-measure", "context": "The F-measure is the harmonic mean of Precision and Recall, providing a single score that balances both metrics.", "relevance": "It offers a combined evaluation of extraction performance, useful when both precision and recall are important.", "parent_title": "Definitions of Metrics", "parent_node_type": "semantic_unit"}, "nodes": [], "node_id": "0157"}, {"title": "Correctly extracted fields (A)", "start_index": 5, "end_index": 5, "text": "Precision =A\n\nA+C (14)\n\nRecall =A\n\nA+B (15)\n\nAccuracy =A+D\n\nA+B+C+D (16)\n\nF/C0measur e=2/C3Precision /C3Recall\n\nPrecis ion+Recall (17)\n\nwhere A is the number of correctly extracted fields, B is the number of fields with existing, but not\n\nextracted data, C is the number of fields with wrongly extracted data, while D is the number of fields\n\nwith not existing and not extracted data.", "summary": "Represents the number of fields that were accurately identified and extracted.", "node_type": "keyword", "_text_locked": true, "metadata": {"term": "Correctly extracted fields (A)", "context": "Represents the number of fields that were accurately identified and extracted.", "relevance": "This is the fundamental measure of successful extraction in the formulas.", "parent_title": "Definitions of Metrics", "parent_node_type": "semantic_unit"}, "nodes": [], "node_id": "0158"}, {"title": "Fields with existing, not extracted data (B)", "start_index": 5, "end_index": 5, "text": "Precision =A\n\nA+C (14)\n\nRecall =A\n\nA+B (15)\n\nAccuracy =A+D\n\nA+B+C+D (16)\n\nF/C0measur e=2/C3Precision /C3Recall\n\nPrecis ion+Recall (17)\n\nwhere A is the number of correctly extracted fields, B is the number of fields with existing, but not\n\nextracted data, C is the number of fields with wrongly extracted data, while D is the number of fields\n\nwith not existing and not extracted data.", "summary": "Represents fields that contained data but were not extracted by the system.", "node_type": "keyword", "_text_locked": true, "metadata": {"term": "Fields with existing, not extracted data (B)", "context": "Represents fields that contained data but were not extracted by the system.", "relevance": "This contributes to the calculation of Recall and indicates missed extractions.", "parent_title": "Definitions of Metrics", "parent_node_type": "semantic_unit"}, "nodes": [], "node_id": "0159"}, {"title": "Fields with wrongly extracted data (C)", "start_index": 5, "end_index": 5, "text": "Precision =A\n\nA+C (14)\n\nRecall =A\n\nA+B (15)\n\nAccuracy =A+D\n\nA+B+C+D (16)\n\nF/C0measur e=2/C3Precision /C3Recall\n\nPrecis ion+Recall (17)\n\nwhere A is the number of correctly extracted fields, B is the number of fields with existing, but not\n\nextracted data, C is the number of fields with wrongly extracted data, while D is the number of fields\n\nwith not existing and not extracted data.", "summary": "Represents fields where data was extracted but was incorrect.", "node_type": "keyword", "_text_locked": true, "metadata": {"term": "Fields with wrongly extracted data (C)", "context": "Represents fields where data was extracted but was incorrect.", "relevance": "This contributes to the calculation of Precision and indicates extraction errors.", "parent_title": "Definitions of Metrics", "parent_node_type": "semantic_unit"}, "nodes": [], "node_id": "0160"}, {"title": "Fields with not existing, not extracted data (D)", "start_index": 5, "end_index": 5, "text": "Precision =A\n\nA+C (14)\n\nRecall =A\n\nA+B (15)\n\nAccuracy =A+D\n\nA+B+C+D (16)\n\nF/C0measur e=2/C3Precision /C3Recall\n\nPrecis ion+Recall (17)\n\nwhere A is the number of correctly extracted fields, B is the number of fields with existing, but not\n\nextracted data, C is the number of fields with wrongly extracted data, while D is the number of fields\n\nwith not existing and not extracted data.", "summary": "Represents fields that did not contain data and were not extracted.", "node_type": "keyword", "_text_locked": true, "metadata": {"term": "Fields with not existing, not extracted data (D)", "context": "Represents fields that did not contain data and were not extracted.", "relevance": "This contributes to the calculation of Accuracy and represents correct non-extractions.", "parent_title": "Definitions of Metrics", "parent_node_type": "semantic_unit"}, "nodes": [], "node_id": "0161"}], "node_id": "0153"}], "node_id": "0152"}, {"title": "Manual Verification and Sample Size", "start_index": 5, "end_index": 5, "text": "The test for automatic extraction correctness was based on a manual verification of the correct-\n\nness of the extracted metadata against the original document. Due to such manual verification, which was lengthy and tedious, the sample size was limited to 40 documents.", "summary": "Explains that automatic extraction correctness was verified manually against original documents, which limited the sample size to 40 documents due to the tedious nature of the process.", "node_type": "semantic_unit", "metadata": {"semantic_type": "procedure", "start_paragraph": 26, "end_paragraph": 27, "original_title": "Manual Verification and Sample Size"}, "nodes": [{"title": "Manual verification", "start_index": 5, "end_index": 5, "text": "The test for automatic extraction correctness was based on a manual verification of the correct-\n\nness of the extracted metadata against the original document. Due to such manual verification, which was lengthy and tedious, the sample size was limited to 40 documents.", "summary": "The process of human review to confirm the accuracy of extracted metadata against the source document.", "node_type": "keyword", "_text_locked": true, "metadata": {"term": "Manual verification", "context": "The process of human review to confirm the accuracy of extracted metadata against the source document.", "relevance": "This is the core methodology used to assess the correctness of the automatic extraction process.", "parent_title": "Manual Verification and Sample Size", "parent_node_type": "semantic_unit"}, "nodes": [], "node_id": "0163"}, {"title": "Extracted metadata", "start_index": 5, "end_index": 5, "text": "The test for automatic extraction correctness was based on a manual verification of the correct-\n\nness of the extracted metadata against the original document. Due to such manual verification, which was lengthy and tedious, the sample size was limited to 40 documents.", "summary": "Information automatically pulled from a document that describes its content or structure.", "node_type": "keyword", "_text_locked": true, "metadata": {"term": "Extracted metadata", "context": "Information automatically pulled from a document that describes its content or structure.", "relevance": "The accuracy of this metadata is the subject of the manual verification.", "parent_title": "Manual Verification and Sample Size", "parent_node_type": "semantic_unit"}, "nodes": [], "node_id": "0164"}, {"title": "Original document", "start_index": 5, "end_index": 5, "text": "The test for automatic extraction correctness was based on a manual verification of the correct-\n\nness of the extracted metadata against the original document. Due to such manual verification, which was lengthy and tedious, the sample size was limited to 40 documents.", "summary": "The source material from which metadata is being extracted.", "node_type": "keyword", "_text_locked": true, "metadata": {"term": "Original document", "context": "The source material from which metadata is being extracted.", "relevance": "Serves as the ground truth against which the extracted metadata is compared.", "parent_title": "Manual Verification and Sample Size", "parent_node_type": "semantic_unit"}, "nodes": [], "node_id": "0165"}, {"title": "Lengthy and tedious", "start_index": 5, "end_index": 5, "text": "The test for automatic extraction correctness was based on a manual verification of the correct-\n\nness of the extracted metadata against the original document. Due to such manual verification, which was lengthy and tedious, the sample size was limited to 40 documents.", "summary": "Describes the manual verification process as time-consuming and requiring great effort.", "node_type": "keyword", "_text_locked": true, "metadata": {"term": "Lengthy and tedious", "context": "Describes the manual verification process as time-consuming and requiring great effort.", "relevance": "Explains the constraint that led to a limited sample size.", "parent_title": "Manual Verification and Sample Size", "parent_node_type": "semantic_unit"}, "nodes": [], "node_id": "0166"}, {"title": "Sample size", "start_index": 5, "end_index": 5, "text": "The test for automatic extraction correctness was based on a manual verification of the correct-\n\nness of the extracted metadata against the original document. Due to such manual verification, which was lengthy and tedious, the sample size was limited to 40 documents.", "summary": "The number of documents included in the manual verification process.", "node_type": "keyword", "_text_locked": true, "metadata": {"term": "Sample size", "context": "The number of documents included in the manual verification process.", "relevance": "A critical factor in the study's scope, limited by the manual verification effort.", "parent_title": "Manual Verification and Sample Size", "parent_node_type": "semantic_unit"}, "nodes": [], "node_id": "0167"}, {"title": "40 documents", "start_index": 5, "end_index": 5, "text": "The test for automatic extraction correctness was based on a manual verification of the correct-\n\nness of the extracted metadata against the original document. Due to such manual verification, which was lengthy and tedious, the sample size was limited to 40 documents.", "summary": "The specific quantity of documents used for the manual verification.", "node_type": "keyword", "_text_locked": true, "metadata": {"term": "40 documents", "context": "The specific quantity of documents used for the manual verification.", "relevance": "Quantifies the limitation imposed on the study due to the verification method.", "parent_title": "Manual Verification and Sample Size", "parent_node_type": "semantic_unit"}, "nodes": [], "node_id": "0168"}], "node_id": "0162"}, {"title": "Summary of Results", "start_index": 5, "end_index": 5, "text": "Tables 1â€“4 summarize the overall precision, recall, accuracy and F-measure results respectively.", "summary": "Indicates that Tables 1-4 summarize the overall precision, recall, accuracy, and F-measure results, respectively.", "node_type": "semantic_unit", "metadata": {"semantic_type": "analysis", "start_paragraph": 28, "end_paragraph": 28, "original_title": "Summary of Results"}, "nodes": [{"title": "precision", "start_index": 5, "end_index": 5, "text": "Tables 1â€“4 summarize the overall precision, recall, accuracy and F-measure results respectively.", "summary": "Precision measures the proportion of true positive predictions among all positive predictions made by a model.", "node_type": "keyword", "_text_locked": true, "metadata": {"term": "precision", "context": "Precision measures the proportion of true positive predictions among all positive predictions made by a model.", "relevance": "It is a key metric used to evaluate the performance of classification models, indicating how reliable the positive predictions are.", "parent_title": "Summary of Results", "parent_node_type": "semantic_unit"}, "nodes": [], "node_id": "0170"}, {"title": "recall", "start_index": 5, "end_index": 5, "text": "Tables 1â€“4 summarize the overall precision, recall, accuracy and F-measure results respectively.", "summary": "Recall measures the proportion of true positive predictions among all actual positive instances.", "node_type": "keyword", "_text_locked": true, "metadata": {"term": "recall", "context": "Recall measures the proportion of true positive predictions among all actual positive instances.", "relevance": "It is another crucial metric for evaluating model performance, indicating the model's ability to find all the relevant instances.", "parent_title": "Summary of Results", "parent_node_type": "semantic_unit"}, "nodes": [], "node_id": "0171"}, {"title": "accuracy", "start_index": 5, "end_index": 5, "text": "Tables 1â€“4 summarize the overall precision, recall, accuracy and F-measure results respectively.", "summary": "Accuracy represents the overall proportion of correct predictions (both true positives and true negatives) out of all predictions made.", "node_type": "keyword", "_text_locked": true, "metadata": {"term": "accuracy", "context": "Accuracy represents the overall proportion of correct predictions (both true positives and true negatives) out of all predictions made.", "relevance": "It provides a general measure of the model's correctness across all classes.", "parent_title": "Summary of Results", "parent_node_type": "semantic_unit"}, "nodes": [], "node_id": "0172"}, {"title": "F-measure", "start_index": 5, "end_index": 5, "text": "Tables 1â€“4 summarize the overall precision, recall, accuracy and F-measure results respectively.", "summary": "The F-measure (or F1-score) is the harmonic mean of precision and recall, providing a single score that balances both metrics.", "node_type": "keyword", "_text_locked": true, "metadata": {"term": "F-measure", "context": "The F-measure (or F1-score) is the harmonic mean of precision and recall, providing a single score that balances both metrics.", "relevance": "It is important for evaluating models where both false positives and false negatives are costly, offering a more balanced performance assessment than accuracy alone.", "parent_title": "Summary of Results", "parent_node_type": "semantic_unit"}, "nodes": [], "node_id": "0173"}, {"title": "Tables 1â€“4", "start_index": 5, "end_index": 5, "text": "Tables 1â€“4 summarize the overall precision, recall, accuracy and F-measure results respectively.", "summary": "These tables present the summarized results for precision, recall, accuracy, and F-measure.", "node_type": "keyword", "_text_locked": true, "metadata": {"term": "Tables 1â€“4", "context": "These tables present the summarized results for precision, recall, accuracy, and F-measure.", "relevance": "They are the primary source of the quantitative findings discussed in this section, allowing for a detailed examination of model performance.", "parent_title": "Summary of Results", "parent_node_type": "semantic_unit"}, "nodes": [], "node_id": "0174"}], "node_id": "0169"}], "node_id": "0093"}, {"title": "Experimental Evaluation Results", "start_index": 6, "end_index": 6, "text": "Bolanle Adefowoke Ojokoh et al.\nJournal of Information Science, 35 (5) 2009, pp. 563â€“570 Â© CILIP, DOI: 10.1177/0165551509105195 568Table 1 \nMetadata extraction precision over 40 theses and related documents\n Precision\nTitle 0.75\nTable of Contents 0.73\nPreface 0.86\nAbstract 0.77\nAcknowledgment 0.64\nIntroduction 0.68\nConclusion 0.90\nReferences 1.0\n \nTable 2 \nMetadata extraction recall over 40 theses and related documents\n Recall\nTitle 0.75\nTable of Contents 0.81\nPreface 1.0\nAbstract 0.92\nAcknowledgment 0.90\nIntroduction 0.68\nConclusion 0.68\nReferences 0.91\n \nTable 3 \nMetadata extraction accuracy over 40 theses and related documents\n Accuracy\nTitle 0.75\nTable of Contents 0.68\nPreface 0.98\nAbstract 0.78\nAcknowledgment 0.70\nIntroduction 0.60\nConclusion 0.70\nReferences 0.93\n \nTable 4 \nMetadata extraction F-measure over 40 theses and related documents\n F-measure\nTitle 0.75\nTable of Contents 0.77\nPreface 0.92\nAbstract 0.84\nAcknowledgment 0.75\nIntroduction 0.68\nConclusion 0.77\nReferences 0.95", "summary": "Presents the results of the metadata extraction experiment, including precision, recall, accuracy, and F-measure for various metadata fields over 40 documents, summarized in Tables 1-4.", "node_type": "semantic_unit", "metadata": {"semantic_type": "analysis", "start_paragraph": 1, "end_paragraph": 1, "original_title": "Experimental Evaluation Results"}, "nodes": [{"title": "Metadata Extraction Precision", "start_index": 6, "end_index": 6, "text": "Metadata extraction precision over 40 theses and related documents\n\nPrecision\n\nTitle 0.75\n\nTable of Contents 0.73\n\nPreface 0.86\n\nAbstract 0.77\n\nAcknowledgment 0.64\n\nIntroduction 0.68\n\nConclusion 0.90\n\nReferences 1.0", "summary": "Presents the precision of metadata extraction for various sections of 40 theses and related documents, with References achieving the highest precision.", "node_type": "semantic_unit", "metadata": {"semantic_type": "measurement", "start_paragraph": 2, "end_paragraph": 11, "original_title": "Metadata Extraction Precision"}, "nodes": [{"title": "Metadata Extraction Precision Across Document Types", "start_index": 6, "end_index": 6, "text": "Metadata extraction precision over 40 theses and related documents\n\nPrecision\n\nTitle 0.75\n\nTable of Contents 0.73\n\nPreface 0.86\n\nAbstract 0.77\n\nAcknowledgment 0.64\n\nIntroduction 0.68\n\nConclusion 0.90", "summary": "This unit presents the precision of metadata extraction for various document components, including titles, tables of contents, prefaces, abstracts, acknowledgments, and introductions. The precision scores range from 0.64 to 0.86.", "node_type": "semantic_unit", "metadata": {"semantic_type": "measurement", "start_paragraph": 0, "end_paragraph": 8, "original_title": "Metadata Extraction Precision Across Document Types"}, "nodes": [{"title": "Metadata Extraction Precision", "start_index": 6, "end_index": 6, "text": "Metadata extraction precision over 40 theses and related documents\n\nPrecision\n\nTitle 0.75\n\nTable of Contents 0.73\n\nPreface 0.86\n\nAbstract 0.77\n\nAcknowledgment 0.64\n\nIntroduction 0.68\n\nConclusion 0.90", "summary": "A measure of the accuracy of extracted metadata across different document sections.", "node_type": "keyword", "_text_locked": true, "metadata": {"term": "Metadata Extraction Precision", "context": "A measure of the accuracy of extracted metadata across different document sections.", "relevance": "This is the central metric and focus of the entire section, indicating the success of the extraction process.", "parent_title": "Metadata Extraction Precision Across Document Types", "parent_node_type": "semantic_unit"}, "nodes": [], "node_id": "0178"}, {"title": "Document Types", "start_index": 6, "end_index": 6, "text": "Metadata extraction precision over 40 theses and related documents\n\nPrecision\n\nTitle 0.75\n\nTable of Contents 0.73\n\nPreface 0.86\n\nAbstract 0.77\n\nAcknowledgment 0.64\n\nIntroduction 0.68\n\nConclusion 0.90", "summary": "Refers to the various kinds of documents analyzed, in this case, theses and related materials.", "node_type": "keyword", "_text_locked": true, "metadata": {"term": "Document Types", "context": "Refers to the various kinds of documents analyzed, in this case, theses and related materials.", "relevance": "Highlights the scope of the analysis and the diversity of sources for metadata extraction.", "parent_title": "Metadata Extraction Precision Across Document Types", "parent_node_type": "semantic_unit"}, "nodes": [], "node_id": "0179"}, {"title": "Theses", "start_index": 6, "end_index": 6, "text": "Metadata extraction precision over 40 theses and related documents\n\nPrecision\n\nTitle 0.75\n\nTable of Contents 0.73\n\nPreface 0.86\n\nAbstract 0.77\n\nAcknowledgment 0.64\n\nIntroduction 0.68\n\nConclusion 0.90", "summary": "Academic documents presenting research findings, often with distinct structural components.", "node_type": "keyword", "_text_locked": true, "metadata": {"term": "Theses", "context": "Academic documents presenting research findings, often with distinct structural components.", "relevance": "A primary document type analyzed, providing a specific context for the precision measurements.", "parent_title": "Metadata Extraction Precision Across Document Types", "parent_node_type": "semantic_unit"}, "nodes": [], "node_id": "0180"}, {"title": "Title Precision", "start_index": 6, "end_index": 6, "text": "Metadata extraction precision over 40 theses and related documents\n\nPrecision\n\nTitle 0.75\n\nTable of Contents 0.73\n\nPreface 0.86\n\nAbstract 0.77\n\nAcknowledgment 0.64\n\nIntroduction 0.68\n\nConclusion 0.90", "summary": "The accuracy of metadata extracted specifically from the title section of documents.", "node_type": "keyword", "_text_locked": true, "metadata": {"term": "Title Precision", "context": "The accuracy of metadata extracted specifically from the title section of documents.", "relevance": "Represents one specific component's performance within the overall metadata extraction.", "parent_title": "Metadata Extraction Precision Across Document Types", "parent_node_type": "semantic_unit"}, "nodes": [], "node_id": "0181"}, {"title": "Table of Contents Precision", "start_index": 6, "end_index": 6, "text": "Metadata extraction precision over 40 theses and related documents\n\nPrecision\n\nTitle 0.75\n\nTable of Contents 0.73\n\nPreface 0.86\n\nAbstract 0.77\n\nAcknowledgment 0.64\n\nIntroduction 0.68\n\nConclusion 0.90", "summary": "The accuracy of metadata extracted from the table of contents.", "node_type": "keyword", "_text_locked": true, "metadata": {"term": "Table of Contents Precision", "context": "The accuracy of metadata extracted from the table of contents.", "relevance": "Indicates the performance of metadata extraction on a structural element that outlines document content.", "parent_title": "Metadata Extraction Precision Across Document Types", "parent_node_type": "semantic_unit"}, "nodes": [], "node_id": "0182"}, {"title": "Preface Precision", "start_index": 6, "end_index": 6, "text": "Metadata extraction precision over 40 theses and related documents\n\nPrecision\n\nTitle 0.75\n\nTable of Contents 0.73\n\nPreface 0.86\n\nAbstract 0.77\n\nAcknowledgment 0.64\n\nIntroduction 0.68\n\nConclusion 0.90", "summary": "The accuracy of metadata extracted from the preface section of documents.", "node_type": "keyword", "_text_locked": true, "metadata": {"term": "Preface Precision", "context": "The accuracy of metadata extracted from the preface section of documents.", "relevance": "Shows the extraction precision for a less structured, often introductory part of a document.", "parent_title": "Metadata Extraction Precision Across Document Types", "parent_node_type": "semantic_unit"}, "nodes": [], "node_id": "0183"}, {"title": "Abstract Precision", "start_index": 6, "end_index": 6, "text": "Metadata extraction precision over 40 theses and related documents\n\nPrecision\n\nTitle 0.75\n\nTable of Contents 0.73\n\nPreface 0.86\n\nAbstract 0.77\n\nAcknowledgment 0.64\n\nIntroduction 0.68\n\nConclusion 0.90", "summary": "The accuracy of metadata extracted from the abstract, a summary of the document.", "node_type": "keyword", "_text_locked": true, "metadata": {"term": "Abstract Precision", "context": "The accuracy of metadata extracted from the abstract, a summary of the document.", "relevance": "Measures extraction performance on a key section that encapsulates the document's main points.", "parent_title": "Metadata Extraction Precision Across Document Types", "parent_node_type": "semantic_unit"}, "nodes": [], "node_id": "0184"}, {"title": "Acknowledgment Precision", "start_index": 6, "end_index": 6, "text": "Metadata extraction precision over 40 theses and related documents\n\nPrecision\n\nTitle 0.75\n\nTable of Contents 0.73\n\nPreface 0.86\n\nAbstract 0.77\n\nAcknowledgment 0.64\n\nIntroduction 0.68\n\nConclusion 0.90", "summary": "The accuracy of metadata extracted from the acknowledgment section.", "node_type": "keyword", "_text_locked": true, "metadata": {"term": "Acknowledgment Precision", "context": "The accuracy of metadata extracted from the acknowledgment section.", "relevance": "Evaluates extraction performance on a section that typically contains names and affiliations.", "parent_title": "Metadata Extraction Precision Across Document Types", "parent_node_type": "semantic_unit"}, "nodes": [], "node_id": "0185"}, {"title": "Introduction Precision", "start_index": 6, "end_index": 6, "text": "Metadata extraction precision over 40 theses and related documents\n\nPrecision\n\nTitle 0.75\n\nTable of Contents 0.73\n\nPreface 0.86\n\nAbstract 0.77\n\nAcknowledgment 0.64\n\nIntroduction 0.68\n\nConclusion 0.90", "summary": "The accuracy of metadata extracted from the introduction section of documents.", "node_type": "keyword", "_text_locked": true, "metadata": {"term": "Introduction Precision", "context": "The accuracy of metadata extracted from the introduction section of documents.", "relevance": "Assesses extraction performance on the section that sets the context and background for the research.", "parent_title": "Metadata Extraction Precision Across Document Types", "parent_node_type": "semantic_unit"}, "nodes": [], "node_id": "0186"}, {"title": "Conclusion Precision", "start_index": 6, "end_index": 6, "text": "Metadata extraction precision over 40 theses and related documents\n\nPrecision\n\nTitle 0.75\n\nTable of Contents 0.73\n\nPreface 0.86\n\nAbstract 0.77\n\nAcknowledgment 0.64\n\nIntroduction 0.68\n\nConclusion 0.90", "summary": "The accuracy of metadata extracted from the conclusion section, summarizing findings.", "node_type": "keyword", "_text_locked": true, "metadata": {"term": "Conclusion Precision", "context": "The accuracy of metadata extracted from the conclusion section, summarizing findings.", "relevance": "Indicates the extraction performance on the section that presents the final results and implications.", "parent_title": "Metadata Extraction Precision Across Document Types", "parent_node_type": "semantic_unit"}, "nodes": [], "node_id": "0187"}], "node_id": "0177"}, {"title": "Metadata Extraction Precision for References", "start_index": 6, "end_index": 6, "text": "References 1.0", "summary": "This unit specifically reports the metadata extraction precision for references, which achieved a perfect score of 1.0.", "node_type": "semantic_unit", "metadata": {"semantic_type": "measurement", "start_paragraph": 9, "end_paragraph": 9, "original_title": "Metadata Extraction Precision for References"}, "nodes": [{"title": "Metadata Extraction", "start_index": 6, "end_index": 6, "text": "References 1.0", "summary": "The process of identifying and extracting structured information from unstructured or semi-structured data.", "node_type": "keyword", "_text_locked": true, "metadata": {"term": "Metadata Extraction", "context": "The process of identifying and extracting structured information from unstructured or semi-structured data.", "relevance": "This is the core technical process being evaluated for its precision in the context of references.", "parent_title": "Metadata Extraction Precision for References", "parent_node_type": "semantic_unit"}, "nodes": [], "node_id": "0189"}, {"title": "References", "start_index": 6, "end_index": 6, "text": "References 1.0", "summary": "Citations or bibliographic information that point to other sources of information.", "node_type": "keyword", "_text_locked": true, "metadata": {"term": "References", "context": "Citations or bibliographic information that point to other sources of information.", "relevance": "The specific type of data for which metadata extraction precision is being measured.", "parent_title": "Metadata Extraction Precision for References", "parent_node_type": "semantic_unit"}, "nodes": [], "node_id": "0190"}, {"title": "Precision", "start_index": 6, "end_index": 6, "text": "References 1.0", "summary": "A metric that measures the accuracy of positive predictions, calculated as true positives divided by the sum of true positives and false positives.", "node_type": "keyword", "_text_locked": true, "metadata": {"term": "Precision", "context": "A metric that measures the accuracy of positive predictions, calculated as true positives divided by the sum of true positives and false positives.", "relevance": "The primary performance metric used to evaluate the effectiveness of the metadata extraction process.", "parent_title": "Metadata Extraction Precision for References", "parent_node_type": "semantic_unit"}, "nodes": [], "node_id": "0191"}, {"title": "References 1.0", "start_index": 6, "end_index": 6, "text": "References 1.0", "summary": "Likely refers to a specific version or standard for handling bibliographic references.", "node_type": "keyword", "_text_locked": true, "metadata": {"term": "References 1.0", "context": "Likely refers to a specific version or standard for handling bibliographic references.", "relevance": "Indicates the specific domain or standard being applied to the metadata extraction task.", "parent_title": "Metadata Extraction Precision for References", "parent_node_type": "semantic_unit"}, "nodes": [], "node_id": "0192"}, {"title": "Information Retrieval", "start_index": 6, "end_index": 6, "text": "References 1.0", "summary": "The activity of obtaining information resources relevant to an information need from a collection of those resources.", "node_type": "keyword", "_text_locked": true, "metadata": {"term": "Information Retrieval", "context": "The activity of obtaining information resources relevant to an information need from a collection of those resources.", "relevance": "Underpins the utility of precise metadata extraction for finding relevant references.", "parent_title": "Metadata Extraction Precision for References", "parent_node_type": "semantic_unit"}, "nodes": [], "node_id": "0193"}, {"title": "Domain-Specific Terminology", "start_index": 6, "end_index": 6, "text": "References 1.0", "summary": "Vocabulary unique to a particular field or area of study.", "node_type": "keyword", "_text_locked": true, "metadata": {"term": "Domain-Specific Terminology", "context": "Vocabulary unique to a particular field or area of study.", "relevance": "Highlights the need for specialized terms in understanding the nuances of reference metadata.", "parent_title": "Metadata Extraction Precision for References", "parent_node_type": "semantic_unit"}, "nodes": [], "node_id": "0194"}], "node_id": "0188"}], "node_id": "0176"}, {"title": "Metadata Extraction Recall", "start_index": 6, "end_index": 6, "text": "Metadata extraction recall over 40 theses and related documents\n\nRecall\n\nTitle 0.75\n\nTable of Contents 0.81\n\nPreface 1.0\n\nAbstract 0.92\n\nAcknowledgment 0.90\n\nIntroduction 0.68\n\nConclusion 0.68\n\nReferences 0.91", "summary": "Presents the recall of metadata extraction for various sections of 40 theses and related documents, with Preface achieving the highest recall.", "node_type": "semantic_unit", "metadata": {"semantic_type": "measurement", "start_paragraph": 13, "end_paragraph": 22, "original_title": "Metadata Extraction Recall"}, "nodes": [{"title": "Metadata Extraction Recall for Theses and Related Documents", "start_index": 6, "end_index": 6, "text": "Metadata extraction recall over 40 theses and related documents", "summary": "This unit presents the overall recall rate for metadata extraction across 40 theses and related documents.", "node_type": "semantic_unit", "metadata": {"semantic_type": "measurement", "start_paragraph": 0, "end_paragraph": 0, "original_title": "Metadata Extraction Recall for Theses and Related Documents"}, "nodes": [{"title": "Metadata Extraction Recall", "start_index": 6, "end_index": 6, "text": "Metadata extraction recall over 40 theses and related documents", "summary": "A measure of how effectively metadata is identified and retrieved from documents.", "node_type": "keyword", "_text_locked": true, "metadata": {"term": "Metadata Extraction Recall", "context": "A measure of how effectively metadata is identified and retrieved from documents.", "relevance": "This is the central metric and focus of the study, indicating the success of the metadata extraction process.", "parent_title": "Metadata Extraction Recall for Theses and Related Documents", "parent_node_type": "semantic_unit"}, "nodes": [], "node_id": "0197"}, {"title": "Theses", "start_index": 6, "end_index": 6, "text": "Metadata extraction recall over 40 theses and related documents", "summary": "Academic documents presenting original research and findings.", "node_type": "keyword", "_text_locked": true, "metadata": {"term": "Theses", "context": "Academic documents presenting original research and findings.", "relevance": "These are the primary type of documents analyzed in the study, forming the dataset for evaluation.", "parent_title": "Metadata Extraction Recall for Theses and Related Documents", "parent_node_type": "semantic_unit"}, "nodes": [], "node_id": "0198"}, {"title": "Related Documents", "start_index": 6, "end_index": 6, "text": "Metadata extraction recall over 40 theses and related documents", "summary": "Other academic or research-oriented materials that share characteristics with theses.", "node_type": "keyword", "_text_locked": true, "metadata": {"term": "Related Documents", "context": "Other academic or research-oriented materials that share characteristics with theses.", "relevance": "These documents expand the scope of the study beyond just theses, providing a broader context for metadata extraction.", "parent_title": "Metadata Extraction Recall for Theses and Related Documents", "parent_node_type": "semantic_unit"}, "nodes": [], "node_id": "0199"}, {"title": "Document Analysis", "start_index": 6, "end_index": 6, "text": "Metadata extraction recall over 40 theses and related documents", "summary": "The process of examining documents to identify and extract specific information.", "node_type": "keyword", "_text_locked": true, "metadata": {"term": "Document Analysis", "context": "The process of examining documents to identify and extract specific information.", "relevance": "This is the core activity performed in the section to achieve metadata extraction.", "parent_title": "Metadata Extraction Recall for Theses and Related Documents", "parent_node_type": "semantic_unit"}, "nodes": [], "node_id": "0200"}, {"title": "Information Retrieval", "start_index": 6, "end_index": 6, "text": "Metadata extraction recall over 40 theses and related documents", "summary": "The process of finding relevant information from a collection of resources.", "node_type": "keyword", "_text_locked": true, "metadata": {"term": "Information Retrieval", "context": "The process of finding relevant information from a collection of resources.", "relevance": "Metadata extraction is a crucial step that directly supports effective information retrieval from the analyzed documents.", "parent_title": "Metadata Extraction Recall for Theses and Related Documents", "parent_node_type": "semantic_unit"}, "nodes": [], "node_id": "0201"}], "node_id": "0196"}, {"title": "Recall Rates for Specific Document Sections", "start_index": 6, "end_index": 6, "text": "Recall\n\nTitle 0.75\n\nTable of Contents 0.81\n\nPreface 1.0\n\nAbstract 0.92\n\nAcknowledgment 0.90\n\nIntroduction 0.68\n\nConclusion 0.68\n\nReferences 0.91", "summary": "This unit details the recall rates for various sections of the documents, including Title, Table of Contents, Preface, Abstract, Acknowledgment, Introduction, Conclusion, and References.", "node_type": "semantic_unit", "metadata": {"semantic_type": "measurement", "start_paragraph": 1, "end_paragraph": 9, "original_title": "Recall Rates for Specific Document Sections"}, "nodes": [{"title": "Recall Rates", "start_index": 6, "end_index": 6, "text": "Recall\n\nTitle 0.75\n\nTable of Contents 0.81\n\nPreface 1.0\n\nAbstract 0.92\n\nAcknowledgment 0.90\n\nIntroduction 0.68\n\nConclusion 0.68\n\nReferences 0.91", "summary": "Measures the proportion of relevant items that are successfully retrieved.", "node_type": "keyword", "_text_locked": true, "metadata": {"term": "Recall Rates", "context": "Measures the proportion of relevant items that are successfully retrieved.", "relevance": "This is the primary metric discussed in the section, indicating retrieval success for different document parts.", "parent_title": "Recall Rates for Specific Document Sections", "parent_node_type": "semantic_unit"}, "nodes": [], "node_id": "0203"}, {"title": "Title Recall", "start_index": 6, "end_index": 6, "text": "Recall\n\nTitle 0.75\n\nTable of Contents 0.81\n\nPreface 1.0\n\nAbstract 0.92\n\nAcknowledgment 0.90\n\nIntroduction 0.68\n\nConclusion 0.68\n\nReferences 0.91", "summary": "The recall rate specifically for retrieving the document's title.", "node_type": "keyword", "_text_locked": true, "metadata": {"term": "Title Recall", "context": "The recall rate specifically for retrieving the document's title.", "relevance": "Represents a specific retrieval performance for a key document identifier.", "parent_title": "Recall Rates for Specific Document Sections", "parent_node_type": "semantic_unit"}, "nodes": [], "node_id": "0204"}, {"title": "Table of Contents Recall", "start_index": 6, "end_index": 6, "text": "Recall\n\nTitle 0.75\n\nTable of Contents 0.81\n\nPreface 1.0\n\nAbstract 0.92\n\nAcknowledgment 0.90\n\nIntroduction 0.68\n\nConclusion 0.68\n\nReferences 0.91", "summary": "The recall rate for retrieving information from the table of contents.", "node_type": "keyword", "_text_locked": true, "metadata": {"term": "Table of Contents Recall", "context": "The recall rate for retrieving information from the table of contents.", "relevance": "Indicates retrieval effectiveness for a structural element that guides users through a document.", "parent_title": "Recall Rates for Specific Document Sections", "parent_node_type": "semantic_unit"}, "nodes": [], "node_id": "0205"}, {"title": "Preface Recall", "start_index": 6, "end_index": 6, "text": "Recall\n\nTitle 0.75\n\nTable of Contents 0.81\n\nPreface 1.0\n\nAbstract 0.92\n\nAcknowledgment 0.90\n\nIntroduction 0.68\n\nConclusion 0.68\n\nReferences 0.91", "summary": "The recall rate associated with retrieving content from the preface.", "node_type": "keyword", "_text_locked": true, "metadata": {"term": "Preface Recall", "context": "The recall rate associated with retrieving content from the preface.", "relevance": "Highlights the high retrieval success for introductory, often summary-like, sections.", "parent_title": "Recall Rates for Specific Document Sections", "parent_node_type": "semantic_unit"}, "nodes": [], "node_id": "0206"}, {"title": "Abstract Recall", "start_index": 6, "end_index": 6, "text": "Recall\n\nTitle 0.75\n\nTable of Contents 0.81\n\nPreface 1.0\n\nAbstract 0.92\n\nAcknowledgment 0.90\n\nIntroduction 0.68\n\nConclusion 0.68\n\nReferences 0.91", "summary": "The recall rate for retrieving the document's abstract.", "node_type": "keyword", "_text_locked": true, "metadata": {"term": "Abstract Recall", "context": "The recall rate for retrieving the document's abstract.", "relevance": "Shows strong retrieval performance for a concise summary of the document's content.", "parent_title": "Recall Rates for Specific Document Sections", "parent_node_type": "semantic_unit"}, "nodes": [], "node_id": "0207"}, {"title": "Acknowledgment Recall", "start_index": 6, "end_index": 6, "text": "Recall\n\nTitle 0.75\n\nTable of Contents 0.81\n\nPreface 1.0\n\nAbstract 0.92\n\nAcknowledgment 0.90\n\nIntroduction 0.68\n\nConclusion 0.68\n\nReferences 0.91", "summary": "The recall rate for retrieving the acknowledgment section.", "node_type": "keyword", "_text_locked": true, "metadata": {"term": "Acknowledgment Recall", "context": "The recall rate for retrieving the acknowledgment section.", "relevance": "Demonstrates high retrieval success for a specific, often formulaic, part of a document.", "parent_title": "Recall Rates for Specific Document Sections", "parent_node_type": "semantic_unit"}, "nodes": [], "node_id": "0208"}, {"title": "Introduction Recall", "start_index": 6, "end_index": 6, "text": "Recall\n\nTitle 0.75\n\nTable of Contents 0.81\n\nPreface 1.0\n\nAbstract 0.92\n\nAcknowledgment 0.90\n\nIntroduction 0.68\n\nConclusion 0.68\n\nReferences 0.91", "summary": "The recall rate for retrieving the introduction section.", "node_type": "keyword", "_text_locked": true, "metadata": {"term": "Introduction Recall", "context": "The recall rate for retrieving the introduction section.", "relevance": "Indicates retrieval performance for a foundational part of the document's main content.", "parent_title": "Recall Rates for Specific Document Sections", "parent_node_type": "semantic_unit"}, "nodes": [], "node_id": "0209"}, {"title": "Conclusion Recall", "start_index": 6, "end_index": 6, "text": "Recall\n\nTitle 0.75\n\nTable of Contents 0.81\n\nPreface 1.0\n\nAbstract 0.92\n\nAcknowledgment 0.90\n\nIntroduction 0.68\n\nConclusion 0.68\n\nReferences 0.91", "summary": "The recall rate for retrieving the conclusion section.", "node_type": "keyword", "_text_locked": true, "metadata": {"term": "Conclusion Recall", "context": "The recall rate for retrieving the conclusion section.", "relevance": "Shows retrieval performance for the section summarizing findings and outcomes.", "parent_title": "Recall Rates for Specific Document Sections", "parent_node_type": "semantic_unit"}, "nodes": [], "node_id": "0210"}, {"title": "References Recall", "start_index": 6, "end_index": 6, "text": "Recall\n\nTitle 0.75\n\nTable of Contents 0.81\n\nPreface 1.0\n\nAbstract 0.92\n\nAcknowledgment 0.90\n\nIntroduction 0.68\n\nConclusion 0.68\n\nReferences 0.91", "summary": "The recall rate for retrieving the list of references.", "node_type": "keyword", "_text_locked": true, "metadata": {"term": "References Recall", "context": "The recall rate for retrieving the list of references.", "relevance": "Indicates high retrieval success for the bibliography, crucial for citation and further research.", "parent_title": "Recall Rates for Specific Document Sections", "parent_node_type": "semantic_unit"}, "nodes": [], "node_id": "0211"}], "node_id": "0202"}], "node_id": "0195"}, {"title": "Metadata Extraction Accuracy", "start_index": 6, "end_index": 6, "text": "Metadata extraction accuracy over 40 theses and related documents\n\nAccuracy\n\nTitle 0.75\n\nTable of Contents 0.68\n\nPreface 0.98\n\nAbstract 0.78\n\nAcknowledgment 0.70\n\nIntroduction 0.60\n\nConclusion 0.70\n\nReferences 0.93", "summary": "Presents the accuracy of metadata extraction for various sections of 40 theses and related documents, with Preface achieving the highest accuracy.", "node_type": "semantic_unit", "metadata": {"semantic_type": "measurement", "start_paragraph": 24, "end_paragraph": 33, "original_title": "Metadata Extraction Accuracy"}, "nodes": [{"title": "Metadata Extraction Accuracy Across Document Types", "start_index": 6, "end_index": 6, "text": "Metadata extraction accuracy over 40 theses and related documents\n\nAccuracy\n\nTitle 0.75\n\nTable of Contents 0.68\n\nPreface 0.98\n\nAbstract 0.78\n\nAcknowledgment 0.70\n\nIntroduction 0.60\n\nConclusion 0.70\n\nReferences 0.93", "summary": "This section presents the accuracy of metadata extraction for various document components, including titles, tables of contents, prefaces, abstracts, acknowledgments, introductions, conclusions, and references. The accuracy scores range from 0.60 for introductions to 0.98 for prefaces.", "node_type": "semantic_unit", "metadata": {"semantic_type": "measurement", "start_paragraph": 0, "end_paragraph": 9, "original_title": "Metadata Extraction Accuracy Across Document Types"}, "nodes": [{"title": "Metadata Extraction Accuracy", "start_index": 6, "end_index": 6, "text": "Metadata extraction accuracy over 40 theses and related documents\n\nAccuracy\n\nTitle 0.75\n\nTable of Contents 0.68\n\nPreface 0.98\n\nAbstract 0.78\n\nAcknowledgment 0.70\n\nIntroduction 0.60\n\nConclusion 0.70\n\nReferences 0.93", "summary": "The precision with which metadata is identified and extracted from documents.", "node_type": "keyword", "_text_locked": true, "metadata": {"term": "Metadata Extraction Accuracy", "context": "The precision with which metadata is identified and extracted from documents.", "relevance": "This is the primary metric being evaluated and discussed in the section.", "parent_title": "Metadata Extraction Accuracy Across Document Types", "parent_node_type": "semantic_unit"}, "nodes": [], "node_id": "0214"}, {"title": "Document Types", "start_index": 6, "end_index": 6, "text": "Metadata extraction accuracy over 40 theses and related documents\n\nAccuracy\n\nTitle 0.75\n\nTable of Contents 0.68\n\nPreface 0.98\n\nAbstract 0.78\n\nAcknowledgment 0.70\n\nIntroduction 0.60\n\nConclusion 0.70\n\nReferences 0.93", "summary": "The various categories or formats of documents analyzed for metadata extraction.", "node_type": "keyword", "_text_locked": true, "metadata": {"term": "Document Types", "context": "The various categories or formats of documents analyzed for metadata extraction.", "relevance": "The accuracy is assessed across different document types, highlighting variations.", "parent_title": "Metadata Extraction Accuracy Across Document Types", "parent_node_type": "semantic_unit"}, "nodes": [], "node_id": "0215"}, {"title": "Theses", "start_index": 6, "end_index": 6, "text": "Metadata extraction accuracy over 40 theses and related documents\n\nAccuracy\n\nTitle 0.75\n\nTable of Contents 0.68\n\nPreface 0.98\n\nAbstract 0.78\n\nAcknowledgment 0.70\n\nIntroduction 0.60\n\nConclusion 0.70\n\nReferences 0.93", "summary": "Academic documents, typically dissertations or master's papers, used in the analysis.", "node_type": "keyword", "_text_locked": true, "metadata": {"term": "Theses", "context": "Academic documents, typically dissertations or master's papers, used in the analysis.", "relevance": "Theses are the main corpus of documents from which metadata accuracy is measured.", "parent_title": "Metadata Extraction Accuracy Across Document Types", "parent_node_type": "semantic_unit"}, "nodes": [], "node_id": "0216"}, {"title": "Title Accuracy", "start_index": 6, "end_index": 6, "text": "Metadata extraction accuracy over 40 theses and related documents\n\nAccuracy\n\nTitle 0.75\n\nTable of Contents 0.68\n\nPreface 0.98\n\nAbstract 0.78\n\nAcknowledgment 0.70\n\nIntroduction 0.60\n\nConclusion 0.70\n\nReferences 0.93", "summary": "The accuracy score specifically for extracting the title of a document.", "node_type": "keyword", "_text_locked": true, "metadata": {"term": "Title Accuracy", "context": "The accuracy score specifically for extracting the title of a document.", "relevance": "Represents one specific metadata field whose extraction accuracy is quantified.", "parent_title": "Metadata Extraction Accuracy Across Document Types", "parent_node_type": "semantic_unit"}, "nodes": [], "node_id": "0217"}, {"title": "Table of Contents Accuracy", "start_index": 6, "end_index": 6, "text": "Metadata extraction accuracy over 40 theses and related documents\n\nAccuracy\n\nTitle 0.75\n\nTable of Contents 0.68\n\nPreface 0.98\n\nAbstract 0.78\n\nAcknowledgment 0.70\n\nIntroduction 0.60\n\nConclusion 0.70\n\nReferences 0.93", "summary": "The accuracy score for extracting the table of contents from documents.", "node_type": "keyword", "_text_locked": true, "metadata": {"term": "Table of Contents Accuracy", "context": "The accuracy score for extracting the table of contents from documents.", "relevance": "Indicates the performance of metadata extraction for structural document elements.", "parent_title": "Metadata Extraction Accuracy Across Document Types", "parent_node_type": "semantic_unit"}, "nodes": [], "node_id": "0218"}, {"title": "Preface Accuracy", "start_index": 6, "end_index": 6, "text": "Metadata extraction accuracy over 40 theses and related documents\n\nAccuracy\n\nTitle 0.75\n\nTable of Contents 0.68\n\nPreface 0.98\n\nAbstract 0.78\n\nAcknowledgment 0.70\n\nIntroduction 0.60\n\nConclusion 0.70\n\nReferences 0.93", "summary": "The accuracy score for extracting the preface section of a document.", "node_type": "keyword", "_text_locked": true, "metadata": {"term": "Preface Accuracy", "context": "The accuracy score for extracting the preface section of a document.", "relevance": "Shows a high accuracy, suggesting prefaces are easily identifiable metadata.", "parent_title": "Metadata Extraction Accuracy Across Document Types", "parent_node_type": "semantic_unit"}, "nodes": [], "node_id": "0219"}, {"title": "Abstract Accuracy", "start_index": 6, "end_index": 6, "text": "Metadata extraction accuracy over 40 theses and related documents\n\nAccuracy\n\nTitle 0.75\n\nTable of Contents 0.68\n\nPreface 0.98\n\nAbstract 0.78\n\nAcknowledgment 0.70\n\nIntroduction 0.60\n\nConclusion 0.70\n\nReferences 0.93", "summary": "The accuracy score for extracting the abstract from documents.", "node_type": "keyword", "_text_locked": true, "metadata": {"term": "Abstract Accuracy", "context": "The accuracy score for extracting the abstract from documents.", "relevance": "Measures the extraction performance for a key summary section of academic papers.", "parent_title": "Metadata Extraction Accuracy Across Document Types", "parent_node_type": "semantic_unit"}, "nodes": [], "node_id": "0220"}, {"title": "Acknowledgment Accuracy", "start_index": 6, "end_index": 6, "text": "Metadata extraction accuracy over 40 theses and related documents\n\nAccuracy\n\nTitle 0.75\n\nTable of Contents 0.68\n\nPreface 0.98\n\nAbstract 0.78\n\nAcknowledgment 0.70\n\nIntroduction 0.60\n\nConclusion 0.70\n\nReferences 0.93", "summary": "The accuracy score for extracting the acknowledgment section of a document.", "node_type": "keyword", "_text_locked": true, "metadata": {"term": "Acknowledgment Accuracy", "context": "The accuracy score for extracting the acknowledgment section of a document.", "relevance": "Provides insight into the extraction accuracy of supplementary document sections.", "parent_title": "Metadata Extraction Accuracy Across Document Types", "parent_node_type": "semantic_unit"}, "nodes": [], "node_id": "0221"}, {"title": "Introduction Accuracy", "start_index": 6, "end_index": 6, "text": "Metadata extraction accuracy over 40 theses and related documents\n\nAccuracy\n\nTitle 0.75\n\nTable of Contents 0.68\n\nPreface 0.98\n\nAbstract 0.78\n\nAcknowledgment 0.70\n\nIntroduction 0.60\n\nConclusion 0.70\n\nReferences 0.93", "summary": "The accuracy score for extracting the introduction section of a document.", "node_type": "keyword", "_text_locked": true, "metadata": {"term": "Introduction Accuracy", "context": "The accuracy score for extracting the introduction section of a document.", "relevance": "Highlights the extraction performance for the initial content of a document.", "parent_title": "Metadata Extraction Accuracy Across Document Types", "parent_node_type": "semantic_unit"}, "nodes": [], "node_id": "0222"}, {"title": "Conclusion Accuracy", "start_index": 6, "end_index": 6, "text": "Metadata extraction accuracy over 40 theses and related documents\n\nAccuracy\n\nTitle 0.75\n\nTable of Contents 0.68\n\nPreface 0.98\n\nAbstract 0.78\n\nAcknowledgment 0.70\n\nIntroduction 0.60\n\nConclusion 0.70\n\nReferences 0.93", "summary": "The accuracy score for extracting the conclusion section of a document.", "node_type": "keyword", "_text_locked": true, "metadata": {"term": "Conclusion Accuracy", "context": "The accuracy score for extracting the conclusion section of a document.", "relevance": "Measures the extraction accuracy for the final substantive part of a document.", "parent_title": "Metadata Extraction Accuracy Across Document Types", "parent_node_type": "semantic_unit"}, "nodes": [], "node_id": "0223"}, {"title": "References Accuracy", "start_index": 6, "end_index": 6, "text": "Metadata extraction accuracy over 40 theses and related documents\n\nAccuracy\n\nTitle 0.75\n\nTable of Contents 0.68\n\nPreface 0.98\n\nAbstract 0.78\n\nAcknowledgment 0.70\n\nIntroduction 0.60\n\nConclusion 0.70\n\nReferences 0.93", "summary": "The accuracy score for extracting the references or bibliography from documents.", "node_type": "keyword", "_text_locked": true, "metadata": {"term": "References Accuracy", "context": "The accuracy score for extracting the references or bibliography from documents.", "relevance": "Indicates the high accuracy in extracting a critical, often structured, part of academic documents.", "parent_title": "Metadata Extraction Accuracy Across Document Types", "parent_node_type": "semantic_unit"}, "nodes": [], "node_id": "0224"}], "node_id": "0213"}], "node_id": "0212"}, {"title": "Metadata Extraction F-measure", "start_index": 6, "end_index": 6, "text": "Metadata extraction F-measure over 40 theses and related documents\n\nF-measure\n\nTitle 0.75\n\nTable of Contents 0.77\n\nPreface 0.92\n\nAbstract 0.84\n\nAcknowledgment 0.75\n\nIntroduction 0.68\n\nConclusion 0.77\n\nReferences 0.95", "summary": "Presents the F-measure of metadata extraction for various sections of 40 theses and related documents, with References achieving the highest F-measure.", "node_type": "semantic_unit", "metadata": {"semantic_type": "measurement", "start_paragraph": 35, "end_paragraph": 44, "original_title": "Metadata Extraction F-measure"}, "nodes": [{"title": "Metadata Extraction F-measure Across Theses and Related Documents", "start_index": 6, "end_index": 6, "text": "Metadata extraction F-measure over 40 theses and related documents", "summary": "This unit presents the F-measure for metadata extraction across 40 theses and related documents.", "node_type": "semantic_unit", "metadata": {"semantic_type": "measurement", "start_paragraph": 0, "end_paragraph": 0, "original_title": "Metadata Extraction F-measure Across Theses and Related Documents"}, "nodes": [{"title": "Metadata Extraction", "start_index": 6, "end_index": 6, "text": "Metadata extraction F-measure over 40 theses and related documents", "summary": "The process of automatically identifying and extracting structured information from unstructured or semi-structured text.", "node_type": "keyword", "_text_locked": true, "metadata": {"term": "Metadata Extraction", "context": "The process of automatically identifying and extracting structured information from unstructured or semi-structured text.", "relevance": "This is the core task being evaluated in the section.", "parent_title": "Metadata Extraction F-measure Across Theses and Related Documents", "parent_node_type": "semantic_unit"}, "nodes": [], "node_id": "0227"}, {"title": "F-measure", "start_index": 6, "end_index": 6, "text": "Metadata extraction F-measure over 40 theses and related documents", "summary": "A metric that combines precision and recall into a single measure of accuracy for classification tasks.", "node_type": "keyword", "_text_locked": true, "metadata": {"term": "F-measure", "context": "A metric that combines precision and recall into a single measure of accuracy for classification tasks.", "relevance": "It is the primary evaluation metric used to assess the performance of metadata extraction.", "parent_title": "Metadata Extraction F-measure Across Theses and Related Documents", "parent_node_type": "semantic_unit"}, "nodes": [], "node_id": "0228"}, {"title": "Theses", "start_index": 6, "end_index": 6, "text": "Metadata extraction F-measure over 40 theses and related documents", "summary": "Academic documents presenting original research and findings, often containing significant amounts of structured information.", "node_type": "keyword", "_text_locked": true, "metadata": {"term": "Theses", "context": "Academic documents presenting original research and findings, often containing significant amounts of structured information.", "relevance": "These documents form a primary dataset for evaluating metadata extraction performance.", "parent_title": "Metadata Extraction F-measure Across Theses and Related Documents", "parent_node_type": "semantic_unit"}, "nodes": [], "node_id": "0229"}, {"title": "Related Documents", "start_index": 6, "end_index": 6, "text": "Metadata extraction F-measure over 40 theses and related documents", "summary": "A broader category of texts that share characteristics with theses but may differ in structure or scope.", "node_type": "keyword", "_text_locked": true, "metadata": {"term": "Related Documents", "context": "A broader category of texts that share characteristics with theses but may differ in structure or scope.", "relevance": "These documents expand the dataset, testing the generalizability of metadata extraction methods.", "parent_title": "Metadata Extraction F-measure Across Theses and Related Documents", "parent_node_type": "semantic_unit"}, "nodes": [], "node_id": "0230"}, {"title": "Performance Evaluation", "start_index": 6, "end_index": 6, "text": "Metadata extraction F-measure over 40 theses and related documents", "summary": "The assessment of how well a system or method performs a specific task.", "node_type": "keyword", "_text_locked": true, "metadata": {"term": "Performance Evaluation", "context": "The assessment of how well a system or method performs a specific task.", "relevance": "The section is fundamentally about evaluating the performance of metadata extraction.", "parent_title": "Metadata Extraction F-measure Across Theses and Related Documents", "parent_node_type": "semantic_unit"}, "nodes": [], "node_id": "0231"}], "node_id": "0226"}, {"title": "F-measure for Specific Document Sections", "start_index": 6, "end_index": 6, "text": "F-measure\n\nTitle 0.75\n\nTable of Contents 0.77\n\nPreface 0.92\n\nAbstract 0.84\n\nAcknowledgment 0.75\n\nIntroduction 0.68\n\nConclusion 0.77\n\nReferences 0.95", "summary": "This unit details the F-measure scores for various sections of the documents, including Title, Table of Contents, Preface, Abstract, Acknowledgment, Introduction, Conclusion, and References.", "node_type": "semantic_unit", "metadata": {"semantic_type": "measurement", "start_paragraph": 1, "end_paragraph": 9, "original_title": "F-measure for Specific Document Sections"}, "nodes": [{"title": "F-measure", "start_index": 6, "end_index": 6, "text": "F-measure\n\nTitle 0.75\n\nTable of Contents 0.77\n\nPreface 0.92\n\nAbstract 0.84\n\nAcknowledgment 0.75\n\nIntroduction 0.68\n\nConclusion 0.77\n\nReferences 0.95", "summary": "A harmonic mean of precision and recall, used to evaluate classification models.", "node_type": "keyword", "_text_locked": true, "metadata": {"term": "F-measure", "context": "A harmonic mean of precision and recall, used to evaluate classification models.", "relevance": "This is the primary metric being evaluated across different document sections.", "parent_title": "F-measure for Specific Document Sections", "parent_node_type": "semantic_unit"}, "nodes": [], "node_id": "0233"}, {"title": "Title", "start_index": 6, "end_index": 6, "text": "F-measure\n\nTitle 0.75\n\nTable of Contents 0.77\n\nPreface 0.92\n\nAbstract 0.84\n\nAcknowledgment 0.75\n\nIntroduction 0.68\n\nConclusion 0.77\n\nReferences 0.95", "summary": "The heading or name of a document or section.", "node_type": "keyword", "_text_locked": true, "metadata": {"term": "Title", "context": "The heading or name of a document or section.", "relevance": "Represents a specific document section for which F-measure is calculated.", "parent_title": "F-measure for Specific Document Sections", "parent_node_type": "semantic_unit"}, "nodes": [], "node_id": "0234"}, {"title": "Table of Contents", "start_index": 6, "end_index": 6, "text": "F-measure\n\nTitle 0.75\n\nTable of Contents 0.77\n\nPreface 0.92\n\nAbstract 0.84\n\nAcknowledgment 0.75\n\nIntroduction 0.68\n\nConclusion 0.77\n\nReferences 0.95", "summary": "A list of the sections of a document and their page numbers.", "node_type": "keyword", "_text_locked": true, "metadata": {"term": "Table of Contents", "context": "A list of the sections of a document and their page numbers.", "relevance": "Represents a specific document section for which F-measure is calculated.", "parent_title": "F-measure for Specific Document Sections", "parent_node_type": "semantic_unit"}, "nodes": [], "node_id": "0235"}, {"title": "Preface", "start_index": 6, "end_index": 6, "text": "F-measure\n\nTitle 0.75\n\nTable of Contents 0.77\n\nPreface 0.92\n\nAbstract 0.84\n\nAcknowledgment 0.75\n\nIntroduction 0.68\n\nConclusion 0.77\n\nReferences 0.95", "summary": "An introductory statement in a book or other piece of writing.", "node_type": "keyword", "_text_locked": true, "metadata": {"term": "Preface", "context": "An introductory statement in a book or other piece of writing.", "relevance": "Represents a specific document section for which F-measure is calculated.", "parent_title": "F-measure for Specific Document Sections", "parent_node_type": "semantic_unit"}, "nodes": [], "node_id": "0236"}, {"title": "Abstract", "start_index": 6, "end_index": 6, "text": "F-measure\n\nTitle 0.75\n\nTable of Contents 0.77\n\nPreface 0.92\n\nAbstract 0.84\n\nAcknowledgment 0.75\n\nIntroduction 0.68\n\nConclusion 0.77\n\nReferences 0.95", "summary": "A brief summary of the contents of a document.", "node_type": "keyword", "_text_locked": true, "metadata": {"term": "Abstract", "context": "A brief summary of the contents of a document.", "relevance": "Represents a specific document section for which F-measure is calculated.", "parent_title": "F-measure for Specific Document Sections", "parent_node_type": "semantic_unit"}, "nodes": [], "node_id": "0237"}, {"title": "Acknowledgment", "start_index": 6, "end_index": 6, "text": "F-measure\n\nTitle 0.75\n\nTable of Contents 0.77\n\nPreface 0.92\n\nAbstract 0.84\n\nAcknowledgment 0.75\n\nIntroduction 0.68\n\nConclusion 0.77\n\nReferences 0.95", "summary": "A section where authors thank individuals or organizations who contributed to the work.", "node_type": "keyword", "_text_locked": true, "metadata": {"term": "Acknowledgment", "context": "A section where authors thank individuals or organizations who contributed to the work.", "relevance": "Represents a specific document section for which F-measure is calculated.", "parent_title": "F-measure for Specific Document Sections", "parent_node_type": "semantic_unit"}, "nodes": [], "node_id": "0238"}, {"title": "Introduction", "start_index": 6, "end_index": 6, "text": "F-measure\n\nTitle 0.75\n\nTable of Contents 0.77\n\nPreface 0.92\n\nAbstract 0.84\n\nAcknowledgment 0.75\n\nIntroduction 0.68\n\nConclusion 0.77\n\nReferences 0.95", "summary": "The opening section of a document that introduces the topic and purpose.", "node_type": "keyword", "_text_locked": true, "metadata": {"term": "Introduction", "context": "The opening section of a document that introduces the topic and purpose.", "relevance": "Represents a specific document section for which F-measure is calculated.", "parent_title": "F-measure for Specific Document Sections", "parent_node_type": "semantic_unit"}, "nodes": [], "node_id": "0239"}, {"title": "Conclusion", "start_index": 6, "end_index": 6, "text": "F-measure\n\nTitle 0.75\n\nTable of Contents 0.77\n\nPreface 0.92\n\nAbstract 0.84\n\nAcknowledgment 0.75\n\nIntroduction 0.68\n\nConclusion 0.77\n\nReferences 0.95", "summary": "A summary of the main points of a document.", "node_type": "keyword", "_text_locked": true, "metadata": {"term": "Conclusion", "context": "A summary of the main points of a document.", "relevance": "Represents a specific document section for which F-measure is calculated.", "parent_title": "F-measure for Specific Document Sections", "parent_node_type": "semantic_unit"}, "nodes": [], "node_id": "0240"}, {"title": "References", "start_index": 6, "end_index": 6, "text": "F-measure\n\nTitle 0.75\n\nTable of Contents 0.77\n\nPreface 0.92\n\nAbstract 0.84\n\nAcknowledgment 0.75\n\nIntroduction 0.68\n\nConclusion 0.77\n\nReferences 0.95", "summary": "A list of sources cited within a document.", "node_type": "keyword", "_text_locked": true, "metadata": {"term": "References", "context": "A list of sources cited within a document.", "relevance": "Represents a specific document section for which F-measure is calculated.", "parent_title": "F-measure for Specific Document Sections", "parent_node_type": "semantic_unit"}, "nodes": [], "node_id": "0241"}], "node_id": "0232"}], "node_id": "0225"}], "node_id": "0175"}, {"title": "Discussion of Results and Comparison with Related Work", "start_index": 7, "end_index": 7, "text": "Bolanle Adefowoke Ojokoh et al.\nJournal of Information Science, 35 (5) 2009, pp. 563â€“570 Â© CILIP, DOI: 10.1177/0165551509105195 569From the results, â€˜Referencesâ€™ was extracted with the highest precision. Its extraction is also rela-\ntively high compared to others in terms of recall, accuracy and F-measure. This could be largely due \nto the fact that they appear, in most cases, at the end of the document.\nMost of the â€˜Prefaceâ€™ extraction cases fall under the not existing and not extracted cases because \nvery few of the documents (only six) contained a preface. As a result, recall and accuracy were high-\nest for â€˜Prefaceâ€™.\nâ€˜Introductionâ€™ was extracted generally with the least values in terms of the evaluation criteria \n(0.68 for precision, recall and F-measure and 0.60 for accuracy). â€˜Conclusionâ€™ extraction was low too \nin terms of accuracy, although relatively high in precision (0.90). Reasons for these could be attrib-uted to the fact that in many cases introductions and conclusions exist in some theses (sometimes in every chapter), and sometimes too, other keywords that might not be recognized by the system are attached to them. In addition, some patterns not embedded in the rule-based system might be encountered leading to incorrect extraction.\nâ€˜Abstractâ€™ extraction was performed with relatively high recall and F-measure. The precision and \naccuracy of its extraction was mostly affected negatively because in a few theses, the abstract part was not specifically labelled â€˜Abstractâ€™ or was not labelled at all.\nâ€˜Table of Contentsâ€™ was extracted with relatively high recall, but with fair precision and F-measure. \nThe accuracy with which it was extracted was a bit low, because in some cases, the system extracted some other parts, which were not actually part of the table of contents, with it.\nâ€˜Titleâ€™ extraction was particularly challenging as a result of the fact that titles of documents are \nnot usually labelled as such. Nevertheless, the task was done with consistent precision, recall, accu-racy and F-measure showing the effectiveness of the rule-based system. During the evaluation, it \nwas also discovered that, for most of the wrongly extracted cases for titles, the information extracted was still relevant, for instance when the authorsâ€™ names or institution of study were extracted.\nSome of the studies with presented results include the work of Hu et al. [10] who extracted title \nfrom Word documents with precision and recall of 0.810 and 0.837, respectively, and precision and recall of 0.875 and 0.895 from PowerPoint documents, respectively in an experiment on intranet data using machine learning technique.\nSome systems whose work could be fairly compared to this system include that of Berkowitz and \nElkhadiri [17] who extracted authors and titles from documents; they reported recall of 25.96% for exact extraction of author names; for 24.99% of the papers they managed to extract either part of the author name(s), or the name(s) plus extra text. All these focused on extraction of a single metadata. Giuffrida and colleagues [14] extracted title, author, affiliation, author-to-affiliation mapping and table of contents from Postscript files using a knowledge-based approach obtaining 92%, 87%, 75%, 71% and 76% accuracy respectively. Hence, the methods proposed by this research for general documents metadata extraction with particular emphasis on theses can handle the task with rela-tively high efficiency. Compared to existing systems, it extracts more metadata, and with relatively comparable effectiveness.\n5. Conclusions and further research directions\nThis paper describes a method for general metadata extraction from general documents using a combination of the segmentation by keyword algorithm and regular expressions. Extraction of title is done using a different set of rules, implemented before segmentation by keyword is carried out because title extraction is often not affected by keywords. The rules used for title extraction proved consistently effective for theses and dissertations. The proposed model for extracting other metadata was tested on some randomly downloaded theses and related documents and used to extract Abstract, Preface, Table of Contents, Introduction, Conclusion, References and Acknowledgments. The experimental results show that the extraction was done with a relatively high degree of precision, recall and accuracy except for â€˜Introductionâ€™ and â€˜Conclusionâ€™ with low recall because of the usual existence of multiples of them in theses documents. Compared to existing systems, this system", "summary": "Analyzes the performance of the metadata extraction for different fields, explaining reasons for high or low scores, and compares the system's effectiveness with previously published related work.", "node_type": "semantic_unit", "metadata": {"semantic_type": "analysis", "start_paragraph": 2, "end_paragraph": 2, "original_title": "Discussion of Results and Comparison with Related Work"}, "nodes": [{"title": "Interpretation of 'References' Extraction", "start_index": 7, "end_index": 7, "text": "Journal of Information Science, 35 (5) 2009, pp. 563â€“570 Â© CILIP, DOI: 10.1177/0165551509105195 569From the results, â€˜Referencesâ€™ was extracted with the highest precision. Its extraction is also rela-\n\ntively high compared to others in terms of recall, accuracy and F-measure. This could be largely due\n\nto the fact that they appear, in most cases, at the end of the document.", "summary": "The 'References' section was extracted with the highest precision, recall, accuracy, and F-measure, likely because it typically appears at the end of documents.", "node_type": "semantic_unit", "metadata": {"semantic_type": "interpretation", "start_paragraph": 1, "end_paragraph": 3, "original_title": "Interpretation of 'References' Extraction"}, "nodes": [{"title": "Interpretation of High Precision for 'References'", "start_index": 7, "end_index": 7, "text": "Journal of Information Science, 35 (5) 2009, pp. 563â€“570 Â© CILIP, DOI: 10.1177/0165551509105195 569From the results, â€˜Referencesâ€™ was extracted with the highest precision. Its extraction is also rela-\n\ntively high compared to others in terms of recall, accuracy and F-measure. This could be largely due\n\nto the fact that they appear, in most cases, at the end of the document.", "summary": "The 'References' section was extracted with the highest precision, recall, accuracy, and F-measure. This is attributed to its common placement at the end of documents.", "node_type": "semantic_unit", "metadata": {"semantic_type": "interpretation", "start_paragraph": 0, "end_paragraph": 2, "original_title": "Interpretation of High Precision for 'References'"}, "nodes": [{"title": "References", "start_index": 7, "end_index": 7, "text": "Journal of Information Science, 35 (5) 2009, pp. 563â€“570 Â© CILIP, DOI: 10.1177/0165551509105195 569From the results, â€˜Referencesâ€™ was extracted with the highest precision. Its extraction is also rela-\n\ntively high compared to others in terms of recall, accuracy and F-measure. This could be largely due\n\nto the fact that they appear, in most cases, at the end of the document.", "summary": "A section typically found at the end of a document listing sources.", "node_type": "keyword", "_text_locked": true, "metadata": {"term": "References", "context": "A section typically found at the end of a document listing sources.", "relevance": "This term is the central subject of the section, being analyzed for extraction performance.", "parent_title": "Interpretation of High Precision for 'References'", "parent_node_type": "semantic_unit"}, "nodes": [], "node_id": "0245"}, {"title": "High Precision", "start_index": 7, "end_index": 7, "text": "Journal of Information Science, 35 (5) 2009, pp. 563â€“570 Â© CILIP, DOI: 10.1177/0165551509105195 569From the results, â€˜Referencesâ€™ was extracted with the highest precision. Its extraction is also rela-\n\ntively high compared to others in terms of recall, accuracy and F-measure. This could be largely due\n\nto the fact that they appear, in most cases, at the end of the document.", "summary": "A performance metric indicating the proportion of extracted items that are relevant.", "node_type": "keyword", "_text_locked": true, "metadata": {"term": "High Precision", "context": "A performance metric indicating the proportion of extracted items that are relevant.", "relevance": "This is the primary metric by which the 'References' extraction is evaluated.", "parent_title": "Interpretation of High Precision for 'References'", "parent_node_type": "semantic_unit"}, "nodes": [], "node_id": "0246"}, {"title": "Recall", "start_index": 7, "end_index": 7, "text": "Journal of Information Science, 35 (5) 2009, pp. 563â€“570 Â© CILIP, DOI: 10.1177/0165551509105195 569From the results, â€˜Referencesâ€™ was extracted with the highest precision. Its extraction is also rela-\n\ntively high compared to others in terms of recall, accuracy and F-measure. This could be largely due\n\nto the fact that they appear, in most cases, at the end of the document.", "summary": "A performance metric indicating the proportion of relevant items that were successfully extracted.", "node_type": "keyword", "_text_locked": true, "metadata": {"term": "Recall", "context": "A performance metric indicating the proportion of relevant items that were successfully extracted.", "relevance": "This metric, along with precision and F-measure, provides a comprehensive view of extraction performance.", "parent_title": "Interpretation of High Precision for 'References'", "parent_node_type": "semantic_unit"}, "nodes": [], "node_id": "0247"}, {"title": "Accuracy", "start_index": 7, "end_index": 7, "text": "Journal of Information Science, 35 (5) 2009, pp. 563â€“570 Â© CILIP, DOI: 10.1177/0165551509105195 569From the results, â€˜Referencesâ€™ was extracted with the highest precision. Its extraction is also rela-\n\ntively high compared to others in terms of recall, accuracy and F-measure. This could be largely due\n\nto the fact that they appear, in most cases, at the end of the document.", "summary": "A performance metric measuring the overall correctness of the extraction process.", "node_type": "keyword", "_text_locked": true, "metadata": {"term": "Accuracy", "context": "A performance metric measuring the overall correctness of the extraction process.", "relevance": "This metric contributes to the overall evaluation of the extraction method's effectiveness.", "parent_title": "Interpretation of High Precision for 'References'", "parent_node_type": "semantic_unit"}, "nodes": [], "node_id": "0248"}, {"title": "F-measure", "start_index": 7, "end_index": 7, "text": "Journal of Information Science, 35 (5) 2009, pp. 563â€“570 Â© CILIP, DOI: 10.1177/0165551509105195 569From the results, â€˜Referencesâ€™ was extracted with the highest precision. Its extraction is also rela-\n\ntively high compared to others in terms of recall, accuracy and F-measure. This could be largely due\n\nto the fact that they appear, in most cases, at the end of the document.", "summary": "The harmonic mean of precision and recall, providing a single score for performance.", "node_type": "keyword", "_text_locked": true, "metadata": {"term": "F-measure", "context": "The harmonic mean of precision and recall, providing a single score for performance.", "relevance": "This metric offers a balanced evaluation of the extraction performance, considering both precision and recall.", "parent_title": "Interpretation of High Precision for 'References'", "parent_node_type": "semantic_unit"}, "nodes": [], "node_id": "0249"}, {"title": "Document End Location", "start_index": 7, "end_index": 7, "text": "Journal of Information Science, 35 (5) 2009, pp. 563â€“570 Â© CILIP, DOI: 10.1177/0165551509105195 569From the results, â€˜Referencesâ€™ was extracted with the highest precision. Its extraction is also rela-\n\ntively high compared to others in terms of recall, accuracy and F-measure. This could be largely due\n\nto the fact that they appear, in most cases, at the end of the document.", "summary": "The typical placement of 'References' at the conclusion of a document.", "node_type": "keyword", "_text_locked": true, "metadata": {"term": "Document End Location", "context": "The typical placement of 'References' at the conclusion of a document.", "relevance": "This characteristic is identified as a key reason for the high extraction performance of 'References'.", "parent_title": "Interpretation of High Precision for 'References'", "parent_node_type": "semantic_unit"}, "nodes": [], "node_id": "0250"}], "node_id": "0244"}], "node_id": "0243"}, {"title": "Interpretation of 'Preface' Extraction", "start_index": 7, "end_index": 7, "text": "Most of the â€˜Prefaceâ€™ extraction cases fall under the not existing and not extracted cases because\n\nvery few of the documents (only six) contained a preface. As a result, recall and accuracy were high-\n\nest for â€˜Prefaceâ€™.", "summary": "Due to its infrequent appearance, 'Preface' extraction had high recall and accuracy when it was present, as most cases were either not extracted or not found.", "node_type": "semantic_unit", "metadata": {"semantic_type": "interpretation", "start_paragraph": 4, "end_paragraph": 6, "original_title": "Interpretation of 'Preface' Extraction"}, "nodes": [{"title": "Preface extraction", "start_index": 7, "end_index": 7, "text": "Most of the â€˜Prefaceâ€™ extraction cases fall under the not existing and not extracted cases because\n\nvery few of the documents (only six) contained a preface. As a result, recall and accuracy were high-\n\nest for â€˜Prefaceâ€™.", "summary": "The process of identifying and extracting content specifically from the preface section of documents.", "node_type": "keyword", "_text_locked": true, "metadata": {"term": "Preface extraction", "context": "The process of identifying and extracting content specifically from the preface section of documents.", "relevance": "This is the central task and subject of the section, defining the scope of the analysis.", "parent_title": "Interpretation of 'Preface' Extraction", "parent_node_type": "semantic_unit"}, "nodes": [], "node_id": "0252"}, {"title": "Not existing cases", "start_index": 7, "end_index": 7, "text": "Most of the â€˜Prefaceâ€™ extraction cases fall under the not existing and not extracted cases because\n\nvery few of the documents (only six) contained a preface. As a result, recall and accuracy were high-\n\nest for â€˜Prefaceâ€™.", "summary": "Instances where the preface was not found within the analyzed documents.", "node_type": "keyword", "_text_locked": true, "metadata": {"term": "Not existing cases", "context": "Instances where the preface was not found within the analyzed documents.", "relevance": "This category represents a significant portion of the extraction outcomes, explaining low recall.", "parent_title": "Interpretation of 'Preface' Extraction", "parent_node_type": "semantic_unit"}, "nodes": [], "node_id": "0253"}, {"title": "Not extracted cases", "start_index": 7, "end_index": 7, "text": "Most of the â€˜Prefaceâ€™ extraction cases fall under the not existing and not extracted cases because\n\nvery few of the documents (only six) contained a preface. As a result, recall and accuracy were high-\n\nest for â€˜Prefaceâ€™.", "summary": "Instances where the preface existed but could not be successfully extracted by the system.", "node_type": "keyword", "_text_locked": true, "metadata": {"term": "Not extracted cases", "context": "Instances where the preface existed but could not be successfully extracted by the system.", "relevance": "This category, along with 'not existing', contributes to the overall understanding of extraction performance.", "parent_title": "Interpretation of 'Preface' Extraction", "parent_node_type": "semantic_unit"}, "nodes": [], "node_id": "0254"}, {"title": "Recall", "start_index": 7, "end_index": 7, "text": "Most of the â€˜Prefaceâ€™ extraction cases fall under the not existing and not extracted cases because\n\nvery few of the documents (only six) contained a preface. As a result, recall and accuracy were high-\n\nest for â€˜Prefaceâ€™.", "summary": "A measure of how many of the relevant items are successfully retrieved.", "node_type": "keyword", "_text_locked": true, "metadata": {"term": "Recall", "context": "A measure of how many of the relevant items are successfully retrieved.", "relevance": "This metric is highlighted as being high for 'Preface' due to the limited number of documents containing prefaces.", "parent_title": "Interpretation of 'Preface' Extraction", "parent_node_type": "semantic_unit"}, "nodes": [], "node_id": "0255"}, {"title": "Accuracy", "start_index": 7, "end_index": 7, "text": "Most of the â€˜Prefaceâ€™ extraction cases fall under the not existing and not extracted cases because\n\nvery few of the documents (only six) contained a preface. As a result, recall and accuracy were high-\n\nest for â€˜Prefaceâ€™.", "summary": "A measure of how many of the retrieved items are relevant.", "node_type": "keyword", "_text_locked": true, "metadata": {"term": "Accuracy", "context": "A measure of how many of the retrieved items are relevant.", "relevance": "This metric is also noted as being high for 'Preface', indicating successful extraction when a preface was present.", "parent_title": "Interpretation of 'Preface' Extraction", "parent_node_type": "semantic_unit"}, "nodes": [], "node_id": "0256"}], "node_id": "0251"}, {"title": "Interpretation of 'Introduction' and 'Conclusion' Extraction", "start_index": 7, "end_index": 7, "text": "â€˜Introductionâ€™ was extracted generally with the least values in terms of the evaluation criteria\n\n(0.68 for precision, recall and F-measure and 0.60 for accuracy). â€˜Conclusionâ€™ extraction was low too\n\nin terms of accuracy, although relatively high in precision (0.90). Reasons for these could be attrib-uted to the fact that in many cases introductions and conclusions exist in some theses (sometimes in every chapter), and sometimes too, other keywords that might not be recognized by the system are attached to them. In addition, some patterns not embedded in the rule-based system might be encountered leading to incorrect extraction.", "summary": "'Introduction' extraction yielded the lowest evaluation scores, while 'Conclusion' had low accuracy despite high precision. This is attributed to their frequent multiple occurrences and potential for unrecognized keywords or patterns.", "node_type": "semantic_unit", "metadata": {"semantic_type": "interpretation", "start_paragraph": 7, "end_paragraph": 9, "original_title": "Interpretation of 'Introduction' and 'Conclusion' Extraction"}, "nodes": [{"title": "Performance of 'Introduction' and 'Conclusion' Extraction", "start_index": 7, "end_index": 7, "text": "â€˜Introductionâ€™ was extracted generally with the least values in terms of the evaluation criteria\n\n(0.68 for precision, recall and F-measure and 0.60 for accuracy). â€˜Conclusionâ€™ extraction was low too", "summary": "The 'Introduction' section generally showed the lowest scores across precision, recall, F-measure, and accuracy. 'Conclusion' extraction also had low accuracy, despite high precision.", "node_type": "semantic_unit", "metadata": {"semantic_type": "interpretation", "start_paragraph": 0, "end_paragraph": 1, "original_title": "Performance of 'Introduction' and 'Conclusion' Extraction"}, "nodes": [{"title": "Introduction extraction", "start_index": 7, "end_index": 7, "text": "â€˜Introductionâ€™ was extracted generally with the least values in terms of the evaluation criteria\n\n(0.68 for precision, recall and F-measure and 0.60 for accuracy). â€˜Conclusionâ€™ extraction was low too", "summary": "The process of identifying and extracting the 'Introduction' section from a document.", "node_type": "keyword", "_text_locked": true, "metadata": {"term": "Introduction extraction", "context": "The process of identifying and extracting the 'Introduction' section from a document.", "relevance": "This is a primary subject of the evaluation, showing low performance metrics.", "parent_title": "Performance of 'Introduction' and 'Conclusion' Extraction", "parent_node_type": "semantic_unit"}, "nodes": [], "node_id": "0259"}, {"title": "Conclusion extraction", "start_index": 7, "end_index": 7, "text": "â€˜Introductionâ€™ was extracted generally with the least values in terms of the evaluation criteria\n\n(0.68 for precision, recall and F-measure and 0.60 for accuracy). â€˜Conclusionâ€™ extraction was low too", "summary": "The process of identifying and extracting the 'Conclusion' section from a document.", "node_type": "keyword", "_text_locked": true, "metadata": {"term": "Conclusion extraction", "context": "The process of identifying and extracting the 'Conclusion' section from a document.", "relevance": "This is another subject of the evaluation, also showing low performance.", "parent_title": "Performance of 'Introduction' and 'Conclusion' Extraction", "parent_node_type": "semantic_unit"}, "nodes": [], "node_id": "0260"}, {"title": "Evaluation criteria", "start_index": 7, "end_index": 7, "text": "â€˜Introductionâ€™ was extracted generally with the least values in terms of the evaluation criteria\n\n(0.68 for precision, recall and F-measure and 0.60 for accuracy). â€˜Conclusionâ€™ extraction was low too", "summary": "The metrics used to assess the performance of extraction tasks, including precision, recall, F-measure, and accuracy.", "node_type": "keyword", "_text_locked": true, "metadata": {"term": "Evaluation criteria", "context": "The metrics used to assess the performance of extraction tasks, including precision, recall, F-measure, and accuracy.", "relevance": "These criteria are used to quantify the performance of 'Introduction' and 'Conclusion' extraction.", "parent_title": "Performance of 'Introduction' and 'Conclusion' Extraction", "parent_node_type": "semantic_unit"}, "nodes": [], "node_id": "0261"}, {"title": "Precision", "start_index": 7, "end_index": 7, "text": "â€˜Introductionâ€™ was extracted generally with the least values in terms of the evaluation criteria\n\n(0.68 for precision, recall and F-measure and 0.60 for accuracy). â€˜Conclusionâ€™ extraction was low too", "summary": "A metric measuring the proportion of correctly extracted sections among all sections identified as the target section.", "node_type": "keyword", "_text_locked": true, "metadata": {"term": "Precision", "context": "A metric measuring the proportion of correctly extracted sections among all sections identified as the target section.", "relevance": "One of the key metrics used to evaluate the performance of the extraction methods.", "parent_title": "Performance of 'Introduction' and 'Conclusion' Extraction", "parent_node_type": "semantic_unit"}, "nodes": [], "node_id": "0262"}, {"title": "Recall", "start_index": 7, "end_index": 7, "text": "â€˜Introductionâ€™ was extracted generally with the least values in terms of the evaluation criteria\n\n(0.68 for precision, recall and F-measure and 0.60 for accuracy). â€˜Conclusionâ€™ extraction was low too", "summary": "A metric measuring the proportion of correctly extracted sections among all actual target sections present in the document.", "node_type": "keyword", "_text_locked": true, "metadata": {"term": "Recall", "context": "A metric measuring the proportion of correctly extracted sections among all actual target sections present in the document.", "relevance": "Another key metric used to evaluate the performance of the extraction methods.", "parent_title": "Performance of 'Introduction' and 'Conclusion' Extraction", "parent_node_type": "semantic_unit"}, "nodes": [], "node_id": "0263"}, {"title": "F-measure", "start_index": 7, "end_index": 7, "text": "â€˜Introductionâ€™ was extracted generally with the least values in terms of the evaluation criteria\n\n(0.68 for precision, recall and F-measure and 0.60 for accuracy). â€˜Conclusionâ€™ extraction was low too", "summary": "The harmonic mean of precision and recall, providing a single score to balance both metrics.", "node_type": "keyword", "_text_locked": true, "metadata": {"term": "F-measure", "context": "The harmonic mean of precision and recall, providing a single score to balance both metrics.", "relevance": "A combined metric used to assess the overall performance of the extraction.", "parent_title": "Performance of 'Introduction' and 'Conclusion' Extraction", "parent_node_type": "semantic_unit"}, "nodes": [], "node_id": "0264"}, {"title": "Accuracy", "start_index": 7, "end_index": 7, "text": "â€˜Introductionâ€™ was extracted generally with the least values in terms of the evaluation criteria\n\n(0.68 for precision, recall and F-measure and 0.60 for accuracy). â€˜Conclusionâ€™ extraction was low too", "summary": "A metric measuring the overall correctness of the extraction process.", "node_type": "keyword", "_text_locked": true, "metadata": {"term": "Accuracy", "context": "A metric measuring the overall correctness of the extraction process.", "relevance": "A general measure of performance for the extraction tasks.", "parent_title": "Performance of 'Introduction' and 'Conclusion' Extraction", "parent_node_type": "semantic_unit"}, "nodes": [], "node_id": "0265"}], "node_id": "0258"}, {"title": "Reasons for Extraction Challenges", "start_index": 7, "end_index": 7, "text": "in terms of accuracy, although relatively high in precision (0.90). Reasons for these could be attrib-uted to the fact that in many cases introductions and conclusions exist in some theses (sometimes in every chapter), and sometimes too, other keywords that might not be recognized by the system are attached to them. In addition, some patterns not embedded in the rule-based system might be encountered leading to incorrect extraction.", "summary": "Challenges in extraction are attributed to the presence of introductions and conclusions in multiple chapters, unrecognized keywords, and patterns not covered by the rule-based system.", "node_type": "semantic_unit", "metadata": {"semantic_type": "interpretation", "start_paragraph": 2, "end_paragraph": 2, "original_title": "Reasons for Extraction Challenges"}, "nodes": [{"title": "accuracy", "start_index": 7, "end_index": 7, "text": "in terms of accuracy, although relatively high in precision (0.90). Reasons for these could be attrib-uted to the fact that in many cases introductions and conclusions exist in some theses (sometimes in every chapter), and sometimes too, other keywords that might not be recognized by the system are attached to them. In addition, some patterns not embedded in the rule-based system might be encountered leading to incorrect extraction.", "summary": "The degree of closeness of measurements of a quantity to that quantity's actual (true) value.", "node_type": "keyword", "_text_locked": true, "metadata": {"term": "accuracy", "context": "The degree of closeness of measurements of a quantity to that quantity's actual (true) value.", "relevance": "This is a key performance metric discussed in the section, highlighting a challenge in the extraction process.", "parent_title": "Reasons for Extraction Challenges", "parent_node_type": "semantic_unit"}, "nodes": [], "node_id": "0267"}, {"title": "precision", "start_index": 7, "end_index": 7, "text": "in terms of accuracy, although relatively high in precision (0.90). Reasons for these could be attrib-uted to the fact that in many cases introductions and conclusions exist in some theses (sometimes in every chapter), and sometimes too, other keywords that might not be recognized by the system are attached to them. In addition, some patterns not embedded in the rule-based system might be encountered leading to incorrect extraction.", "summary": "The degree of closeness of successive measurements (confirming the reproducibility of the measurement).", "node_type": "keyword", "_text_locked": true, "metadata": {"term": "precision", "context": "The degree of closeness of successive measurements (confirming the reproducibility of the measurement).", "relevance": "This metric is presented as relatively high, contrasting with the lower accuracy and indicating a specific aspect of the extraction performance.", "parent_title": "Reasons for Extraction Challenges", "parent_node_type": "semantic_unit"}, "nodes": [], "node_id": "0268"}, {"title": "introductions and conclusions", "start_index": 7, "end_index": 7, "text": "in terms of accuracy, although relatively high in precision (0.90). Reasons for these could be attrib-uted to the fact that in many cases introductions and conclusions exist in some theses (sometimes in every chapter), and sometimes too, other keywords that might not be recognized by the system are attached to them. In addition, some patterns not embedded in the rule-based system might be encountered leading to incorrect extraction.", "summary": "Sections within a document that typically summarize or introduce content.", "node_type": "keyword", "_text_locked": true, "metadata": {"term": "introductions and conclusions", "context": "Sections within a document that typically summarize or introduce content.", "relevance": "These sections are identified as a reason for extraction challenges, likely due to their distinct content or structure.", "parent_title": "Reasons for Extraction Challenges", "parent_node_type": "semantic_unit"}, "nodes": [], "node_id": "0269"}, {"title": "keywords", "start_index": 7, "end_index": 7, "text": "in terms of accuracy, although relatively high in precision (0.90). Reasons for these could be attrib-uted to the fact that in many cases introductions and conclusions exist in some theses (sometimes in every chapter), and sometimes too, other keywords that might not be recognized by the system are attached to them. In addition, some patterns not embedded in the rule-based system might be encountered leading to incorrect extraction.", "summary": "Words or phrases that describe the main topics of a document.", "node_type": "keyword", "_text_locked": true, "metadata": {"term": "keywords", "context": "Words or phrases that describe the main topics of a document.", "relevance": "The presence of unrecognized keywords attached to other sections is cited as a cause for extraction difficulties.", "parent_title": "Reasons for Extraction Challenges", "parent_node_type": "semantic_unit"}, "nodes": [], "node_id": "0270"}, {"title": "rule-based system", "start_index": 7, "end_index": 7, "text": "in terms of accuracy, although relatively high in precision (0.90). Reasons for these could be attrib-uted to the fact that in many cases introductions and conclusions exist in some theses (sometimes in every chapter), and sometimes too, other keywords that might not be recognized by the system are attached to them. In addition, some patterns not embedded in the rule-based system might be encountered leading to incorrect extraction.", "summary": "A system that uses a set of predefined rules to make decisions or perform actions.", "node_type": "keyword", "_text_locked": true, "metadata": {"term": "rule-based system", "context": "A system that uses a set of predefined rules to make decisions or perform actions.", "relevance": "The limitations of this system, specifically patterns not embedded within it, are presented as a reason for incorrect extraction.", "parent_title": "Reasons for Extraction Challenges", "parent_node_type": "semantic_unit"}, "nodes": [], "node_id": "0271"}, {"title": "extraction challenges", "start_index": 7, "end_index": 7, "text": "in terms of accuracy, although relatively high in precision (0.90). Reasons for these could be attrib-uted to the fact that in many cases introductions and conclusions exist in some theses (sometimes in every chapter), and sometimes too, other keywords that might not be recognized by the system are attached to them. In addition, some patterns not embedded in the rule-based system might be encountered leading to incorrect extraction.", "summary": "Difficulties encountered during the process of extracting specific information from text.", "node_type": "keyword", "_text_locked": true, "metadata": {"term": "extraction challenges", "context": "Difficulties encountered during the process of extracting specific information from text.", "relevance": "This is the overarching theme of the section, explaining the reasons behind the observed performance metrics.", "parent_title": "Reasons for Extraction Challenges", "parent_node_type": "semantic_unit"}, "nodes": [], "node_id": "0272"}], "node_id": "0266"}], "node_id": "0257"}, {"title": "Interpretation of 'Abstract' Extraction", "start_index": 7, "end_index": 7, "text": "â€˜Abstractâ€™ extraction was performed with relatively high recall and F-measure. The precision and\n\naccuracy of its extraction was mostly affected negatively because in a few theses, the abstract part was not specifically labelled â€˜Abstractâ€™ or was not labelled at all.", "summary": "'Abstract' extraction showed relatively high recall and F-measure, but precision and accuracy were negatively impacted because abstracts were not always clearly labeled or present in the documents.", "node_type": "semantic_unit", "metadata": {"semantic_type": "interpretation", "start_paragraph": 10, "end_paragraph": 11, "original_title": "Interpretation of 'Abstract' Extraction"}, "nodes": [{"title": "Abstract extraction", "start_index": 7, "end_index": 7, "text": "â€˜Abstractâ€™ extraction was performed with relatively high recall and F-measure. The precision and\n\naccuracy of its extraction was mostly affected negatively because in a few theses, the abstract part was not specifically labelled â€˜Abstractâ€™ or was not labelled at all.", "summary": "The process of identifying and retrieving the abstract section from documents.", "node_type": "keyword", "_text_locked": true, "metadata": {"term": "Abstract extraction", "context": "The process of identifying and retrieving the abstract section from documents.", "relevance": "This is the primary subject of the section, detailing the success and challenges of its implementation.", "parent_title": "Interpretation of 'Abstract' Extraction", "parent_node_type": "semantic_unit"}, "nodes": [], "node_id": "0274"}, {"title": "Recall", "start_index": 7, "end_index": 7, "text": "â€˜Abstractâ€™ extraction was performed with relatively high recall and F-measure. The precision and\n\naccuracy of its extraction was mostly affected negatively because in a few theses, the abstract part was not specifically labelled â€˜Abstractâ€™ or was not labelled at all.", "summary": "In information retrieval, recall measures the proportion of relevant items that are correctly retrieved.", "node_type": "keyword", "_text_locked": true, "metadata": {"term": "Recall", "context": "In information retrieval, recall measures the proportion of relevant items that are correctly retrieved.", "relevance": "It is a key metric used to evaluate the performance of the abstract extraction process.", "parent_title": "Interpretation of 'Abstract' Extraction", "parent_node_type": "semantic_unit"}, "nodes": [], "node_id": "0275"}, {"title": "F-measure", "start_index": 7, "end_index": 7, "text": "â€˜Abstractâ€™ extraction was performed with relatively high recall and F-measure. The precision and\n\naccuracy of its extraction was mostly affected negatively because in a few theses, the abstract part was not specifically labelled â€˜Abstractâ€™ or was not labelled at all.", "summary": "The harmonic mean of precision and recall, providing a single score to evaluate retrieval performance.", "node_type": "keyword", "_text_locked": true, "metadata": {"term": "F-measure", "context": "The harmonic mean of precision and recall, providing a single score to evaluate retrieval performance.", "relevance": "This metric, along with recall, indicates the overall effectiveness of the extraction method.", "parent_title": "Interpretation of 'Abstract' Extraction", "parent_node_type": "semantic_unit"}, "nodes": [], "node_id": "0276"}, {"title": "Precision", "start_index": 7, "end_index": 7, "text": "â€˜Abstractâ€™ extraction was performed with relatively high recall and F-measure. The precision and\n\naccuracy of its extraction was mostly affected negatively because in a few theses, the abstract part was not specifically labelled â€˜Abstractâ€™ or was not labelled at all.", "summary": "In information retrieval, precision measures the proportion of retrieved items that are relevant.", "node_type": "keyword", "_text_locked": true, "metadata": {"term": "Precision", "context": "In information retrieval, precision measures the proportion of retrieved items that are relevant.", "relevance": "It is another crucial metric for assessing the quality of the abstract extraction, though negatively affected in this case.", "parent_title": "Interpretation of 'Abstract' Extraction", "parent_node_type": "semantic_unit"}, "nodes": [], "node_id": "0277"}, {"title": "Accuracy", "start_index": 7, "end_index": 7, "text": "â€˜Abstractâ€™ extraction was performed with relatively high recall and F-measure. The precision and\n\naccuracy of its extraction was mostly affected negatively because in a few theses, the abstract part was not specifically labelled â€˜Abstractâ€™ or was not labelled at all.", "summary": "The overall correctness of the extraction process, considering both true positives and true negatives.", "node_type": "keyword", "_text_locked": true, "metadata": {"term": "Accuracy", "context": "The overall correctness of the extraction process, considering both true positives and true negatives.", "relevance": "This metric highlights the impact of unlabelled or mislabelled abstract sections on the extraction's reliability.", "parent_title": "Interpretation of 'Abstract' Extraction", "parent_node_type": "semantic_unit"}, "nodes": [], "node_id": "0278"}, {"title": "Theses", "start_index": 7, "end_index": 7, "text": "â€˜Abstractâ€™ extraction was performed with relatively high recall and F-measure. The precision and\n\naccuracy of its extraction was mostly affected negatively because in a few theses, the abstract part was not specifically labelled â€˜Abstractâ€™ or was not labelled at all.", "summary": "Academic documents, often dissertations or master's papers, from which abstracts are being extracted.", "node_type": "keyword", "_text_locked": true, "metadata": {"term": "Theses", "context": "Academic documents, often dissertations or master's papers, from which abstracts are being extracted.", "relevance": "These documents are the source material for the abstract extraction, and their formatting issues directly impact performance.", "parent_title": "Interpretation of 'Abstract' Extraction", "parent_node_type": "semantic_unit"}, "nodes": [], "node_id": "0279"}, {"title": "Labelled abstract", "start_index": 7, "end_index": 7, "text": "â€˜Abstractâ€™ extraction was performed with relatively high recall and F-measure. The precision and\n\naccuracy of its extraction was mostly affected negatively because in a few theses, the abstract part was not specifically labelled â€˜Abstractâ€™ or was not labelled at all.", "summary": "An abstract section that is explicitly marked or identified with a specific tag or heading.", "node_type": "keyword", "_text_locked": true, "metadata": {"term": "Labelled abstract", "context": "An abstract section that is explicitly marked or identified with a specific tag or heading.", "relevance": "The absence or mislabelling of this tag is identified as a primary reason for reduced extraction accuracy.", "parent_title": "Interpretation of 'Abstract' Extraction", "parent_node_type": "semantic_unit"}, "nodes": [], "node_id": "0280"}], "node_id": "0273"}, {"title": "Interpretation of 'Table of Contents' Extraction", "start_index": 7, "end_index": 7, "text": "â€˜Table of Contentsâ€™ was extracted with relatively high recall, but with fair precision and F-measure.\n\nThe accuracy with which it was extracted was a bit low, because in some cases, the system extracted some other parts, which were not actually part of the table of contents, with it.", "summary": "'Table of Contents' extraction had high recall but fair precision and F-measure. Accuracy was somewhat low because the system sometimes included extraneous content.", "node_type": "semantic_unit", "metadata": {"semantic_type": "interpretation", "start_paragraph": 12, "end_paragraph": 13, "original_title": "Interpretation of 'Table of Contents' Extraction"}, "nodes": [{"title": "Table of Contents extraction", "start_index": 7, "end_index": 7, "text": "â€˜Table of Contentsâ€™ was extracted with relatively high recall, but with fair precision and F-measure.\n\nThe accuracy with which it was extracted was a bit low, because in some cases, the system extracted some other parts, which were not actually part of the table of contents, with it.", "summary": "The process of identifying and extracting the table of contents from a document.", "node_type": "keyword", "_text_locked": true, "metadata": {"term": "Table of Contents extraction", "context": "The process of identifying and extracting the table of contents from a document.", "relevance": "This is the primary subject of the section, detailing the performance of its extraction.", "parent_title": "Interpretation of 'Table of Contents' Extraction", "parent_node_type": "semantic_unit"}, "nodes": [], "node_id": "0282"}, {"title": "Recall", "start_index": 7, "end_index": 7, "text": "â€˜Table of Contentsâ€™ was extracted with relatively high recall, but with fair precision and F-measure.\n\nThe accuracy with which it was extracted was a bit low, because in some cases, the system extracted some other parts, which were not actually part of the table of contents, with it.", "summary": "In information retrieval, recall measures the proportion of relevant items that are retrieved.", "node_type": "keyword", "_text_locked": true, "metadata": {"term": "Recall", "context": "In information retrieval, recall measures the proportion of relevant items that are retrieved.", "relevance": "A key metric used to evaluate the success of the 'Table of Contents' extraction.", "parent_title": "Interpretation of 'Table of Contents' Extraction", "parent_node_type": "semantic_unit"}, "nodes": [], "node_id": "0283"}, {"title": "Precision", "start_index": 7, "end_index": 7, "text": "â€˜Table of Contentsâ€™ was extracted with relatively high recall, but with fair precision and F-measure.\n\nThe accuracy with which it was extracted was a bit low, because in some cases, the system extracted some other parts, which were not actually part of the table of contents, with it.", "summary": "In information retrieval, precision measures the proportion of retrieved items that are relevant.", "node_type": "keyword", "_text_locked": true, "metadata": {"term": "Precision", "context": "In information retrieval, precision measures the proportion of retrieved items that are relevant.", "relevance": "Another key metric used to evaluate the success of the 'Table of Contents' extraction.", "parent_title": "Interpretation of 'Table of Contents' Extraction", "parent_node_type": "semantic_unit"}, "nodes": [], "node_id": "0284"}, {"title": "F-measure", "start_index": 7, "end_index": 7, "text": "â€˜Table of Contentsâ€™ was extracted with relatively high recall, but with fair precision and F-measure.\n\nThe accuracy with which it was extracted was a bit low, because in some cases, the system extracted some other parts, which were not actually part of the table of contents, with it.", "summary": "The harmonic mean of precision and recall, providing a single score for retrieval performance.", "node_type": "keyword", "_text_locked": true, "metadata": {"term": "F-measure", "context": "The harmonic mean of precision and recall, providing a single score for retrieval performance.", "relevance": "A combined metric indicating the overall effectiveness of the extraction process.", "parent_title": "Interpretation of 'Table of Contents' Extraction", "parent_node_type": "semantic_unit"}, "nodes": [], "node_id": "0285"}, {"title": "Accuracy", "start_index": 7, "end_index": 7, "text": "â€˜Table of Contentsâ€™ was extracted with relatively high recall, but with fair precision and F-measure.\n\nThe accuracy with which it was extracted was a bit low, because in some cases, the system extracted some other parts, which were not actually part of the table of contents, with it.", "summary": "The degree of closeness of measurements of a quantity to that quantity's actual (true) value.", "node_type": "keyword", "_text_locked": true, "metadata": {"term": "Accuracy", "context": "The degree of closeness of measurements of a quantity to that quantity's actual (true) value.", "relevance": "A measure of how correct the extracted 'Table of Contents' is, highlighting a specific weakness.", "parent_title": "Interpretation of 'Table of Contents' Extraction", "parent_node_type": "semantic_unit"}, "nodes": [], "node_id": "0286"}], "node_id": "0281"}, {"title": "Interpretation of 'Title' Extraction", "start_index": 7, "end_index": 7, "text": "â€˜Titleâ€™ extraction was particularly challenging as a result of the fact that titles of documents are\n\nnot usually labelled as such. Nevertheless, the task was done with consistent precision, recall, accu-racy and F-measure showing the effectiveness of the rule-based system. During the evaluation, it\n\nwas also discovered that, for most of the wrongly extracted cases for titles, the information extracted was still relevant, for instance when the authorsâ€™ names or institution of study were extracted.", "summary": "Title extraction was challenging due to the lack of explicit labeling, but the rule-based system achieved consistent performance. Notably, even incorrectly extracted titles often contained relevant information like author names or institutions.", "node_type": "semantic_unit", "metadata": {"semantic_type": "interpretation", "start_paragraph": 14, "end_paragraph": 16, "original_title": "Interpretation of 'Title' Extraction"}, "nodes": [{"title": "Effectiveness of Rule-Based System for Title Extraction", "start_index": 7, "end_index": 7, "text": "â€˜Titleâ€™ extraction was particularly challenging as a result of the fact that titles of documents are\n\nnot usually labelled as such. Nevertheless, the task was done with consistent precision, recall, accu-racy and F-measure showing the effectiveness of the rule-based system. During the evaluation, it", "summary": "The rule-based system demonstrated effectiveness in title extraction despite challenges, achieving high precision, recall, accuracy, and F-measure.", "node_type": "semantic_unit", "metadata": {"semantic_type": "interpretation", "start_paragraph": 0, "end_paragraph": 1, "original_title": "Effectiveness of Rule-Based System for Title Extraction"}, "nodes": [{"title": "Title extraction", "start_index": 7, "end_index": 7, "text": "â€˜Titleâ€™ extraction was particularly challenging as a result of the fact that titles of documents are\n\nnot usually labelled as such. Nevertheless, the task was done with consistent precision, recall, accu-racy and F-measure showing the effectiveness of the rule-based system. During the evaluation, it", "summary": "The process of identifying and extracting document titles from unstructured text.", "node_type": "keyword", "_text_locked": true, "metadata": {"term": "Title extraction", "context": "The process of identifying and extracting document titles from unstructured text.", "relevance": "This is the primary task being addressed and evaluated in the section.", "parent_title": "Effectiveness of Rule-Based System for Title Extraction", "parent_node_type": "semantic_unit"}, "nodes": [], "node_id": "0289"}, {"title": "Rule-based system", "start_index": 7, "end_index": 7, "text": "â€˜Titleâ€™ extraction was particularly challenging as a result of the fact that titles of documents are\n\nnot usually labelled as such. Nevertheless, the task was done with consistent precision, recall, accu-racy and F-measure showing the effectiveness of the rule-based system. During the evaluation, it", "summary": "A system that uses a set of predefined rules to make decisions or perform actions.", "node_type": "keyword", "_text_locked": true, "metadata": {"term": "Rule-based system", "context": "A system that uses a set of predefined rules to make decisions or perform actions.", "relevance": "This is the methodology employed for the title extraction task.", "parent_title": "Effectiveness of Rule-Based System for Title Extraction", "parent_node_type": "semantic_unit"}, "nodes": [], "node_id": "0290"}, {"title": "Precision", "start_index": 7, "end_index": 7, "text": "â€˜Titleâ€™ extraction was particularly challenging as a result of the fact that titles of documents are\n\nnot usually labelled as such. Nevertheless, the task was done with consistent precision, recall, accu-racy and F-measure showing the effectiveness of the rule-based system. During the evaluation, it", "summary": "A metric measuring the proportion of correctly identified titles out of all identified titles.", "node_type": "keyword", "_text_locked": true, "metadata": {"term": "Precision", "context": "A metric measuring the proportion of correctly identified titles out of all identified titles.", "relevance": "A key performance indicator used to evaluate the effectiveness of the system.", "parent_title": "Effectiveness of Rule-Based System for Title Extraction", "parent_node_type": "semantic_unit"}, "nodes": [], "node_id": "0291"}, {"title": "Recall", "start_index": 7, "end_index": 7, "text": "â€˜Titleâ€™ extraction was particularly challenging as a result of the fact that titles of documents are\n\nnot usually labelled as such. Nevertheless, the task was done with consistent precision, recall, accu-racy and F-measure showing the effectiveness of the rule-based system. During the evaluation, it", "summary": "A metric measuring the proportion of correctly identified titles out of all actual titles present.", "node_type": "keyword", "_text_locked": true, "metadata": {"term": "Recall", "context": "A metric measuring the proportion of correctly identified titles out of all actual titles present.", "relevance": "Another key performance indicator used to evaluate the effectiveness of the system.", "parent_title": "Effectiveness of Rule-Based System for Title Extraction", "parent_node_type": "semantic_unit"}, "nodes": [], "node_id": "0292"}, {"title": "Accuracy", "start_index": 7, "end_index": 7, "text": "â€˜Titleâ€™ extraction was particularly challenging as a result of the fact that titles of documents are\n\nnot usually labelled as such. Nevertheless, the task was done with consistent precision, recall, accu-racy and F-measure showing the effectiveness of the rule-based system. During the evaluation, it", "summary": "A metric representing the overall correctness of the title extraction process.", "node_type": "keyword", "_text_locked": true, "metadata": {"term": "Accuracy", "context": "A metric representing the overall correctness of the title extraction process.", "relevance": "A fundamental measure of the system's performance.", "parent_title": "Effectiveness of Rule-Based System for Title Extraction", "parent_node_type": "semantic_unit"}, "nodes": [], "node_id": "0293"}, {"title": "F-measure", "start_index": 7, "end_index": 7, "text": "â€˜Titleâ€™ extraction was particularly challenging as a result of the fact that titles of documents are\n\nnot usually labelled as such. Nevertheless, the task was done with consistent precision, recall, accu-racy and F-measure showing the effectiveness of the rule-based system. During the evaluation, it", "summary": "The harmonic mean of precision and recall, providing a single score for performance.", "node_type": "keyword", "_text_locked": true, "metadata": {"term": "F-measure", "context": "The harmonic mean of precision and recall, providing a single score for performance.", "relevance": "A combined metric that balances precision and recall for a comprehensive evaluation.", "parent_title": "Effectiveness of Rule-Based System for Title Extraction", "parent_node_type": "semantic_unit"}, "nodes": [], "node_id": "0294"}, {"title": "Unlabelled titles", "start_index": 7, "end_index": 7, "text": "â€˜Titleâ€™ extraction was particularly challenging as a result of the fact that titles of documents are\n\nnot usually labelled as such. Nevertheless, the task was done with consistent precision, recall, accu-racy and F-measure showing the effectiveness of the rule-based system. During the evaluation, it", "summary": "Document titles that are not explicitly marked or tagged within the text.", "node_type": "keyword", "_text_locked": true, "metadata": {"term": "Unlabelled titles", "context": "Document titles that are not explicitly marked or tagged within the text.", "relevance": "This highlights the inherent difficulty and challenge of the title extraction task.", "parent_title": "Effectiveness of Rule-Based System for Title Extraction", "parent_node_type": "semantic_unit"}, "nodes": [], "node_id": "0295"}], "node_id": "0288"}, {"title": "Relevance of Mis-extracted Information", "start_index": 7, "end_index": 7, "text": "was also discovered that, for most of the wrongly extracted cases for titles, the information extracted was still relevant, for instance when the authorsâ€™ names or institution of study were extracted.", "summary": "Even when title extraction was incorrect, the extracted information, such as author names or institutions, often remained relevant.", "node_type": "semantic_unit", "metadata": {"semantic_type": "interpretation", "start_paragraph": 2, "end_paragraph": 2, "original_title": "Relevance of Mis-extracted Information"}, "nodes": [{"title": "wrongly extracted cases", "start_index": 7, "end_index": 7, "text": "was also discovered that, for most of the wrongly extracted cases for titles, the information extracted was still relevant, for instance when the authorsâ€™ names or institution of study were extracted.", "summary": "Instances where information was incorrectly identified or pulled from a source.", "node_type": "keyword", "_text_locked": true, "metadata": {"term": "wrongly extracted cases", "context": "Instances where information was incorrectly identified or pulled from a source.", "relevance": "This highlights the focus of the section on analyzing errors in information extraction.", "parent_title": "Relevance of Mis-extracted Information", "parent_node_type": "semantic_unit"}, "nodes": [], "node_id": "0297"}, {"title": "extracted information", "start_index": 7, "end_index": 7, "text": "was also discovered that, for most of the wrongly extracted cases for titles, the information extracted was still relevant, for instance when the authorsâ€™ names or institution of study were extracted.", "summary": "Data or details that have been successfully identified and retrieved from a larger body of text.", "node_type": "keyword", "_text_locked": true, "metadata": {"term": "extracted information", "context": "Data or details that have been successfully identified and retrieved from a larger body of text.", "relevance": "The section discusses the utility of even incorrectly extracted information.", "parent_title": "Relevance of Mis-extracted Information", "parent_node_type": "semantic_unit"}, "nodes": [], "node_id": "0298"}, {"title": "authors' names", "start_index": 7, "end_index": 7, "text": "was also discovered that, for most of the wrongly extracted cases for titles, the information extracted was still relevant, for instance when the authorsâ€™ names or institution of study were extracted.", "summary": "The specific names identifying the creators of a work.", "node_type": "keyword", "_text_locked": true, "metadata": {"term": "authors' names", "context": "The specific names identifying the creators of a work.", "relevance": "This is given as an example of relevant information that might be wrongly extracted.", "parent_title": "Relevance of Mis-extracted Information", "parent_node_type": "semantic_unit"}, "nodes": [], "node_id": "0299"}, {"title": "institution of study", "start_index": 7, "end_index": 7, "text": "was also discovered that, for most of the wrongly extracted cases for titles, the information extracted was still relevant, for instance when the authorsâ€™ names or institution of study were extracted.", "summary": "The academic or research organization with which individuals are affiliated.", "node_type": "keyword", "_text_locked": true, "metadata": {"term": "institution of study", "context": "The academic or research organization with which individuals are affiliated.", "relevance": "This is another example of relevant information that can be extracted, even in error.", "parent_title": "Relevance of Mis-extracted Information", "parent_node_type": "semantic_unit"}, "nodes": [], "node_id": "0300"}], "node_id": "0296"}], "node_id": "0287"}, {"title": "Comparison with Hu et al. [10]", "start_index": 7, "end_index": 7, "text": "Some of the studies with presented results include the work of Hu et al. [10] who extracted title\n\nfrom Word documents with precision and recall of 0.810 and 0.837, respectively, and precision and recall of 0.875 and 0.895 from PowerPoint documents, respectively in an experiment on intranet data using machine learning technique.", "summary": "Compares the system's title extraction performance with Hu et al.'s results on Word and PowerPoint documents using machine learning, noting their reported precision and recall values.", "node_type": "semantic_unit", "metadata": {"semantic_type": "comparison", "start_paragraph": 17, "end_paragraph": 18, "original_title": "Comparison with Hu et al. [10]"}, "nodes": [{"title": "Hu et al. [10]", "start_index": 7, "end_index": 7, "text": "Some of the studies with presented results include the work of Hu et al. [10] who extracted title\n\nfrom Word documents with precision and recall of 0.810 and 0.837, respectively, and precision and recall of 0.875 and 0.895 from PowerPoint documents, respectively in an experiment on intranet data using machine learning technique.", "summary": "A specific study referenced for comparison, focusing on title extraction from documents.", "node_type": "keyword", "_text_locked": true, "metadata": {"term": "Hu et al. [10]", "context": "A specific study referenced for comparison, focusing on title extraction from documents.", "relevance": "This is the primary work against which the current section's findings are being compared.", "parent_title": "Comparison with Hu et al. [10]", "parent_node_type": "semantic_unit"}, "nodes": [], "node_id": "0302"}, {"title": "title extraction", "start_index": 7, "end_index": 7, "text": "Some of the studies with presented results include the work of Hu et al. [10] who extracted title\n\nfrom Word documents with precision and recall of 0.810 and 0.837, respectively, and precision and recall of 0.875 and 0.895 from PowerPoint documents, respectively in an experiment on intranet data using machine learning technique.", "summary": "The process of identifying and extracting titles from documents.", "node_type": "keyword", "_text_locked": true, "metadata": {"term": "title extraction", "context": "The process of identifying and extracting titles from documents.", "relevance": "This is the core task performed in the referenced Hu et al. study.", "parent_title": "Comparison with Hu et al. [10]", "parent_node_type": "semantic_unit"}, "nodes": [], "node_id": "0303"}, {"title": "Word documents", "start_index": 7, "end_index": 7, "text": "Some of the studies with presented results include the work of Hu et al. [10] who extracted title\n\nfrom Word documents with precision and recall of 0.810 and 0.837, respectively, and precision and recall of 0.875 and 0.895 from PowerPoint documents, respectively in an experiment on intranet data using machine learning technique.", "summary": "A type of document file format created by Microsoft Word.", "node_type": "keyword", "_text_locked": true, "metadata": {"term": "Word documents", "context": "A type of document file format created by Microsoft Word.", "relevance": "One of the document types on which Hu et al. performed their title extraction.", "parent_title": "Comparison with Hu et al. [10]", "parent_node_type": "semantic_unit"}, "nodes": [], "node_id": "0304"}, {"title": "PowerPoint documents", "start_index": 7, "end_index": 7, "text": "Some of the studies with presented results include the work of Hu et al. [10] who extracted title\n\nfrom Word documents with precision and recall of 0.810 and 0.837, respectively, and precision and recall of 0.875 and 0.895 from PowerPoint documents, respectively in an experiment on intranet data using machine learning technique.", "summary": "A type of document file format created by Microsoft PowerPoint.", "node_type": "keyword", "_text_locked": true, "metadata": {"term": "PowerPoint documents", "context": "A type of document file format created by Microsoft PowerPoint.", "relevance": "The other document type on which Hu et al. performed their title extraction.", "parent_title": "Comparison with Hu et al. [10]", "parent_node_type": "semantic_unit"}, "nodes": [], "node_id": "0305"}, {"title": "precision", "start_index": 7, "end_index": 7, "text": "Some of the studies with presented results include the work of Hu et al. [10] who extracted title\n\nfrom Word documents with precision and recall of 0.810 and 0.837, respectively, and precision and recall of 0.875 and 0.895 from PowerPoint documents, respectively in an experiment on intranet data using machine learning technique.", "summary": "A metric measuring the accuracy of positive predictions in information retrieval.", "node_type": "keyword", "_text_locked": true, "metadata": {"term": "precision", "context": "A metric measuring the accuracy of positive predictions in information retrieval.", "relevance": "A key performance metric reported by Hu et al. for their title extraction task.", "parent_title": "Comparison with Hu et al. [10]", "parent_node_type": "semantic_unit"}, "nodes": [], "node_id": "0306"}, {"title": "recall", "start_index": 7, "end_index": 7, "text": "Some of the studies with presented results include the work of Hu et al. [10] who extracted title\n\nfrom Word documents with precision and recall of 0.810 and 0.837, respectively, and precision and recall of 0.875 and 0.895 from PowerPoint documents, respectively in an experiment on intranet data using machine learning technique.", "summary": "A metric measuring the completeness of positive predictions in information retrieval.", "node_type": "keyword", "_text_locked": true, "metadata": {"term": "recall", "context": "A metric measuring the completeness of positive predictions in information retrieval.", "relevance": "Another key performance metric reported by Hu et al. for their title extraction task.", "parent_title": "Comparison with Hu et al. [10]", "parent_node_type": "semantic_unit"}, "nodes": [], "node_id": "0307"}, {"title": "intranet data", "start_index": 7, "end_index": 7, "text": "Some of the studies with presented results include the work of Hu et al. [10] who extracted title\n\nfrom Word documents with precision and recall of 0.810 and 0.837, respectively, and precision and recall of 0.875 and 0.895 from PowerPoint documents, respectively in an experiment on intranet data using machine learning technique.", "summary": "Data originating from within an organization's internal network.", "node_type": "keyword", "_text_locked": true, "metadata": {"term": "intranet data", "context": "Data originating from within an organization's internal network.", "relevance": "The dataset used by Hu et al. in their experiment, providing context for their results.", "parent_title": "Comparison with Hu et al. [10]", "parent_node_type": "semantic_unit"}, "nodes": [], "node_id": "0308"}, {"title": "machine learning technique", "start_index": 7, "end_index": 7, "text": "Some of the studies with presented results include the work of Hu et al. [10] who extracted title\n\nfrom Word documents with precision and recall of 0.810 and 0.837, respectively, and precision and recall of 0.875 and 0.895 from PowerPoint documents, respectively in an experiment on intranet data using machine learning technique.", "summary": "A method that enables systems to learn from data without explicit programming.", "node_type": "keyword", "_text_locked": true, "metadata": {"term": "machine learning technique", "context": "A method that enables systems to learn from data without explicit programming.", "relevance": "The underlying methodology employed by Hu et al. for their title extraction.", "parent_title": "Comparison with Hu et al. [10]", "parent_node_type": "semantic_unit"}, "nodes": [], "node_id": "0309"}], "node_id": "0301"}, {"title": "Comparison with Berkowitz and Elkhadiri [17] and Giuffrida et al. [14]", "start_index": 7, "end_index": 7, "text": "Some systems whose work could be fairly compared to this system include that of Berkowitz and\n\nElkhadiri [17] who extracted authors and titles from documents; they reported recall of 25.96% for exact extraction of author names; for 24.99% of the papers they managed to extract either part of the author name(s), or the name(s) plus extra text. All these focused on extraction of a single metadata. Giuffrida and colleagues [14] extracted title, author, affiliation, author-to-affiliation mapping and table of contents from Postscript files using a knowledge-based approach obtaining 92%, 87%, 75%, 71% and 76% accuracy respectively. Hence, the methods proposed by this research for general documents metadata extraction with particular emphasis on theses can handle the task with rela-tively high efficiency. Compared to existing systems, it extracts more metadata, and with relatively comparable effectiveness.", "summary": "Compares the current system to previous work by Berkowitz and Elkhadiri (single metadata extraction) and Giuffrida et al. (multiple metadata extraction using a knowledge-based approach), highlighting the current system's ability to extract more metadata with comparable effectiveness.", "node_type": "semantic_unit", "metadata": {"semantic_type": "comparison", "start_paragraph": 19, "end_paragraph": 20, "original_title": "Comparison with Berkowitz and Elkhadiri [17] and Giuffrida et al. [14]"}, "nodes": [{"title": "Berkowitz and Elkhadiri [17]", "start_index": 7, "end_index": 7, "text": "Some systems whose work could be fairly compared to this system include that of Berkowitz and\n\nElkhadiri [17] who extracted authors and titles from documents; they reported recall of 25.96% for exact extraction of author names; for 24.99% of the papers they managed to extract either part of the author name(s), or the name(s) plus extra text. All these focused on extraction of a single metadata. Giuffrida and colleagues [14] extracted title, author, affiliation, author-to-affiliation mapping and table of contents from Postscript files using a knowledge-based approach obtaining 92%, 87%, 75%, 71% and 76% accuracy respectively. Hence, the methods proposed by this research for general documents metadata extraction with particular emphasis on theses can handle the task with rela-tively high efficiency. Compared to existing systems, it extracts more metadata, and with relatively comparable effectiveness.", "summary": "A system that extracted authors and titles from documents, reporting specific recall rates for author name extraction.", "node_type": "keyword", "_text_locked": true, "metadata": {"term": "Berkowitz and Elkhadiri [17]", "context": "A system that extracted authors and titles from documents, reporting specific recall rates for author name extraction.", "relevance": "This work is a key point of comparison for the system's author and title extraction capabilities.", "parent_title": "Comparison with Berkowitz and Elkhadiri [17] and Giuffrida et al. [14]", "parent_node_type": "semantic_unit"}, "nodes": [], "node_id": "0311"}, {"title": "author name extraction", "start_index": 7, "end_index": 7, "text": "Some systems whose work could be fairly compared to this system include that of Berkowitz and\n\nElkhadiri [17] who extracted authors and titles from documents; they reported recall of 25.96% for exact extraction of author names; for 24.99% of the papers they managed to extract either part of the author name(s), or the name(s) plus extra text. All these focused on extraction of a single metadata. Giuffrida and colleagues [14] extracted title, author, affiliation, author-to-affiliation mapping and table of contents from Postscript files using a knowledge-based approach obtaining 92%, 87%, 75%, 71% and 76% accuracy respectively. Hence, the methods proposed by this research for general documents metadata extraction with particular emphasis on theses can handle the task with rela-tively high efficiency. Compared to existing systems, it extracts more metadata, and with relatively comparable effectiveness.", "summary": "The process of identifying and extracting author names from documents.", "node_type": "keyword", "_text_locked": true, "metadata": {"term": "author name extraction", "context": "The process of identifying and extracting author names from documents.", "relevance": "A specific metadata extraction task for which recall rates are reported and compared.", "parent_title": "Comparison with Berkowitz and Elkhadiri [17] and Giuffrida et al. [14]", "parent_node_type": "semantic_unit"}, "nodes": [], "node_id": "0312"}, {"title": "Giuffrida et al. [14]", "start_index": 7, "end_index": 7, "text": "Some systems whose work could be fairly compared to this system include that of Berkowitz and\n\nElkhadiri [17] who extracted authors and titles from documents; they reported recall of 25.96% for exact extraction of author names; for 24.99% of the papers they managed to extract either part of the author name(s), or the name(s) plus extra text. All these focused on extraction of a single metadata. Giuffrida and colleagues [14] extracted title, author, affiliation, author-to-affiliation mapping and table of contents from Postscript files using a knowledge-based approach obtaining 92%, 87%, 75%, 71% and 76% accuracy respectively. Hence, the methods proposed by this research for general documents metadata extraction with particular emphasis on theses can handle the task with rela-tively high efficiency. Compared to existing systems, it extracts more metadata, and with relatively comparable effectiveness.", "summary": "A system that extracted multiple metadata fields (title, author, affiliation, etc.) from Postscript files using a knowledge-based approach.", "node_type": "keyword", "_text_locked": true, "metadata": {"term": "Giuffrida et al. [14]", "context": "A system that extracted multiple metadata fields (title, author, affiliation, etc.) from Postscript files using a knowledge-based approach.", "relevance": "This work provides a benchmark for accuracy across various metadata extraction tasks, particularly for structured documents.", "parent_title": "Comparison with Berkowitz and Elkhadiri [17] and Giuffrida et al. [14]", "parent_node_type": "semantic_unit"}, "nodes": [], "node_id": "0313"}, {"title": "knowledge-based approach", "start_index": 7, "end_index": 7, "text": "Some systems whose work could be fairly compared to this system include that of Berkowitz and\n\nElkhadiri [17] who extracted authors and titles from documents; they reported recall of 25.96% for exact extraction of author names; for 24.99% of the papers they managed to extract either part of the author name(s), or the name(s) plus extra text. All these focused on extraction of a single metadata. Giuffrida and colleagues [14] extracted title, author, affiliation, author-to-affiliation mapping and table of contents from Postscript files using a knowledge-based approach obtaining 92%, 87%, 75%, 71% and 76% accuracy respectively. Hence, the methods proposed by this research for general documents metadata extraction with particular emphasis on theses can handle the task with rela-tively high efficiency. Compared to existing systems, it extracts more metadata, and with relatively comparable effectiveness.", "summary": "A method that utilizes existing knowledge or rules to perform a task, in this case, metadata extraction.", "node_type": "keyword", "_text_locked": true, "metadata": {"term": "knowledge-based approach", "context": "A method that utilizes existing knowledge or rules to perform a task, in this case, metadata extraction.", "relevance": "This methodology is used by a comparative system and highlights a different approach to metadata extraction.", "parent_title": "Comparison with Berkowitz and Elkhadiri [17] and Giuffrida et al. [14]", "parent_node_type": "semantic_unit"}, "nodes": [], "node_id": "0314"}, {"title": "general documents metadata extraction", "start_index": 7, "end_index": 7, "text": "Some systems whose work could be fairly compared to this system include that of Berkowitz and\n\nElkhadiri [17] who extracted authors and titles from documents; they reported recall of 25.96% for exact extraction of author names; for 24.99% of the papers they managed to extract either part of the author name(s), or the name(s) plus extra text. All these focused on extraction of a single metadata. Giuffrida and colleagues [14] extracted title, author, affiliation, author-to-affiliation mapping and table of contents from Postscript files using a knowledge-based approach obtaining 92%, 87%, 75%, 71% and 76% accuracy respectively. Hence, the methods proposed by this research for general documents metadata extraction with particular emphasis on theses can handle the task with rela-tively high efficiency. Compared to existing systems, it extracts more metadata, and with relatively comparable effectiveness.", "summary": "The process of extracting various pieces of information (metadata) from a wide range of document types.", "node_type": "keyword", "_text_locked": true, "metadata": {"term": "general documents metadata extraction", "context": "The process of extracting various pieces of information (metadata) from a wide range of document types.", "relevance": "This is the primary task addressed by the research, and the section compares its effectiveness against prior work.", "parent_title": "Comparison with Berkowitz and Elkhadiri [17] and Giuffrida et al. [14]", "parent_node_type": "semantic_unit"}, "nodes": [], "node_id": "0315"}, {"title": "theses metadata extraction", "start_index": 7, "end_index": 7, "text": "Some systems whose work could be fairly compared to this system include that of Berkowitz and\n\nElkhadiri [17] who extracted authors and titles from documents; they reported recall of 25.96% for exact extraction of author names; for 24.99% of the papers they managed to extract either part of the author name(s), or the name(s) plus extra text. All these focused on extraction of a single metadata. Giuffrida and colleagues [14] extracted title, author, affiliation, author-to-affiliation mapping and table of contents from Postscript files using a knowledge-based approach obtaining 92%, 87%, 75%, 71% and 76% accuracy respectively. Hence, the methods proposed by this research for general documents metadata extraction with particular emphasis on theses can handle the task with rela-tively high efficiency. Compared to existing systems, it extracts more metadata, and with relatively comparable effectiveness.", "summary": "The specific application of extracting metadata from academic theses.", "node_type": "keyword", "_text_locked": true, "metadata": {"term": "theses metadata extraction", "context": "The specific application of extracting metadata from academic theses.", "relevance": "This is a particular focus of the research, indicating a specialized application of the general metadata extraction methods.", "parent_title": "Comparison with Berkowitz and Elkhadiri [17] and Giuffrida et al. [14]", "parent_node_type": "semantic_unit"}, "nodes": [], "node_id": "0316"}], "node_id": "0310"}, {"title": "Conclusions and Future Research Directions", "start_index": 7, "end_index": 7, "text": "5. Conclusions and further research directions\n\nThis paper describes a method for general metadata extraction from general documents using a combination of the segmentation by keyword algorithm and regular expressions. Extraction of title is done using a different set of rules, implemented before segmentation by keyword is carried out because title extraction is often not affected by keywords. The rules used for title extraction proved consistently effective for theses and dissertations. The proposed model for extracting other metadata was tested on some randomly downloaded theses and related documents and used to extract Abstract, Preface, Table of Contents, Introduction, Conclusion, References and Acknowledgments. The experimental results show that the extraction was done with a relatively high degree of precision, recall and accuracy except for â€˜Introductionâ€™ and â€˜Conclusionâ€™ with low recall because of the usual existence of multiples of them in theses documents. Compared to existing systems, this system", "summary": "Summarizes the paper's method for metadata extraction using a combination of algorithms and highlights the effectiveness of the rules for title extraction. It also notes the system's performance on various metadata types and its comparative advantage over existing systems.", "node_type": "semantic_unit", "metadata": {"semantic_type": "future_work", "start_paragraph": 21, "end_paragraph": 22, "original_title": "Conclusions and Future Research Directions"}, "nodes": [{"title": "metadata extraction", "start_index": 7, "end_index": 7, "text": "5. Conclusions and further research directions\n\nThis paper describes a method for general metadata extraction from general documents using a combination of the segmentation by keyword algorithm and regular expressions. Extraction of title is done using a different set of rules, implemented before segmentation by keyword is carried out because title extraction is often not affected by keywords. The rules used for title extraction proved consistently effective for theses and dissertations. The proposed model for extracting other metadata was tested on some randomly downloaded theses and related documents and used to extract Abstract, Preface, Table of Contents, Introduction, Conclusion, References and Acknowledgments. The experimental results show that the extraction was done with a relatively high degree of precision, recall and accuracy except for â€˜Introductionâ€™ and â€˜Conclusionâ€™ with low recall because of the usual existence of multiples of them in theses documents. Compared to existing systems, this system", "summary": "The process of identifying and extracting specific pieces of information from documents.", "node_type": "keyword", "_text_locked": true, "metadata": {"term": "metadata extraction", "context": "The process of identifying and extracting specific pieces of information from documents.", "relevance": "This is the core task addressed by the method described in the paper.", "parent_title": "Conclusions and Future Research Directions", "parent_node_type": "semantic_unit"}, "nodes": [], "node_id": "0318"}, {"title": "segmentation by keyword algorithm", "start_index": 7, "end_index": 7, "text": "5. Conclusions and further research directions\n\nThis paper describes a method for general metadata extraction from general documents using a combination of the segmentation by keyword algorithm and regular expressions. Extraction of title is done using a different set of rules, implemented before segmentation by keyword is carried out because title extraction is often not affected by keywords. The rules used for title extraction proved consistently effective for theses and dissertations. The proposed model for extracting other metadata was tested on some randomly downloaded theses and related documents and used to extract Abstract, Preface, Table of Contents, Introduction, Conclusion, References and Acknowledgments. The experimental results show that the extraction was done with a relatively high degree of precision, recall and accuracy except for â€˜Introductionâ€™ and â€˜Conclusionâ€™ with low recall because of the usual existence of multiples of them in theses documents. Compared to existing systems, this system", "summary": "An algorithm that divides a document into sections based on the presence of specific keywords.", "node_type": "keyword", "_text_locked": true, "metadata": {"term": "segmentation by keyword algorithm", "context": "An algorithm that divides a document into sections based on the presence of specific keywords.", "relevance": "This is a primary algorithmic component used for metadata extraction.", "parent_title": "Conclusions and Future Research Directions", "parent_node_type": "semantic_unit"}, "nodes": [], "node_id": "0319"}, {"title": "regular expressions", "start_index": 7, "end_index": 7, "text": "5. Conclusions and further research directions\n\nThis paper describes a method for general metadata extraction from general documents using a combination of the segmentation by keyword algorithm and regular expressions. Extraction of title is done using a different set of rules, implemented before segmentation by keyword is carried out because title extraction is often not affected by keywords. The rules used for title extraction proved consistently effective for theses and dissertations. The proposed model for extracting other metadata was tested on some randomly downloaded theses and related documents and used to extract Abstract, Preface, Table of Contents, Introduction, Conclusion, References and Acknowledgments. The experimental results show that the extraction was done with a relatively high degree of precision, recall and accuracy except for â€˜Introductionâ€™ and â€˜Conclusionâ€™ with low recall because of the usual existence of multiples of them in theses documents. Compared to existing systems, this system", "summary": "Sequences of characters that define a search pattern, used for pattern matching within text.", "node_type": "keyword", "_text_locked": true, "metadata": {"term": "regular expressions", "context": "Sequences of characters that define a search pattern, used for pattern matching within text.", "relevance": "This is a complementary technique used alongside the keyword algorithm for extraction.", "parent_title": "Conclusions and Future Research Directions", "parent_node_type": "semantic_unit"}, "nodes": [], "node_id": "0320"}, {"title": "title extraction", "start_index": 7, "end_index": 7, "text": "5. Conclusions and further research directions\n\nThis paper describes a method for general metadata extraction from general documents using a combination of the segmentation by keyword algorithm and regular expressions. Extraction of title is done using a different set of rules, implemented before segmentation by keyword is carried out because title extraction is often not affected by keywords. The rules used for title extraction proved consistently effective for theses and dissertations. The proposed model for extracting other metadata was tested on some randomly downloaded theses and related documents and used to extract Abstract, Preface, Table of Contents, Introduction, Conclusion, References and Acknowledgments. The experimental results show that the extraction was done with a relatively high degree of precision, recall and accuracy except for â€˜Introductionâ€™ and â€˜Conclusionâ€™ with low recall because of the usual existence of multiples of them in theses documents. Compared to existing systems, this system", "summary": "The specific process of identifying and extracting the title from a document.", "node_type": "keyword", "_text_locked": true, "metadata": {"term": "title extraction", "context": "The specific process of identifying and extracting the title from a document.", "relevance": "This is a distinct extraction task handled by a separate set of rules due to its unique characteristics.", "parent_title": "Conclusions and Future Research Directions", "parent_node_type": "semantic_unit"}, "nodes": [], "node_id": "0321"}, {"title": "theses and dissertations", "start_index": 7, "end_index": 7, "text": "5. Conclusions and further research directions\n\nThis paper describes a method for general metadata extraction from general documents using a combination of the segmentation by keyword algorithm and regular expressions. Extraction of title is done using a different set of rules, implemented before segmentation by keyword is carried out because title extraction is often not affected by keywords. The rules used for title extraction proved consistently effective for theses and dissertations. The proposed model for extracting other metadata was tested on some randomly downloaded theses and related documents and used to extract Abstract, Preface, Table of Contents, Introduction, Conclusion, References and Acknowledgments. The experimental results show that the extraction was done with a relatively high degree of precision, recall and accuracy except for â€˜Introductionâ€™ and â€˜Conclusionâ€™ with low recall because of the usual existence of multiples of them in theses documents. Compared to existing systems, this system", "summary": "Academic documents typically submitted for a degree or diploma.", "node_type": "keyword", "_text_locked": true, "metadata": {"term": "theses and dissertations", "context": "Academic documents typically submitted for a degree or diploma.", "relevance": "The primary type of documents on which the title extraction rules were tested and found effective.", "parent_title": "Conclusions and Future Research Directions", "parent_node_type": "semantic_unit"}, "nodes": [], "node_id": "0322"}, {"title": "Abstract, Preface, Table of Contents, Introduction, Conclusion, References, Acknowledgments", "start_index": 7, "end_index": 7, "text": "5. Conclusions and further research directions\n\nThis paper describes a method for general metadata extraction from general documents using a combination of the segmentation by keyword algorithm and regular expressions. Extraction of title is done using a different set of rules, implemented before segmentation by keyword is carried out because title extraction is often not affected by keywords. The rules used for title extraction proved consistently effective for theses and dissertations. The proposed model for extracting other metadata was tested on some randomly downloaded theses and related documents and used to extract Abstract, Preface, Table of Contents, Introduction, Conclusion, References and Acknowledgments. The experimental results show that the extraction was done with a relatively high degree of precision, recall and accuracy except for â€˜Introductionâ€™ and â€˜Conclusionâ€™ with low recall because of the usual existence of multiples of them in theses documents. Compared to existing systems, this system", "summary": "Common sections found in academic documents that constitute metadata.", "node_type": "keyword", "_text_locked": true, "metadata": {"term": "Abstract, Preface, Table of Contents, Introduction, Conclusion, References, Acknowledgments", "context": "Common sections found in academic documents that constitute metadata.", "relevance": "These are the specific metadata elements targeted for extraction by the proposed model.", "parent_title": "Conclusions and Future Research Directions", "parent_node_type": "semantic_unit"}, "nodes": [], "node_id": "0323"}, {"title": "precision, recall, and accuracy", "start_index": 7, "end_index": 7, "text": "5. Conclusions and further research directions\n\nThis paper describes a method for general metadata extraction from general documents using a combination of the segmentation by keyword algorithm and regular expressions. Extraction of title is done using a different set of rules, implemented before segmentation by keyword is carried out because title extraction is often not affected by keywords. The rules used for title extraction proved consistently effective for theses and dissertations. The proposed model for extracting other metadata was tested on some randomly downloaded theses and related documents and used to extract Abstract, Preface, Table of Contents, Introduction, Conclusion, References and Acknowledgments. The experimental results show that the extraction was done with a relatively high degree of precision, recall and accuracy except for â€˜Introductionâ€™ and â€˜Conclusionâ€™ with low recall because of the usual existence of multiples of them in theses documents. Compared to existing systems, this system", "summary": "Metrics used to evaluate the performance of information retrieval or extraction systems.", "node_type": "keyword", "_text_locked": true, "metadata": {"term": "precision, recall, and accuracy", "context": "Metrics used to evaluate the performance of information retrieval or extraction systems.", "relevance": "These are the key performance indicators used to assess the effectiveness of the proposed extraction model.", "parent_title": "Conclusions and Future Research Directions", "parent_node_type": "semantic_unit"}, "nodes": [], "node_id": "0324"}, {"title": "low recall", "start_index": 7, "end_index": 7, "text": "5. Conclusions and further research directions\n\nThis paper describes a method for general metadata extraction from general documents using a combination of the segmentation by keyword algorithm and regular expressions. Extraction of title is done using a different set of rules, implemented before segmentation by keyword is carried out because title extraction is often not affected by keywords. The rules used for title extraction proved consistently effective for theses and dissertations. The proposed model for extracting other metadata was tested on some randomly downloaded theses and related documents and used to extract Abstract, Preface, Table of Contents, Introduction, Conclusion, References and Acknowledgments. The experimental results show that the extraction was done with a relatively high degree of precision, recall and accuracy except for â€˜Introductionâ€™ and â€˜Conclusionâ€™ with low recall because of the usual existence of multiples of them in theses documents. Compared to existing systems, this system", "summary": "A performance issue where the system fails to retrieve a significant portion of the relevant items.", "node_type": "keyword", "_text_locked": true, "metadata": {"term": "low recall", "context": "A performance issue where the system fails to retrieve a significant portion of the relevant items.", "relevance": "This was an observed limitation in extracting 'Introduction' and 'Conclusion' due to their multiplicity.", "parent_title": "Conclusions and Future Research Directions", "parent_node_type": "semantic_unit"}, "nodes": [], "node_id": "0325"}], "node_id": "0317"}], "node_id": "0242"}], "node_id": "0092"}, {"title": "Conclusions and further research directions", "start_index": 7, "end_index": 8, "text": "Bolanle Adefowoke Ojokoh et al.\nJournal of Information Science, 35 (5) 2009, pp. 563â€“570 Â© CILIP, DOI: 10.1177/0165551509105195 569From the results, â€˜Referencesâ€™ was extracted with the highest precision. Its extraction is also rela-\ntively high compared to others in terms of recall, accuracy and F-measure. This could be largely due \nto the fact that they appear, in most cases, at the end of the document.\nMost of the â€˜Prefaceâ€™ extraction cases fall under the not existing and not extracted cases because \nvery few of the documents (only six) contained a preface. As a result, recall and accuracy were high-\nest for â€˜Prefaceâ€™.\nâ€˜Introductionâ€™ was extracted generally with the least values in terms of the evaluation criteria \n(0.68 for precision, recall and F-measure and 0.60 for accuracy). â€˜Conclusionâ€™ extraction was low too \nin terms of accuracy, although relatively high in precision (0.90). Reasons for these could be attrib-uted to the fact that in many cases introductions and conclusions exist in some theses (sometimes in every chapter), and sometimes too, other keywords that might not be recognized by the system are attached to them. In addition, some patterns not embedded in the rule-based system might be encountered leading to incorrect extraction.\nâ€˜Abstractâ€™ extraction was performed with relatively high recall and F-measure. The precision and \naccuracy of its extraction was mostly affected negatively because in a few theses, the abstract part was not specifically labelled â€˜Abstractâ€™ or was not labelled at all.\nâ€˜Table of Contentsâ€™ was extracted with relatively high recall, but with fair precision and F-measure. \nThe accuracy with which it was extracted was a bit low, because in some cases, the system extracted some other parts, which were not actually part of the table of contents, with it.\nâ€˜Titleâ€™ extraction was particularly challenging as a result of the fact that titles of documents are \nnot usually labelled as such. Nevertheless, the task was done with consistent precision, recall, accu-racy and F-measure showing the effectiveness of the rule-based system. During the evaluation, it \nwas also discovered that, for most of the wrongly extracted cases for titles, the information extracted was still relevant, for instance when the authorsâ€™ names or institution of study were extracted.\nSome of the studies with presented results include the work of Hu et al. [10] who extracted title \nfrom Word documents with precision and recall of 0.810 and 0.837, respectively, and precision and recall of 0.875 and 0.895 from PowerPoint documents, respectively in an experiment on intranet data using machine learning technique.\nSome systems whose work could be fairly compared to this system include that of Berkowitz and \nElkhadiri [17] who extracted authors and titles from documents; they reported recall of 25.96% for exact extraction of author names; for 24.99% of the papers they managed to extract either part of the author name(s), or the name(s) plus extra text. All these focused on extraction of a single metadata. Giuffrida and colleagues [14] extracted title, author, affiliation, author-to-affiliation mapping and table of contents from Postscript files using a knowledge-based approach obtaining 92%, 87%, 75%, 71% and 76% accuracy respectively. Hence, the methods proposed by this research for general documents metadata extraction with particular emphasis on theses can handle the task with rela-tively high efficiency. Compared to existing systems, it extracts more metadata, and with relatively comparable effectiveness.\n5. Conclusions and further research directions\nThis paper describes a method for general metadata extraction from general documents using a combination of the segmentation by keyword algorithm and regular expressions. Extraction of title is done using a different set of rules, implemented before segmentation by keyword is carried out because title extraction is often not affected by keywords. The rules used for title extraction proved consistently effective for theses and dissertations. The proposed model for extracting other metadata was tested on some randomly downloaded theses and related documents and used to extract Abstract, Preface, Table of Contents, Introduction, Conclusion, References and Acknowledgments. The experimental results show that the extraction was done with a relatively high degree of precision, recall and accuracy except for â€˜Introductionâ€™ and â€˜Conclusionâ€™ with low recall because of the usual existence of multiples of them in theses documents. Compared to existing systems, this system Bolanle Adefowoke Ojokoh et al.\nJournal of Information Science, 35 (5) 2009, pp. 563â€“570 Â© CILIP, DOI: 10.1177/0165551509105195 570extracts more metadata, and with relatively comparable effectiveness. However, since it is rule \nbased, it needs refinement over time as more keywords are discovered and metadata extraction is to be done for some different types of documents. \nReferences\n [1] K.M. Summers, Automatic discovery of logical document structure (PhD dissertation, Cornell University, \nIthaca, NY, 1998).\n [2] A. Arasu and H. Garcia-Molina, Extracting structured data from web pages, Proceedings of the 2003 ACM \nSIGMOD International Conference on Management of Data (SIGMOD) (June 2003) 337â€“348.\n [3] A. Crystal and P. Land, Metadata and search, Global Corporate Circle DCMI 2003 Workshop (2003). \nAvailable from http://dublincore.org/groups/corporate/Seattle/\n [4] H. Han, C.L. Giles, E. Manavoglu, H. Zha, Z. Zhang and E.A. Fox, Automatic document metadata extraction \nusing support vector machine, Joint Conference on Digital Libraries (JCDLâ€™03)  (Houston, Texas USA, 2003).\n [5] B.A. Ojokoh, S.O. Falaki and O.S. Adewale, Automated information extraction system for heterogeneous \ndigital library documents, Proceedings of the ACM/IEEE Joint Conference on Digital Libraries (JCDL 2007) \nDoctoral Consortium (Vancouver, British Columbia, Canada, June 18â€“23, 2007).\n [6] A. Kawtrakul and C. Yingsaeree, A Unified Framework for Automatic Metadata Extraction from Electronic \nDocument (2004). Available at: http://iadlc.nul.nagoya-u.ac.jp/archives/IADLC2005/kawrtrakul.pdf\n [7] E.D. Liddy, S. Sutton, E. Allen, S. Harwell, S. Corieri and O. Yilmazel, Automatic metadata generation and evaluation, Proceedings of the 25th Annual International ACM SIGIR Conference on Research and \nDevelopment in Information Retrieval (Tampere, Finland, 2002) 401â€“402.\n [8] O. Yilmazel, C.M. Finneran and E.D. Liddy, MetaExtract: an NLP system to automatically assign metadata, Proceedings of the 2004 Joint ACM/IEEE Conference on Digital Libraries  (Tuscan, AZ, USA, 2004) 241â€“242.\n [9] S. Mao, J.W. Kim and G.R. Thoma, A dynamic feature generation system for automated metadata extrac-tion in preservation of digital materials, Proceedings of the First International Workshop on Document \nImage Analysis for Libraries (Palo Alto, CA, USA, 2004) 225â€“232.\n[10] Y. Hu, H. Li, Y. Cao, T. Teng, D. Meyerzon and Q. Zheng, Automatic extraction of titles from general documents, Information Processing and Management 42 (2006) 1276â€“1293.\n[11]  F. Peng and A. McCallum, Accurate information extraction from research papers using conditional ran-dom fields, Proceedings of the Human Language Technology Conference/North American Chapter of the \nAssociation for Computational Linguistics Annual Meeting (New York, NY, USA, 2004) 329â€“336.\n[12] B.A. Ojokoh, O.S. Adewale and S.O. Falaki, Improving on the smoothing technique for obtaining emis-sion probabilities in hidden Markov models, Oriental Journal of Computer Science and Technology 1(1) \n(2008) 15â€“24.\n[13] K. Seymore, A. McCallum and R. Rosenfeld, Learning hidden Markov model structure for information \nextraction. In: AAAI Workshop on Machine Learning for Information Extraction (1999).\n[14] G. Giuffrida, E.C Shek and J. Yang, Knowledge-based metadata extraction from postscript files, ACM \nDigital Libraries (2000) 77â€“84. \n[15] K. Nakagawa, A. Nomura and M. Suzuki, Extraction of Logical Structure from Articles in Mathematics \n(Springer, Berlin, 2004).\n[16] M. KrÃ¤mer, H. Kaprykowsky, D. Keysers and T. Breuel, Bibliographic metadata extraction using probabi-\nlistic finite state transducers, Ninth International Conference on Document Analysis and Recognition \n(2007) 609â€“613.\n[17] E.G. Berkowitz and M.R. Elkhadiri, Creation of a Style Independent Intelligent Autonomous Citation \nIndexer to Support Academic Research (MAICS 2004) 68â€“73.", "node_id": "0326"}, {"title": "References", "start_index": 8, "end_index": 8, "text": "Bolanle Adefowoke Ojokoh et al.\nJournal of Information Science, 35 (5) 2009, pp. 563â€“570 Â© CILIP, DOI: 10.1177/0165551509105195 570extracts more metadata, and with relatively comparable effectiveness. However, since it is rule \nbased, it needs refinement over time as more keywords are discovered and metadata extraction is to be done for some different types of documents. \nReferences\n [1] K.M. Summers, Automatic discovery of logical document structure (PhD dissertation, Cornell University, \nIthaca, NY, 1998).\n [2] A. Arasu and H. Garcia-Molina, Extracting structured data from web pages, Proceedings of the 2003 ACM \nSIGMOD International Conference on Management of Data (SIGMOD) (June 2003) 337â€“348.\n [3] A. Crystal and P. Land, Metadata and search, Global Corporate Circle DCMI 2003 Workshop (2003). \nAvailable from http://dublincore.org/groups/corporate/Seattle/\n [4] H. Han, C.L. Giles, E. Manavoglu, H. Zha, Z. Zhang and E.A. Fox, Automatic document metadata extraction \nusing support vector machine, Joint Conference on Digital Libraries (JCDLâ€™03)  (Houston, Texas USA, 2003).\n [5] B.A. Ojokoh, S.O. Falaki and O.S. Adewale, Automated information extraction system for heterogeneous \ndigital library documents, Proceedings of the ACM/IEEE Joint Conference on Digital Libraries (JCDL 2007) \nDoctoral Consortium (Vancouver, British Columbia, Canada, June 18â€“23, 2007).\n [6] A. Kawtrakul and C. Yingsaeree, A Unified Framework for Automatic Metadata Extraction from Electronic \nDocument (2004). Available at: http://iadlc.nul.nagoya-u.ac.jp/archives/IADLC2005/kawrtrakul.pdf\n [7] E.D. Liddy, S. Sutton, E. Allen, S. Harwell, S. Corieri and O. Yilmazel, Automatic metadata generation and evaluation, Proceedings of the 25th Annual International ACM SIGIR Conference on Research and \nDevelopment in Information Retrieval (Tampere, Finland, 2002) 401â€“402.\n [8] O. Yilmazel, C.M. Finneran and E.D. Liddy, MetaExtract: an NLP system to automatically assign metadata, Proceedings of the 2004 Joint ACM/IEEE Conference on Digital Libraries  (Tuscan, AZ, USA, 2004) 241â€“242.\n [9] S. Mao, J.W. Kim and G.R. Thoma, A dynamic feature generation system for automated metadata extrac-tion in preservation of digital materials, Proceedings of the First International Workshop on Document \nImage Analysis for Libraries (Palo Alto, CA, USA, 2004) 225â€“232.\n[10] Y. Hu, H. Li, Y. Cao, T. Teng, D. Meyerzon and Q. Zheng, Automatic extraction of titles from general documents, Information Processing and Management 42 (2006) 1276â€“1293.\n[11]  F. Peng and A. McCallum, Accurate information extraction from research papers using conditional ran-dom fields, Proceedings of the Human Language Technology Conference/North American Chapter of the \nAssociation for Computational Linguistics Annual Meeting (New York, NY, USA, 2004) 329â€“336.\n[12] B.A. Ojokoh, O.S. Adewale and S.O. Falaki, Improving on the smoothing technique for obtaining emis-sion probabilities in hidden Markov models, Oriental Journal of Computer Science and Technology 1(1) \n(2008) 15â€“24.\n[13] K. Seymore, A. McCallum and R. Rosenfeld, Learning hidden Markov model structure for information \nextraction. In: AAAI Workshop on Machine Learning for Information Extraction (1999).\n[14] G. Giuffrida, E.C Shek and J. Yang, Knowledge-based metadata extraction from postscript files, ACM \nDigital Libraries (2000) 77â€“84. \n[15] K. Nakagawa, A. Nomura and M. Suzuki, Extraction of Logical Structure from Articles in Mathematics \n(Springer, Berlin, 2004).\n[16] M. KrÃ¤mer, H. Kaprykowsky, D. Keysers and T. Breuel, Bibliographic metadata extraction using probabi-\nlistic finite state transducers, Ninth International Conference on Document Analysis and Recognition \n(2007) 609â€“613.\n[17] E.G. Berkowitz and M.R. Elkhadiri, Creation of a Style Independent Intelligent Autonomous Citation \nIndexer to Support Academic Research (MAICS 2004) 68â€“73.", "nodes": [{"title": "Authors and Publication Details", "start_index": 8, "end_index": 8, "text": "Bolanle Adefowoke Ojokoh et al.\n\nJournal of Information Science, 35 (5) 2009, pp. 563â€“570 Â© CILIP, DOI: 10.1177/0165551509105195 570extracts more metadata, and with relatively comparable effectiveness. However, since it is rule\n\nbased, it needs refinement over time as more keywords are discovered and metadata extraction is to be done for some different types of documents.", "summary": "This unit identifies the authors of the work, the journal it was published in, and provides a brief note on the metadata extraction method discussed.", "node_type": "semantic_unit", "metadata": {"semantic_type": "metadata", "start_paragraph": 0, "end_paragraph": 2, "original_title": "Authors and Publication Details"}, "nodes": [{"title": "Citation and Metadata Extraction Discussion", "start_index": 8, "end_index": 8, "text": "Bolanle Adefowoke Ojokoh et al.\n\nJournal of Information Science, 35 (5) 2009, pp. 563â€“570 Â© CILIP, DOI: 10.1177/0165551509105195 570extracts more metadata, and with relatively comparable effectiveness. However, since it is rule\n\nbased, it needs refinement over time as more keywords are discovered and metadata extraction is to be done for some different types of documents.", "summary": "This unit presents a citation for a journal article by Bolanle Adefowoke Ojokoh et al. and discusses the effectiveness and limitations of a rule-based metadata extraction method, highlighting the need for ongoing refinement.", "node_type": "semantic_unit", "metadata": {"semantic_type": "Academic Citation and Methodological Discussion", "start_paragraph": 0, "end_paragraph": 2, "original_title": "Citation and Metadata Extraction Discussion"}, "nodes": [{"title": "metadata extraction", "start_index": 8, "end_index": 8, "text": "Bolanle Adefowoke Ojokoh et al.\n\nJournal of Information Science, 35 (5) 2009, pp. 563â€“570 Â© CILIP, DOI: 10.1177/0165551509105195 570extracts more metadata, and with relatively comparable effectiveness. However, since it is rule\n\nbased, it needs refinement over time as more keywords are discovered and metadata extraction is to be done for some different types of documents.", "summary": "The process of automatically identifying and retrieving descriptive information from documents.", "node_type": "keyword", "_text_locked": true, "metadata": {"term": "metadata extraction", "context": "The process of automatically identifying and retrieving descriptive information from documents.", "relevance": "This is the core task discussed in the section, focusing on its challenges and methods.", "parent_title": "Citation and Metadata Extraction Discussion", "parent_node_type": "semantic_unit"}, "nodes": [], "node_id": "0330"}, {"title": "rule-based system", "start_index": 8, "end_index": 8, "text": "Bolanle Adefowoke Ojokoh et al.\n\nJournal of Information Science, 35 (5) 2009, pp. 563â€“570 Â© CILIP, DOI: 10.1177/0165551509105195 570extracts more metadata, and with relatively comparable effectiveness. However, since it is rule\n\nbased, it needs refinement over time as more keywords are discovered and metadata extraction is to be done for some different types of documents.", "summary": "A system that uses a set of predefined rules to make decisions or perform actions.", "node_type": "keyword", "_text_locked": true, "metadata": {"term": "rule-based system", "context": "A system that uses a set of predefined rules to make decisions or perform actions.", "relevance": "This describes a specific approach to metadata extraction that requires ongoing maintenance.", "parent_title": "Citation and Metadata Extraction Discussion", "parent_node_type": "semantic_unit"}, "nodes": [], "node_id": "0331"}, {"title": "refinement over time", "start_index": 8, "end_index": 8, "text": "Bolanle Adefowoke Ojokoh et al.\n\nJournal of Information Science, 35 (5) 2009, pp. 563â€“570 Â© CILIP, DOI: 10.1177/0165551509105195 570extracts more metadata, and with relatively comparable effectiveness. However, since it is rule\n\nbased, it needs refinement over time as more keywords are discovered and metadata extraction is to be done for some different types of documents.", "summary": "The necessity for a system to be updated and improved as new information or patterns emerge.", "node_type": "keyword", "_text_locked": true, "metadata": {"term": "refinement over time", "context": "The necessity for a system to be updated and improved as new information or patterns emerge.", "relevance": "Highlights a key limitation of rule-based systems in the context of evolving data.", "parent_title": "Citation and Metadata Extraction Discussion", "parent_node_type": "semantic_unit"}, "nodes": [], "node_id": "0332"}, {"title": "keywords", "start_index": 8, "end_index": 8, "text": "Bolanle Adefowoke Ojokoh et al.\n\nJournal of Information Science, 35 (5) 2009, pp. 563â€“570 Â© CILIP, DOI: 10.1177/0165551509105195 570extracts more metadata, and with relatively comparable effectiveness. However, since it is rule\n\nbased, it needs refinement over time as more keywords are discovered and metadata extraction is to be done for some different types of documents.", "summary": "Specific terms or phrases that represent the main topics or concepts within a document.", "node_type": "keyword", "_text_locked": true, "metadata": {"term": "keywords", "context": "Specific terms or phrases that represent the main topics or concepts within a document.", "relevance": "The discovery of new keywords is presented as a requirement for refining metadata extraction.", "parent_title": "Citation and Metadata Extraction Discussion", "parent_node_type": "semantic_unit"}, "nodes": [], "node_id": "0333"}, {"title": "different types of documents", "start_index": 8, "end_index": 8, "text": "Bolanle Adefowoke Ojokoh et al.\n\nJournal of Information Science, 35 (5) 2009, pp. 563â€“570 Â© CILIP, DOI: 10.1177/0165551509105195 570extracts more metadata, and with relatively comparable effectiveness. However, since it is rule\n\nbased, it needs refinement over time as more keywords are discovered and metadata extraction is to be done for some different types of documents.", "summary": "Variations in the structure, content, and format of various textual materials.", "node_type": "keyword", "_text_locked": true, "metadata": {"term": "different types of documents", "context": "Variations in the structure, content, and format of various textual materials.", "relevance": "The need for adaptation in metadata extraction methods is emphasized when dealing with diverse document types.", "parent_title": "Citation and Metadata Extraction Discussion", "parent_node_type": "semantic_unit"}, "nodes": [], "node_id": "0334"}], "node_id": "0329"}], "node_id": "0328"}, {"title": "References", "start_index": 8, "end_index": 8, "text": "References\n\n[1] K.M. Summers, Automatic discovery of logical document structure (PhD dissertation, Cornell University,\n\nIthaca, NY, 1998).\n\n[2] A. Arasu and H. Garcia-Molina, Extracting structured data from web pages, Proceedings of the 2003 ACM\n\nSIGMOD International Conference on Management of Data (SIGMOD) (June 2003) 337â€“348.\n\n[3] A. Crystal and P. Land, Metadata and search, Global Corporate Circle DCMI 2003 Workshop (2003).\n\nAvailable from http://dublincore.org/groups/corporate/Seattle/\n\n[4] H. Han, C.L. Giles, E. Manavoglu, H. Zha, Z. Zhang and E.A. Fox, Automatic document metadata extraction\n\nusing support vector machine, Joint Conference on Digital Libraries (JCDLâ€™03)  (Houston, Texas USA, 2003).\n\n[5] B.A. Ojokoh, S.O. Falaki and O.S. Adewale, Automated information extraction system for heterogeneous\n\ndigital library documents, Proceedings of the ACM/IEEE Joint Conference on Digital Libraries (JCDL 2007)\n\nDoctoral Consortium (Vancouver, British Columbia, Canada, June 18â€“23, 2007).\n\n[6] A. Kawtrakul and C. Yingsaeree, A Unified Framework for Automatic Metadata Extraction from Electronic\n\nDocument (2004). Available at: http://iadlc.nul.nagoya-u.ac.jp/archives/IADLC2005/kawrtrakul.pdf\n\n[7] E.D. Liddy, S. Sutton, E. Allen, S. Harwell, S. Corieri and O. Yilmazel, Automatic metadata generation and evaluation, Proceedings of the 25th Annual International ACM SIGIR Conference on Research and\n\nDevelopment in Information Retrieval (Tampere, Finland, 2002) 401â€“402.\n\n[8] O. Yilmazel, C.M. Finneran and E.D. Liddy, MetaExtract: an NLP system to automatically assign metadata, Proceedings of the 2004 Joint ACM/IEEE Conference on Digital Libraries  (Tuscan, AZ, USA, 2004) 241â€“242.\n\n[9] S. Mao, J.W. Kim and G.R. Thoma, A dynamic feature generation system for automated metadata extrac-tion in preservation of digital materials, Proceedings of the First International Workshop on Document\n\nImage Analysis for Libraries (Palo Alto, CA, USA, 2004) 225â€“232.\n\n[10] Y. Hu, H. Li, Y. Cao, T. Teng, D. Meyerzon and Q. Zheng, Automatic extraction of titles from general documents, Information Processing and Management 42 (2006) 1276â€“1293.\n\n[11]  F. Peng and A. McCallum, Accurate information extraction from research papers using conditional ran-dom fields, Proceedings of the Human Language Technology Conference/North American Chapter of the\n\nAssociation for Computational Linguistics Annual Meeting (New York, NY, USA, 2004) 329â€“336.\n\n[12] B.A. Ojokoh, O.S. Adewale and S.O. Falaki, Improving on the smoothing technique for obtaining emis-sion probabilities in hidden Markov models, Oriental Journal of Computer Science and Technology 1(1)\n\n(2008) 15â€“24.\n\n[13] K. Seymore, A. McCallum and R. Rosenfeld, Learning hidden Markov model structure for information\n\nextraction. In: AAAI Workshop on Machine Learning for Information Extraction (1999).\n\n[14] G. Giuffrida, E.C Shek and J. Yang, Knowledge-based metadata extraction from postscript files, ACM\n\nDigital Libraries (2000) 77â€“84.\n\n[15] K. Nakagawa, A. Nomura and M. Suzuki, Extraction of Logical Structure from Articles in Mathematics\n\n(Springer, Berlin, 2004).\n\n[16] M. KrÃ¤mer, H. Kaprykowsky, D. Keysers and T. Breuel, Bibliographic metadata extraction using probabi-\n\nlistic finite state transducers, Ninth International Conference on Document Analysis and Recognition\n\n(2007) 609â€“613.\n\n[17] E.G. Berkowitz and M.R. Elkhadiri, Creation of a Style Independent Intelligent Autonomous Citation\n\nIndexer to Support Academic Research (MAICS 2004) 68â€“73.", "summary": "This section contains a list of references cited in the document, including authors, titles, publication venues, and dates.", "node_type": "semantic_unit", "metadata": {"semantic_type": "references", "start_paragraph": 3, "end_paragraph": 37, "original_title": "References"}, "nodes": [{"title": "References", "start_index": 8, "end_index": 8, "text": "References\n\n[1] K.M. Summers, Automatic discovery of logical document structure (PhD dissertation, Cornell University,\n\nIthaca, NY, 1998).\n\n[2] A. Arasu and H. Garcia-Molina, Extracting structured data from web pages, Proceedings of the 2003 ACM\n\nSIGMOD International Conference on Management of Data (SIGMOD) (June 2003) 337â€“348.\n\n[3] A. Crystal and P. Land, Metadata and search, Global Corporate Circle DCMI 2003 Workshop (2003).\n\nAvailable from http://dublincore.org/groups/corporate/Seattle/\n\n[4] H. Han, C.L. Giles, E. Manavoglu, H. Zha, Z. Zhang and E.A. Fox, Automatic document metadata extraction\n\nusing support vector machine, Joint Conference on Digital Libraries (JCDLâ€™03)  (Houston, Texas USA, 2003).\n\n[5] B.A. Ojokoh, S.O. Falaki and O.S. Adewale, Automated information extraction system for heterogeneous\n\ndigital library documents, Proceedings of the ACM/IEEE Joint Conference on Digital Libraries (JCDL 2007)\n\nDoctoral Consortium (Vancouver, British Columbia, Canada, June 18â€“23, 2007).\n\n[6] A. Kawtrakul and C. Yingsaeree, A Unified Framework for Automatic Metadata Extraction from Electronic\n\nDocument (2004). Available at: http://iadlc.nul.nagoya-u.ac.jp/archives/IADLC2005/kawrtrakul.pdf\n\n[7] E.D. Liddy, S. Sutton, E. Allen, S. Harwell, S. Corieri and O. Yilmazel, Automatic metadata generation and evaluation, Proceedings of the 25th Annual International ACM SIGIR Conference on Research and\n\nDevelopment in Information Retrieval (Tampere, Finland, 2002) 401â€“402.\n\n[8] O. Yilmazel, C.M. Finneran and E.D. Liddy, MetaExtract: an NLP system to automatically assign metadata, Proceedings of the 2004 Joint ACM/IEEE Conference on Digital Libraries  (Tuscan, AZ, USA, 2004) 241â€“242.\n\n[9] S. Mao, J.W. Kim and G.R. Thoma, A dynamic feature generation system for automated metadata extrac-tion in preservation of digital materials, Proceedings of the First International Workshop on Document\n\nImage Analysis for Libraries (Palo Alto, CA, USA, 2004) 225â€“232.\n\n[10] Y. Hu, H. Li, Y. Cao, T. Teng, D. Meyerzon and Q. Zheng, Automatic extraction of titles from general documents, Information Processing and Management 42 (2006) 1276â€“1293.\n\n[11]  F. Peng and A. McCallum, Accurate information extraction from research papers using conditional ran-dom fields, Proceedings of the Human Language Technology Conference/North American Chapter of the\n\nAssociation for Computational Linguistics Annual Meeting (New York, NY, USA, 2004) 329â€“336.\n\n[12] B.A. Ojokoh, O.S. Adewale and S.O. Falaki, Improving on the smoothing technique for obtaining emis-sion probabilities in hidden Markov models, Oriental Journal of Computer Science and Technology 1(1)\n\n(2008) 15â€“24.\n\n[13] K. Seymore, A. McCallum and R. Rosenfeld, Learning hidden Markov model structure for information\n\nextraction. In: AAAI Workshop on Machine Learning for Information Extraction (1999).\n\n[14] G. Giuffrida, E.C Shek and J. Yang, Knowledge-based metadata extraction from postscript files, ACM\n\nDigital Libraries (2000) 77â€“84.\n\n[15] K. Nakagawa, A. Nomura and M. Suzuki, Extraction of Logical Structure from Articles in Mathematics\n\n(Springer, Berlin, 2004).\n\n[16] M. KrÃ¤mer, H. Kaprykowsky, D. Keysers and T. Breuel, Bibliographic metadata extraction using probabi-\n\nlistic finite state transducers, Ninth International Conference on Document Analysis and Recognition\n\n(2007) 609â€“613.\n\n[17] E.G. Berkowitz and M.R. Elkhadiri, Creation of a Style Independent Intelligent Autonomous Citation\n\nIndexer to Support Academic Research (MAICS 2004) 68â€“73.", "summary": "This section lists all the references cited in the document, including author names, publication titles, conference proceedings, and URLs where applicable.", "node_type": "semantic_unit", "metadata": {"semantic_type": "References", "start_paragraph": 0, "end_paragraph": 34, "original_title": "References"}, "nodes": [{"title": "References", "start_index": 8, "end_index": 8, "text": "References\n\n[1] K.M. Summers, Automatic discovery of logical document structure (PhD dissertation, Cornell University,\n\nIthaca, NY, 1998).\n\n[2] A. Arasu and H. Garcia-Molina, Extracting structured data from web pages, Proceedings of the 2003 ACM\n\nSIGMOD International Conference on Management of Data (SIGMOD) (June 2003) 337â€“348.\n\n[3] A. Crystal and P. Land, Metadata and search, Global Corporate Circle DCMI 2003 Workshop (2003).\n\nAvailable from http://dublincore.org/groups/corporate/Seattle/\n\n[4] H. Han, C.L. Giles, E. Manavoglu, H. Zha, Z. Zhang and E.A. Fox, Automatic document metadata extraction\n\nusing support vector machine, Joint Conference on Digital Libraries (JCDLâ€™03)  (Houston, Texas USA, 2003).\n\n[5] B.A. Ojokoh, S.O. Falaki and O.S. Adewale, Automated information extraction system for heterogeneous\n\ndigital library documents, Proceedings of the ACM/IEEE Joint Conference on Digital Libraries (JCDL 2007)\n\nDoctoral Consortium (Vancouver, British Columbia, Canada, June 18â€“23, 2007).\n\n[6] A. Kawtrakul and C. Yingsaeree, A Unified Framework for Automatic Metadata Extraction from Electronic\n\nDocument (2004). Available at: http://iadlc.nul.nagoya-u.ac.jp/archives/IADLC2005/kawrtrakul.pdf\n\n[7] E.D. Liddy, S. Sutton, E. Allen, S. Harwell, S. Corieri and O. Yilmazel, Automatic metadata generation and evaluation, Proceedings of the 25th Annual International ACM SIGIR Conference on Research and\n\nDevelopment in Information Retrieval (Tampere, Finland, 2002) 401â€“402.\n\n[8] O. Yilmazel, C.M. Finneran and E.D. Liddy, MetaExtract: an NLP system to automatically assign metadata, Proceedings of the 2004 Joint ACM/IEEE Conference on Digital Libraries  (Tuscan, AZ, USA, 2004) 241â€“242.\n\n[9] S. Mao, J.W. Kim and G.R. Thoma, A dynamic feature generation system for automated metadata extrac-tion in preservation of digital materials, Proceedings of the First International Workshop on Document\n\nImage Analysis for Libraries (Palo Alto, CA, USA, 2004) 225â€“232.\n\n[10] Y. Hu, H. Li, Y. Cao, T. Teng, D. Meyerzon and Q. Zheng, Automatic extraction of titles from general documents, Information Processing and Management 42 (2006) 1276â€“1293.\n\n[11]  F. Peng and A. McCallum, Accurate information extraction from research papers using conditional ran-dom fields, Proceedings of the Human Language Technology Conference/North American Chapter of the\n\nAssociation for Computational Linguistics Annual Meeting (New York, NY, USA, 2004) 329â€“336.\n\n[12] B.A. Ojokoh, O.S. Adewale and S.O. Falaki, Improving on the smoothing technique for obtaining emis-sion probabilities in hidden Markov models, Oriental Journal of Computer Science and Technology 1(1)\n\n(2008) 15â€“24.\n\n[13] K. Seymore, A. McCallum and R. Rosenfeld, Learning hidden Markov model structure for information\n\nextraction. In: AAAI Workshop on Machine Learning for Information Extraction (1999).\n\n[14] G. Giuffrida, E.C Shek and J. Yang, Knowledge-based metadata extraction from postscript files, ACM\n\nDigital Libraries (2000) 77â€“84.\n\n[15] K. Nakagawa, A. Nomura and M. Suzuki, Extraction of Logical Structure from Articles in Mathematics\n\n(Springer, Berlin, 2004).\n\n[16] M. KrÃ¤mer, H. Kaprykowsky, D. Keysers and T. Breuel, Bibliographic metadata extraction using probabi-\n\nlistic finite state transducers, Ninth International Conference on Document Analysis and Recognition\n\n(2007) 609â€“613.\n\n[17] E.G. Berkowitz and M.R. Elkhadiri, Creation of a Style Independent Intelligent Autonomous Citation\n\nIndexer to Support Academic Research (MAICS 2004) 68â€“73.", "summary": "This section lists all the references cited in the document, including author names, publication titles, conference proceedings, and URLs where applicable.", "node_type": "semantic_unit", "metadata": {"semantic_type": "References", "start_paragraph": 0, "end_paragraph": 34, "original_title": "References"}, "nodes": [{"title": "Logical document structure", "start_index": 8, "end_index": 8, "text": "References\n\n[1] K.M. Summers, Automatic discovery of logical document structure (PhD dissertation, Cornell University,\n\nIthaca, NY, 1998).\n\n[2] A. Arasu and H. Garcia-Molina, Extracting structured data from web pages, Proceedings of the 2003 ACM\n\nSIGMOD International Conference on Management of Data (SIGMOD) (June 2003) 337â€“348.\n\n[3] A. Crystal and P. Land, Metadata and search, Global Corporate Circle DCMI 2003 Workshop (2003).\n\nAvailable from http://dublincore.org/groups/corporate/Seattle/\n\n[4] H. Han, C.L. Giles, E. Manavoglu, H. Zha, Z. Zhang and E.A. Fox, Automatic document metadata extraction\n\nusing support vector machine, Joint Conference on Digital Libraries (JCDLâ€™03)  (Houston, Texas USA, 2003).\n\n[5] B.A. Ojokoh, S.O. Falaki and O.S. Adewale, Automated information extraction system for heterogeneous\n\ndigital library documents, Proceedings of the ACM/IEEE Joint Conference on Digital Libraries (JCDL 2007)\n\nDoctoral Consortium (Vancouver, British Columbia, Canada, June 18â€“23, 2007).\n\n[6] A. Kawtrakul and C. Yingsaeree, A Unified Framework for Automatic Metadata Extraction from Electronic\n\nDocument (2004). Available at: http://iadlc.nul.nagoya-u.ac.jp/archives/IADLC2005/kawrtrakul.pdf\n\n[7] E.D. Liddy, S. Sutton, E. Allen, S. Harwell, S. Corieri and O. Yilmazel, Automatic metadata generation and evaluation, Proceedings of the 25th Annual International ACM SIGIR Conference on Research and\n\nDevelopment in Information Retrieval (Tampere, Finland, 2002) 401â€“402.\n\n[8] O. Yilmazel, C.M. Finneran and E.D. Liddy, MetaExtract: an NLP system to automatically assign metadata, Proceedings of the 2004 Joint ACM/IEEE Conference on Digital Libraries  (Tuscan, AZ, USA, 2004) 241â€“242.\n\n[9] S. Mao, J.W. Kim and G.R. Thoma, A dynamic feature generation system for automated metadata extrac-tion in preservation of digital materials, Proceedings of the First International Workshop on Document\n\nImage Analysis for Libraries (Palo Alto, CA, USA, 2004) 225â€“232.\n\n[10] Y. Hu, H. Li, Y. Cao, T. Teng, D. Meyerzon and Q. Zheng, Automatic extraction of titles from general documents, Information Processing and Management 42 (2006) 1276â€“1293.\n\n[11]  F. Peng and A. McCallum, Accurate information extraction from research papers using conditional ran-dom fields, Proceedings of the Human Language Technology Conference/North American Chapter of the\n\nAssociation for Computational Linguistics Annual Meeting (New York, NY, USA, 2004) 329â€“336.\n\n[12] B.A. Ojokoh, O.S. Adewale and S.O. Falaki, Improving on the smoothing technique for obtaining emis-sion probabilities in hidden Markov models, Oriental Journal of Computer Science and Technology 1(1)\n\n(2008) 15â€“24.\n\n[13] K. Seymore, A. McCallum and R. Rosenfeld, Learning hidden Markov model structure for information\n\nextraction. In: AAAI Workshop on Machine Learning for Information Extraction (1999).\n\n[14] G. Giuffrida, E.C Shek and J. Yang, Knowledge-based metadata extraction from postscript files, ACM\n\nDigital Libraries (2000) 77â€“84.\n\n[15] K. Nakagawa, A. Nomura and M. Suzuki, Extraction of Logical Structure from Articles in Mathematics\n\n(Springer, Berlin, 2004).\n\n[16] M. KrÃ¤mer, H. Kaprykowsky, D. Keysers and T. Breuel, Bibliographic metadata extraction using probabi-\n\nlistic finite state transducers, Ninth International Conference on Document Analysis and Recognition\n\n(2007) 609â€“613.\n\n[17] E.G. Berkowitz and M.R. Elkhadiri, Creation of a Style Independent Intelligent Autonomous Citation\n\nIndexer to Support Academic Research (MAICS 2004) 68â€“73.", "summary": "The underlying organization and hierarchy of elements within a document.", "node_type": "keyword", "_text_locked": true, "metadata": {"term": "Logical document structure", "context": "The underlying organization and hierarchy of elements within a document.", "relevance": "This concept is foundational to understanding how documents are structured and can be processed automatically.", "parent_title": "References", "parent_node_type": "semantic_unit"}, "nodes": [], "node_id": "0338"}, {"title": "Extracting structured data", "start_index": 8, "end_index": 8, "text": "References\n\n[1] K.M. Summers, Automatic discovery of logical document structure (PhD dissertation, Cornell University,\n\nIthaca, NY, 1998).\n\n[2] A. Arasu and H. Garcia-Molina, Extracting structured data from web pages, Proceedings of the 2003 ACM\n\nSIGMOD International Conference on Management of Data (SIGMOD) (June 2003) 337â€“348.\n\n[3] A. Crystal and P. Land, Metadata and search, Global Corporate Circle DCMI 2003 Workshop (2003).\n\nAvailable from http://dublincore.org/groups/corporate/Seattle/\n\n[4] H. Han, C.L. Giles, E. Manavoglu, H. Zha, Z. Zhang and E.A. Fox, Automatic document metadata extraction\n\nusing support vector machine, Joint Conference on Digital Libraries (JCDLâ€™03)  (Houston, Texas USA, 2003).\n\n[5] B.A. Ojokoh, S.O. Falaki and O.S. Adewale, Automated information extraction system for heterogeneous\n\ndigital library documents, Proceedings of the ACM/IEEE Joint Conference on Digital Libraries (JCDL 2007)\n\nDoctoral Consortium (Vancouver, British Columbia, Canada, June 18â€“23, 2007).\n\n[6] A. Kawtrakul and C. Yingsaeree, A Unified Framework for Automatic Metadata Extraction from Electronic\n\nDocument (2004). Available at: http://iadlc.nul.nagoya-u.ac.jp/archives/IADLC2005/kawrtrakul.pdf\n\n[7] E.D. Liddy, S. Sutton, E. Allen, S. Harwell, S. Corieri and O. Yilmazel, Automatic metadata generation and evaluation, Proceedings of the 25th Annual International ACM SIGIR Conference on Research and\n\nDevelopment in Information Retrieval (Tampere, Finland, 2002) 401â€“402.\n\n[8] O. Yilmazel, C.M. Finneran and E.D. Liddy, MetaExtract: an NLP system to automatically assign metadata, Proceedings of the 2004 Joint ACM/IEEE Conference on Digital Libraries  (Tuscan, AZ, USA, 2004) 241â€“242.\n\n[9] S. Mao, J.W. Kim and G.R. Thoma, A dynamic feature generation system for automated metadata extrac-tion in preservation of digital materials, Proceedings of the First International Workshop on Document\n\nImage Analysis for Libraries (Palo Alto, CA, USA, 2004) 225â€“232.\n\n[10] Y. Hu, H. Li, Y. Cao, T. Teng, D. Meyerzon and Q. Zheng, Automatic extraction of titles from general documents, Information Processing and Management 42 (2006) 1276â€“1293.\n\n[11]  F. Peng and A. McCallum, Accurate information extraction from research papers using conditional ran-dom fields, Proceedings of the Human Language Technology Conference/North American Chapter of the\n\nAssociation for Computational Linguistics Annual Meeting (New York, NY, USA, 2004) 329â€“336.\n\n[12] B.A. Ojokoh, O.S. Adewale and S.O. Falaki, Improving on the smoothing technique for obtaining emis-sion probabilities in hidden Markov models, Oriental Journal of Computer Science and Technology 1(1)\n\n(2008) 15â€“24.\n\n[13] K. Seymore, A. McCallum and R. Rosenfeld, Learning hidden Markov model structure for information\n\nextraction. In: AAAI Workshop on Machine Learning for Information Extraction (1999).\n\n[14] G. Giuffrida, E.C Shek and J. Yang, Knowledge-based metadata extraction from postscript files, ACM\n\nDigital Libraries (2000) 77â€“84.\n\n[15] K. Nakagawa, A. Nomura and M. Suzuki, Extraction of Logical Structure from Articles in Mathematics\n\n(Springer, Berlin, 2004).\n\n[16] M. KrÃ¤mer, H. Kaprykowsky, D. Keysers and T. Breuel, Bibliographic metadata extraction using probabi-\n\nlistic finite state transducers, Ninth International Conference on Document Analysis and Recognition\n\n(2007) 609â€“613.\n\n[17] E.G. Berkowitz and M.R. Elkhadiri, Creation of a Style Independent Intelligent Autonomous Citation\n\nIndexer to Support Academic Research (MAICS 2004) 68â€“73.", "summary": "The process of identifying and organizing specific pieces of information from unstructured or semi-structured sources.", "node_type": "keyword", "_text_locked": true, "metadata": {"term": "Extracting structured data", "context": "The process of identifying and organizing specific pieces of information from unstructured or semi-structured sources.", "relevance": "This is a core task addressed by many of the cited works, indicating its importance in the field.", "parent_title": "References", "parent_node_type": "semantic_unit"}, "nodes": [], "node_id": "0339"}, {"title": "Metadata extraction", "start_index": 8, "end_index": 8, "text": "References\n\n[1] K.M. Summers, Automatic discovery of logical document structure (PhD dissertation, Cornell University,\n\nIthaca, NY, 1998).\n\n[2] A. Arasu and H. Garcia-Molina, Extracting structured data from web pages, Proceedings of the 2003 ACM\n\nSIGMOD International Conference on Management of Data (SIGMOD) (June 2003) 337â€“348.\n\n[3] A. Crystal and P. Land, Metadata and search, Global Corporate Circle DCMI 2003 Workshop (2003).\n\nAvailable from http://dublincore.org/groups/corporate/Seattle/\n\n[4] H. Han, C.L. Giles, E. Manavoglu, H. Zha, Z. Zhang and E.A. Fox, Automatic document metadata extraction\n\nusing support vector machine, Joint Conference on Digital Libraries (JCDLâ€™03)  (Houston, Texas USA, 2003).\n\n[5] B.A. Ojokoh, S.O. Falaki and O.S. Adewale, Automated information extraction system for heterogeneous\n\ndigital library documents, Proceedings of the ACM/IEEE Joint Conference on Digital Libraries (JCDL 2007)\n\nDoctoral Consortium (Vancouver, British Columbia, Canada, June 18â€“23, 2007).\n\n[6] A. Kawtrakul and C. Yingsaeree, A Unified Framework for Automatic Metadata Extraction from Electronic\n\nDocument (2004). Available at: http://iadlc.nul.nagoya-u.ac.jp/archives/IADLC2005/kawrtrakul.pdf\n\n[7] E.D. Liddy, S. Sutton, E. Allen, S. Harwell, S. Corieri and O. Yilmazel, Automatic metadata generation and evaluation, Proceedings of the 25th Annual International ACM SIGIR Conference on Research and\n\nDevelopment in Information Retrieval (Tampere, Finland, 2002) 401â€“402.\n\n[8] O. Yilmazel, C.M. Finneran and E.D. Liddy, MetaExtract: an NLP system to automatically assign metadata, Proceedings of the 2004 Joint ACM/IEEE Conference on Digital Libraries  (Tuscan, AZ, USA, 2004) 241â€“242.\n\n[9] S. Mao, J.W. Kim and G.R. Thoma, A dynamic feature generation system for automated metadata extrac-tion in preservation of digital materials, Proceedings of the First International Workshop on Document\n\nImage Analysis for Libraries (Palo Alto, CA, USA, 2004) 225â€“232.\n\n[10] Y. Hu, H. Li, Y. Cao, T. Teng, D. Meyerzon and Q. Zheng, Automatic extraction of titles from general documents, Information Processing and Management 42 (2006) 1276â€“1293.\n\n[11]  F. Peng and A. McCallum, Accurate information extraction from research papers using conditional ran-dom fields, Proceedings of the Human Language Technology Conference/North American Chapter of the\n\nAssociation for Computational Linguistics Annual Meeting (New York, NY, USA, 2004) 329â€“336.\n\n[12] B.A. Ojokoh, O.S. Adewale and S.O. Falaki, Improving on the smoothing technique for obtaining emis-sion probabilities in hidden Markov models, Oriental Journal of Computer Science and Technology 1(1)\n\n(2008) 15â€“24.\n\n[13] K. Seymore, A. McCallum and R. Rosenfeld, Learning hidden Markov model structure for information\n\nextraction. In: AAAI Workshop on Machine Learning for Information Extraction (1999).\n\n[14] G. Giuffrida, E.C Shek and J. Yang, Knowledge-based metadata extraction from postscript files, ACM\n\nDigital Libraries (2000) 77â€“84.\n\n[15] K. Nakagawa, A. Nomura and M. Suzuki, Extraction of Logical Structure from Articles in Mathematics\n\n(Springer, Berlin, 2004).\n\n[16] M. KrÃ¤mer, H. Kaprykowsky, D. Keysers and T. Breuel, Bibliographic metadata extraction using probabi-\n\nlistic finite state transducers, Ninth International Conference on Document Analysis and Recognition\n\n(2007) 609â€“613.\n\n[17] E.G. Berkowitz and M.R. Elkhadiri, Creation of a Style Independent Intelligent Autonomous Citation\n\nIndexer to Support Academic Research (MAICS 2004) 68â€“73.", "summary": "The automated process of identifying and assigning descriptive information (metadata) to digital resources.", "node_type": "keyword", "_text_locked": true, "metadata": {"term": "Metadata extraction", "context": "The automated process of identifying and assigning descriptive information (metadata) to digital resources.", "relevance": "This is a central theme of the cited literature, representing a key application area.", "parent_title": "References", "parent_node_type": "semantic_unit"}, "nodes": [], "node_id": "0340"}, {"title": "Support vector machine", "start_index": 8, "end_index": 8, "text": "References\n\n[1] K.M. Summers, Automatic discovery of logical document structure (PhD dissertation, Cornell University,\n\nIthaca, NY, 1998).\n\n[2] A. Arasu and H. Garcia-Molina, Extracting structured data from web pages, Proceedings of the 2003 ACM\n\nSIGMOD International Conference on Management of Data (SIGMOD) (June 2003) 337â€“348.\n\n[3] A. Crystal and P. Land, Metadata and search, Global Corporate Circle DCMI 2003 Workshop (2003).\n\nAvailable from http://dublincore.org/groups/corporate/Seattle/\n\n[4] H. Han, C.L. Giles, E. Manavoglu, H. Zha, Z. Zhang and E.A. Fox, Automatic document metadata extraction\n\nusing support vector machine, Joint Conference on Digital Libraries (JCDLâ€™03)  (Houston, Texas USA, 2003).\n\n[5] B.A. Ojokoh, S.O. Falaki and O.S. Adewale, Automated information extraction system for heterogeneous\n\ndigital library documents, Proceedings of the ACM/IEEE Joint Conference on Digital Libraries (JCDL 2007)\n\nDoctoral Consortium (Vancouver, British Columbia, Canada, June 18â€“23, 2007).\n\n[6] A. Kawtrakul and C. Yingsaeree, A Unified Framework for Automatic Metadata Extraction from Electronic\n\nDocument (2004). Available at: http://iadlc.nul.nagoya-u.ac.jp/archives/IADLC2005/kawrtrakul.pdf\n\n[7] E.D. Liddy, S. Sutton, E. Allen, S. Harwell, S. Corieri and O. Yilmazel, Automatic metadata generation and evaluation, Proceedings of the 25th Annual International ACM SIGIR Conference on Research and\n\nDevelopment in Information Retrieval (Tampere, Finland, 2002) 401â€“402.\n\n[8] O. Yilmazel, C.M. Finneran and E.D. Liddy, MetaExtract: an NLP system to automatically assign metadata, Proceedings of the 2004 Joint ACM/IEEE Conference on Digital Libraries  (Tuscan, AZ, USA, 2004) 241â€“242.\n\n[9] S. Mao, J.W. Kim and G.R. Thoma, A dynamic feature generation system for automated metadata extrac-tion in preservation of digital materials, Proceedings of the First International Workshop on Document\n\nImage Analysis for Libraries (Palo Alto, CA, USA, 2004) 225â€“232.\n\n[10] Y. Hu, H. Li, Y. Cao, T. Teng, D. Meyerzon and Q. Zheng, Automatic extraction of titles from general documents, Information Processing and Management 42 (2006) 1276â€“1293.\n\n[11]  F. Peng and A. McCallum, Accurate information extraction from research papers using conditional ran-dom fields, Proceedings of the Human Language Technology Conference/North American Chapter of the\n\nAssociation for Computational Linguistics Annual Meeting (New York, NY, USA, 2004) 329â€“336.\n\n[12] B.A. Ojokoh, O.S. Adewale and S.O. Falaki, Improving on the smoothing technique for obtaining emis-sion probabilities in hidden Markov models, Oriental Journal of Computer Science and Technology 1(1)\n\n(2008) 15â€“24.\n\n[13] K. Seymore, A. McCallum and R. Rosenfeld, Learning hidden Markov model structure for information\n\nextraction. In: AAAI Workshop on Machine Learning for Information Extraction (1999).\n\n[14] G. Giuffrida, E.C Shek and J. Yang, Knowledge-based metadata extraction from postscript files, ACM\n\nDigital Libraries (2000) 77â€“84.\n\n[15] K. Nakagawa, A. Nomura and M. Suzuki, Extraction of Logical Structure from Articles in Mathematics\n\n(Springer, Berlin, 2004).\n\n[16] M. KrÃ¤mer, H. Kaprykowsky, D. Keysers and T. Breuel, Bibliographic metadata extraction using probabi-\n\nlistic finite state transducers, Ninth International Conference on Document Analysis and Recognition\n\n(2007) 609â€“613.\n\n[17] E.G. Berkowitz and M.R. Elkhadiri, Creation of a Style Independent Intelligent Autonomous Citation\n\nIndexer to Support Academic Research (MAICS 2004) 68â€“73.", "summary": "A supervised machine learning algorithm used for classification and regression analysis.", "node_type": "keyword", "_text_locked": true, "metadata": {"term": "Support vector machine", "context": "A supervised machine learning algorithm used for classification and regression analysis.", "relevance": "This is a specific machine learning technique mentioned for metadata extraction, highlighting a methodological approach.", "parent_title": "References", "parent_node_type": "semantic_unit"}, "nodes": [], "node_id": "0341"}, {"title": "Information extraction", "start_index": 8, "end_index": 8, "text": "References\n\n[1] K.M. Summers, Automatic discovery of logical document structure (PhD dissertation, Cornell University,\n\nIthaca, NY, 1998).\n\n[2] A. Arasu and H. Garcia-Molina, Extracting structured data from web pages, Proceedings of the 2003 ACM\n\nSIGMOD International Conference on Management of Data (SIGMOD) (June 2003) 337â€“348.\n\n[3] A. Crystal and P. Land, Metadata and search, Global Corporate Circle DCMI 2003 Workshop (2003).\n\nAvailable from http://dublincore.org/groups/corporate/Seattle/\n\n[4] H. Han, C.L. Giles, E. Manavoglu, H. Zha, Z. Zhang and E.A. Fox, Automatic document metadata extraction\n\nusing support vector machine, Joint Conference on Digital Libraries (JCDLâ€™03)  (Houston, Texas USA, 2003).\n\n[5] B.A. Ojokoh, S.O. Falaki and O.S. Adewale, Automated information extraction system for heterogeneous\n\ndigital library documents, Proceedings of the ACM/IEEE Joint Conference on Digital Libraries (JCDL 2007)\n\nDoctoral Consortium (Vancouver, British Columbia, Canada, June 18â€“23, 2007).\n\n[6] A. Kawtrakul and C. Yingsaeree, A Unified Framework for Automatic Metadata Extraction from Electronic\n\nDocument (2004). Available at: http://iadlc.nul.nagoya-u.ac.jp/archives/IADLC2005/kawrtrakul.pdf\n\n[7] E.D. Liddy, S. Sutton, E. Allen, S. Harwell, S. Corieri and O. Yilmazel, Automatic metadata generation and evaluation, Proceedings of the 25th Annual International ACM SIGIR Conference on Research and\n\nDevelopment in Information Retrieval (Tampere, Finland, 2002) 401â€“402.\n\n[8] O. Yilmazel, C.M. Finneran and E.D. Liddy, MetaExtract: an NLP system to automatically assign metadata, Proceedings of the 2004 Joint ACM/IEEE Conference on Digital Libraries  (Tuscan, AZ, USA, 2004) 241â€“242.\n\n[9] S. Mao, J.W. Kim and G.R. Thoma, A dynamic feature generation system for automated metadata extrac-tion in preservation of digital materials, Proceedings of the First International Workshop on Document\n\nImage Analysis for Libraries (Palo Alto, CA, USA, 2004) 225â€“232.\n\n[10] Y. Hu, H. Li, Y. Cao, T. Teng, D. Meyerzon and Q. Zheng, Automatic extraction of titles from general documents, Information Processing and Management 42 (2006) 1276â€“1293.\n\n[11]  F. Peng and A. McCallum, Accurate information extraction from research papers using conditional ran-dom fields, Proceedings of the Human Language Technology Conference/North American Chapter of the\n\nAssociation for Computational Linguistics Annual Meeting (New York, NY, USA, 2004) 329â€“336.\n\n[12] B.A. Ojokoh, O.S. Adewale and S.O. Falaki, Improving on the smoothing technique for obtaining emis-sion probabilities in hidden Markov models, Oriental Journal of Computer Science and Technology 1(1)\n\n(2008) 15â€“24.\n\n[13] K. Seymore, A. McCallum and R. Rosenfeld, Learning hidden Markov model structure for information\n\nextraction. In: AAAI Workshop on Machine Learning for Information Extraction (1999).\n\n[14] G. Giuffrida, E.C Shek and J. Yang, Knowledge-based metadata extraction from postscript files, ACM\n\nDigital Libraries (2000) 77â€“84.\n\n[15] K. Nakagawa, A. Nomura and M. Suzuki, Extraction of Logical Structure from Articles in Mathematics\n\n(Springer, Berlin, 2004).\n\n[16] M. KrÃ¤mer, H. Kaprykowsky, D. Keysers and T. Breuel, Bibliographic metadata extraction using probabi-\n\nlistic finite state transducers, Ninth International Conference on Document Analysis and Recognition\n\n(2007) 609â€“613.\n\n[17] E.G. Berkowitz and M.R. Elkhadiri, Creation of a Style Independent Intelligent Autonomous Citation\n\nIndexer to Support Academic Research (MAICS 2004) 68â€“73.", "summary": "The task of automatically extracting structured information from unstructured or semi-structured machine-readable documents.", "node_type": "keyword", "_text_locked": true, "metadata": {"term": "Information extraction", "context": "The task of automatically extracting structured information from unstructured or semi-structured machine-readable documents.", "relevance": "This is a broad but critical concept that encompasses many of the specific tasks discussed in the references.", "parent_title": "References", "parent_node_type": "semantic_unit"}, "nodes": [], "node_id": "0342"}, {"title": "Digital library documents", "start_index": 8, "end_index": 8, "text": "References\n\n[1] K.M. Summers, Automatic discovery of logical document structure (PhD dissertation, Cornell University,\n\nIthaca, NY, 1998).\n\n[2] A. Arasu and H. Garcia-Molina, Extracting structured data from web pages, Proceedings of the 2003 ACM\n\nSIGMOD International Conference on Management of Data (SIGMOD) (June 2003) 337â€“348.\n\n[3] A. Crystal and P. Land, Metadata and search, Global Corporate Circle DCMI 2003 Workshop (2003).\n\nAvailable from http://dublincore.org/groups/corporate/Seattle/\n\n[4] H. Han, C.L. Giles, E. Manavoglu, H. Zha, Z. Zhang and E.A. Fox, Automatic document metadata extraction\n\nusing support vector machine, Joint Conference on Digital Libraries (JCDLâ€™03)  (Houston, Texas USA, 2003).\n\n[5] B.A. Ojokoh, S.O. Falaki and O.S. Adewale, Automated information extraction system for heterogeneous\n\ndigital library documents, Proceedings of the ACM/IEEE Joint Conference on Digital Libraries (JCDL 2007)\n\nDoctoral Consortium (Vancouver, British Columbia, Canada, June 18â€“23, 2007).\n\n[6] A. Kawtrakul and C. Yingsaeree, A Unified Framework for Automatic Metadata Extraction from Electronic\n\nDocument (2004). Available at: http://iadlc.nul.nagoya-u.ac.jp/archives/IADLC2005/kawrtrakul.pdf\n\n[7] E.D. Liddy, S. Sutton, E. Allen, S. Harwell, S. Corieri and O. Yilmazel, Automatic metadata generation and evaluation, Proceedings of the 25th Annual International ACM SIGIR Conference on Research and\n\nDevelopment in Information Retrieval (Tampere, Finland, 2002) 401â€“402.\n\n[8] O. Yilmazel, C.M. Finneran and E.D. Liddy, MetaExtract: an NLP system to automatically assign metadata, Proceedings of the 2004 Joint ACM/IEEE Conference on Digital Libraries  (Tuscan, AZ, USA, 2004) 241â€“242.\n\n[9] S. Mao, J.W. Kim and G.R. Thoma, A dynamic feature generation system for automated metadata extrac-tion in preservation of digital materials, Proceedings of the First International Workshop on Document\n\nImage Analysis for Libraries (Palo Alto, CA, USA, 2004) 225â€“232.\n\n[10] Y. Hu, H. Li, Y. Cao, T. Teng, D. Meyerzon and Q. Zheng, Automatic extraction of titles from general documents, Information Processing and Management 42 (2006) 1276â€“1293.\n\n[11]  F. Peng and A. McCallum, Accurate information extraction from research papers using conditional ran-dom fields, Proceedings of the Human Language Technology Conference/North American Chapter of the\n\nAssociation for Computational Linguistics Annual Meeting (New York, NY, USA, 2004) 329â€“336.\n\n[12] B.A. Ojokoh, O.S. Adewale and S.O. Falaki, Improving on the smoothing technique for obtaining emis-sion probabilities in hidden Markov models, Oriental Journal of Computer Science and Technology 1(1)\n\n(2008) 15â€“24.\n\n[13] K. Seymore, A. McCallum and R. Rosenfeld, Learning hidden Markov model structure for information\n\nextraction. In: AAAI Workshop on Machine Learning for Information Extraction (1999).\n\n[14] G. Giuffrida, E.C Shek and J. Yang, Knowledge-based metadata extraction from postscript files, ACM\n\nDigital Libraries (2000) 77â€“84.\n\n[15] K. Nakagawa, A. Nomura and M. Suzuki, Extraction of Logical Structure from Articles in Mathematics\n\n(Springer, Berlin, 2004).\n\n[16] M. KrÃ¤mer, H. Kaprykowsky, D. Keysers and T. Breuel, Bibliographic metadata extraction using probabi-\n\nlistic finite state transducers, Ninth International Conference on Document Analysis and Recognition\n\n(2007) 609â€“613.\n\n[17] E.G. Berkowitz and M.R. Elkhadiri, Creation of a Style Independent Intelligent Autonomous Citation\n\nIndexer to Support Academic Research (MAICS 2004) 68â€“73.", "summary": "Electronic documents stored and managed within a digital library system.", "node_type": "keyword", "_text_locked": true, "metadata": {"term": "Digital library documents", "context": "Electronic documents stored and managed within a digital library system.", "relevance": "The context for many of the automated information extraction and metadata generation tasks discussed.", "parent_title": "References", "parent_node_type": "semantic_unit"}, "nodes": [], "node_id": "0343"}, {"title": "NLP system", "start_index": 8, "end_index": 8, "text": "References\n\n[1] K.M. Summers, Automatic discovery of logical document structure (PhD dissertation, Cornell University,\n\nIthaca, NY, 1998).\n\n[2] A. Arasu and H. Garcia-Molina, Extracting structured data from web pages, Proceedings of the 2003 ACM\n\nSIGMOD International Conference on Management of Data (SIGMOD) (June 2003) 337â€“348.\n\n[3] A. Crystal and P. Land, Metadata and search, Global Corporate Circle DCMI 2003 Workshop (2003).\n\nAvailable from http://dublincore.org/groups/corporate/Seattle/\n\n[4] H. Han, C.L. Giles, E. Manavoglu, H. Zha, Z. Zhang and E.A. Fox, Automatic document metadata extraction\n\nusing support vector machine, Joint Conference on Digital Libraries (JCDLâ€™03)  (Houston, Texas USA, 2003).\n\n[5] B.A. Ojokoh, S.O. Falaki and O.S. Adewale, Automated information extraction system for heterogeneous\n\ndigital library documents, Proceedings of the ACM/IEEE Joint Conference on Digital Libraries (JCDL 2007)\n\nDoctoral Consortium (Vancouver, British Columbia, Canada, June 18â€“23, 2007).\n\n[6] A. Kawtrakul and C. Yingsaeree, A Unified Framework for Automatic Metadata Extraction from Electronic\n\nDocument (2004). Available at: http://iadlc.nul.nagoya-u.ac.jp/archives/IADLC2005/kawrtrakul.pdf\n\n[7] E.D. Liddy, S. Sutton, E. Allen, S. Harwell, S. Corieri and O. Yilmazel, Automatic metadata generation and evaluation, Proceedings of the 25th Annual International ACM SIGIR Conference on Research and\n\nDevelopment in Information Retrieval (Tampere, Finland, 2002) 401â€“402.\n\n[8] O. Yilmazel, C.M. Finneran and E.D. Liddy, MetaExtract: an NLP system to automatically assign metadata, Proceedings of the 2004 Joint ACM/IEEE Conference on Digital Libraries  (Tuscan, AZ, USA, 2004) 241â€“242.\n\n[9] S. Mao, J.W. Kim and G.R. Thoma, A dynamic feature generation system for automated metadata extrac-tion in preservation of digital materials, Proceedings of the First International Workshop on Document\n\nImage Analysis for Libraries (Palo Alto, CA, USA, 2004) 225â€“232.\n\n[10] Y. Hu, H. Li, Y. Cao, T. Teng, D. Meyerzon and Q. Zheng, Automatic extraction of titles from general documents, Information Processing and Management 42 (2006) 1276â€“1293.\n\n[11]  F. Peng and A. McCallum, Accurate information extraction from research papers using conditional ran-dom fields, Proceedings of the Human Language Technology Conference/North American Chapter of the\n\nAssociation for Computational Linguistics Annual Meeting (New York, NY, USA, 2004) 329â€“336.\n\n[12] B.A. Ojokoh, O.S. Adewale and S.O. Falaki, Improving on the smoothing technique for obtaining emis-sion probabilities in hidden Markov models, Oriental Journal of Computer Science and Technology 1(1)\n\n(2008) 15â€“24.\n\n[13] K. Seymore, A. McCallum and R. Rosenfeld, Learning hidden Markov model structure for information\n\nextraction. In: AAAI Workshop on Machine Learning for Information Extraction (1999).\n\n[14] G. Giuffrida, E.C Shek and J. Yang, Knowledge-based metadata extraction from postscript files, ACM\n\nDigital Libraries (2000) 77â€“84.\n\n[15] K. Nakagawa, A. Nomura and M. Suzuki, Extraction of Logical Structure from Articles in Mathematics\n\n(Springer, Berlin, 2004).\n\n[16] M. KrÃ¤mer, H. Kaprykowsky, D. Keysers and T. Breuel, Bibliographic metadata extraction using probabi-\n\nlistic finite state transducers, Ninth International Conference on Document Analysis and Recognition\n\n(2007) 609â€“613.\n\n[17] E.G. Berkowitz and M.R. Elkhadiri, Creation of a Style Independent Intelligent Autonomous Citation\n\nIndexer to Support Academic Research (MAICS 2004) 68â€“73.", "summary": "A system that utilizes Natural Language Processing techniques to understand and process human language.", "node_type": "keyword", "_text_locked": true, "metadata": {"term": "NLP system", "context": "A system that utilizes Natural Language Processing techniques to understand and process human language.", "relevance": "This indicates the use of linguistic processing for automated metadata assignment.", "parent_title": "References", "parent_node_type": "semantic_unit"}, "nodes": [], "node_id": "0344"}, {"title": "Feature generation", "start_index": 8, "end_index": 8, "text": "References\n\n[1] K.M. Summers, Automatic discovery of logical document structure (PhD dissertation, Cornell University,\n\nIthaca, NY, 1998).\n\n[2] A. Arasu and H. Garcia-Molina, Extracting structured data from web pages, Proceedings of the 2003 ACM\n\nSIGMOD International Conference on Management of Data (SIGMOD) (June 2003) 337â€“348.\n\n[3] A. Crystal and P. Land, Metadata and search, Global Corporate Circle DCMI 2003 Workshop (2003).\n\nAvailable from http://dublincore.org/groups/corporate/Seattle/\n\n[4] H. Han, C.L. Giles, E. Manavoglu, H. Zha, Z. Zhang and E.A. Fox, Automatic document metadata extraction\n\nusing support vector machine, Joint Conference on Digital Libraries (JCDLâ€™03)  (Houston, Texas USA, 2003).\n\n[5] B.A. Ojokoh, S.O. Falaki and O.S. Adewale, Automated information extraction system for heterogeneous\n\ndigital library documents, Proceedings of the ACM/IEEE Joint Conference on Digital Libraries (JCDL 2007)\n\nDoctoral Consortium (Vancouver, British Columbia, Canada, June 18â€“23, 2007).\n\n[6] A. Kawtrakul and C. Yingsaeree, A Unified Framework for Automatic Metadata Extraction from Electronic\n\nDocument (2004). Available at: http://iadlc.nul.nagoya-u.ac.jp/archives/IADLC2005/kawrtrakul.pdf\n\n[7] E.D. Liddy, S. Sutton, E. Allen, S. Harwell, S. Corieri and O. Yilmazel, Automatic metadata generation and evaluation, Proceedings of the 25th Annual International ACM SIGIR Conference on Research and\n\nDevelopment in Information Retrieval (Tampere, Finland, 2002) 401â€“402.\n\n[8] O. Yilmazel, C.M. Finneran and E.D. Liddy, MetaExtract: an NLP system to automatically assign metadata, Proceedings of the 2004 Joint ACM/IEEE Conference on Digital Libraries  (Tuscan, AZ, USA, 2004) 241â€“242.\n\n[9] S. Mao, J.W. Kim and G.R. Thoma, A dynamic feature generation system for automated metadata extrac-tion in preservation of digital materials, Proceedings of the First International Workshop on Document\n\nImage Analysis for Libraries (Palo Alto, CA, USA, 2004) 225â€“232.\n\n[10] Y. Hu, H. Li, Y. Cao, T. Teng, D. Meyerzon and Q. Zheng, Automatic extraction of titles from general documents, Information Processing and Management 42 (2006) 1276â€“1293.\n\n[11]  F. Peng and A. McCallum, Accurate information extraction from research papers using conditional ran-dom fields, Proceedings of the Human Language Technology Conference/North American Chapter of the\n\nAssociation for Computational Linguistics Annual Meeting (New York, NY, USA, 2004) 329â€“336.\n\n[12] B.A. Ojokoh, O.S. Adewale and S.O. Falaki, Improving on the smoothing technique for obtaining emis-sion probabilities in hidden Markov models, Oriental Journal of Computer Science and Technology 1(1)\n\n(2008) 15â€“24.\n\n[13] K. Seymore, A. McCallum and R. Rosenfeld, Learning hidden Markov model structure for information\n\nextraction. In: AAAI Workshop on Machine Learning for Information Extraction (1999).\n\n[14] G. Giuffrida, E.C Shek and J. Yang, Knowledge-based metadata extraction from postscript files, ACM\n\nDigital Libraries (2000) 77â€“84.\n\n[15] K. Nakagawa, A. Nomura and M. Suzuki, Extraction of Logical Structure from Articles in Mathematics\n\n(Springer, Berlin, 2004).\n\n[16] M. KrÃ¤mer, H. Kaprykowsky, D. Keysers and T. Breuel, Bibliographic metadata extraction using probabi-\n\nlistic finite state transducers, Ninth International Conference on Document Analysis and Recognition\n\n(2007) 609â€“613.\n\n[17] E.G. Berkowitz and M.R. Elkhadiri, Creation of a Style Independent Intelligent Autonomous Citation\n\nIndexer to Support Academic Research (MAICS 2004) 68â€“73.", "summary": "The process of creating new input features from existing data to improve the performance of machine learning models.", "node_type": "keyword", "_text_locked": true, "metadata": {"term": "Feature generation", "context": "The process of creating new input features from existing data to improve the performance of machine learning models.", "relevance": "This is a technical aspect of building automated extraction systems, relevant to model development.", "parent_title": "References", "parent_node_type": "semantic_unit"}, "nodes": [], "node_id": "0345"}, {"title": "Conditional random fields", "start_index": 8, "end_index": 8, "text": "References\n\n[1] K.M. Summers, Automatic discovery of logical document structure (PhD dissertation, Cornell University,\n\nIthaca, NY, 1998).\n\n[2] A. Arasu and H. Garcia-Molina, Extracting structured data from web pages, Proceedings of the 2003 ACM\n\nSIGMOD International Conference on Management of Data (SIGMOD) (June 2003) 337â€“348.\n\n[3] A. Crystal and P. Land, Metadata and search, Global Corporate Circle DCMI 2003 Workshop (2003).\n\nAvailable from http://dublincore.org/groups/corporate/Seattle/\n\n[4] H. Han, C.L. Giles, E. Manavoglu, H. Zha, Z. Zhang and E.A. Fox, Automatic document metadata extraction\n\nusing support vector machine, Joint Conference on Digital Libraries (JCDLâ€™03)  (Houston, Texas USA, 2003).\n\n[5] B.A. Ojokoh, S.O. Falaki and O.S. Adewale, Automated information extraction system for heterogeneous\n\ndigital library documents, Proceedings of the ACM/IEEE Joint Conference on Digital Libraries (JCDL 2007)\n\nDoctoral Consortium (Vancouver, British Columbia, Canada, June 18â€“23, 2007).\n\n[6] A. Kawtrakul and C. Yingsaeree, A Unified Framework for Automatic Metadata Extraction from Electronic\n\nDocument (2004). Available at: http://iadlc.nul.nagoya-u.ac.jp/archives/IADLC2005/kawrtrakul.pdf\n\n[7] E.D. Liddy, S. Sutton, E. Allen, S. Harwell, S. Corieri and O. Yilmazel, Automatic metadata generation and evaluation, Proceedings of the 25th Annual International ACM SIGIR Conference on Research and\n\nDevelopment in Information Retrieval (Tampere, Finland, 2002) 401â€“402.\n\n[8] O. Yilmazel, C.M. Finneran and E.D. Liddy, MetaExtract: an NLP system to automatically assign metadata, Proceedings of the 2004 Joint ACM/IEEE Conference on Digital Libraries  (Tuscan, AZ, USA, 2004) 241â€“242.\n\n[9] S. Mao, J.W. Kim and G.R. Thoma, A dynamic feature generation system for automated metadata extrac-tion in preservation of digital materials, Proceedings of the First International Workshop on Document\n\nImage Analysis for Libraries (Palo Alto, CA, USA, 2004) 225â€“232.\n\n[10] Y. Hu, H. Li, Y. Cao, T. Teng, D. Meyerzon and Q. Zheng, Automatic extraction of titles from general documents, Information Processing and Management 42 (2006) 1276â€“1293.\n\n[11]  F. Peng and A. McCallum, Accurate information extraction from research papers using conditional ran-dom fields, Proceedings of the Human Language Technology Conference/North American Chapter of the\n\nAssociation for Computational Linguistics Annual Meeting (New York, NY, USA, 2004) 329â€“336.\n\n[12] B.A. Ojokoh, O.S. Adewale and S.O. Falaki, Improving on the smoothing technique for obtaining emis-sion probabilities in hidden Markov models, Oriental Journal of Computer Science and Technology 1(1)\n\n(2008) 15â€“24.\n\n[13] K. Seymore, A. McCallum and R. Rosenfeld, Learning hidden Markov model structure for information\n\nextraction. In: AAAI Workshop on Machine Learning for Information Extraction (1999).\n\n[14] G. Giuffrida, E.C Shek and J. Yang, Knowledge-based metadata extraction from postscript files, ACM\n\nDigital Libraries (2000) 77â€“84.\n\n[15] K. Nakagawa, A. Nomura and M. Suzuki, Extraction of Logical Structure from Articles in Mathematics\n\n(Springer, Berlin, 2004).\n\n[16] M. KrÃ¤mer, H. Kaprykowsky, D. Keysers and T. Breuel, Bibliographic metadata extraction using probabi-\n\nlistic finite state transducers, Ninth International Conference on Document Analysis and Recognition\n\n(2007) 609â€“613.\n\n[17] E.G. Berkowitz and M.R. Elkhadiri, Creation of a Style Independent Intelligent Autonomous Citation\n\nIndexer to Support Academic Research (MAICS 2004) 68â€“73.", "summary": "A type of discriminative probabilistic graphical model used for labeling sequence data.", "node_type": "keyword", "_text_locked": true, "metadata": {"term": "Conditional random fields", "context": "A type of discriminative probabilistic graphical model used for labeling sequence data.", "relevance": "This is a specific machine learning model mentioned for accurate information extraction from research papers.", "parent_title": "References", "parent_node_type": "semantic_unit"}, "nodes": [], "node_id": "0346"}, {"title": "Hidden Markov models", "start_index": 8, "end_index": 8, "text": "References\n\n[1] K.M. Summers, Automatic discovery of logical document structure (PhD dissertation, Cornell University,\n\nIthaca, NY, 1998).\n\n[2] A. Arasu and H. Garcia-Molina, Extracting structured data from web pages, Proceedings of the 2003 ACM\n\nSIGMOD International Conference on Management of Data (SIGMOD) (June 2003) 337â€“348.\n\n[3] A. Crystal and P. Land, Metadata and search, Global Corporate Circle DCMI 2003 Workshop (2003).\n\nAvailable from http://dublincore.org/groups/corporate/Seattle/\n\n[4] H. Han, C.L. Giles, E. Manavoglu, H. Zha, Z. Zhang and E.A. Fox, Automatic document metadata extraction\n\nusing support vector machine, Joint Conference on Digital Libraries (JCDLâ€™03)  (Houston, Texas USA, 2003).\n\n[5] B.A. Ojokoh, S.O. Falaki and O.S. Adewale, Automated information extraction system for heterogeneous\n\ndigital library documents, Proceedings of the ACM/IEEE Joint Conference on Digital Libraries (JCDL 2007)\n\nDoctoral Consortium (Vancouver, British Columbia, Canada, June 18â€“23, 2007).\n\n[6] A. Kawtrakul and C. Yingsaeree, A Unified Framework for Automatic Metadata Extraction from Electronic\n\nDocument (2004). Available at: http://iadlc.nul.nagoya-u.ac.jp/archives/IADLC2005/kawrtrakul.pdf\n\n[7] E.D. Liddy, S. Sutton, E. Allen, S. Harwell, S. Corieri and O. Yilmazel, Automatic metadata generation and evaluation, Proceedings of the 25th Annual International ACM SIGIR Conference on Research and\n\nDevelopment in Information Retrieval (Tampere, Finland, 2002) 401â€“402.\n\n[8] O. Yilmazel, C.M. Finneran and E.D. Liddy, MetaExtract: an NLP system to automatically assign metadata, Proceedings of the 2004 Joint ACM/IEEE Conference on Digital Libraries  (Tuscan, AZ, USA, 2004) 241â€“242.\n\n[9] S. Mao, J.W. Kim and G.R. Thoma, A dynamic feature generation system for automated metadata extrac-tion in preservation of digital materials, Proceedings of the First International Workshop on Document\n\nImage Analysis for Libraries (Palo Alto, CA, USA, 2004) 225â€“232.\n\n[10] Y. Hu, H. Li, Y. Cao, T. Teng, D. Meyerzon and Q. Zheng, Automatic extraction of titles from general documents, Information Processing and Management 42 (2006) 1276â€“1293.\n\n[11]  F. Peng and A. McCallum, Accurate information extraction from research papers using conditional ran-dom fields, Proceedings of the Human Language Technology Conference/North American Chapter of the\n\nAssociation for Computational Linguistics Annual Meeting (New York, NY, USA, 2004) 329â€“336.\n\n[12] B.A. Ojokoh, O.S. Adewale and S.O. Falaki, Improving on the smoothing technique for obtaining emis-sion probabilities in hidden Markov models, Oriental Journal of Computer Science and Technology 1(1)\n\n(2008) 15â€“24.\n\n[13] K. Seymore, A. McCallum and R. Rosenfeld, Learning hidden Markov model structure for information\n\nextraction. In: AAAI Workshop on Machine Learning for Information Extraction (1999).\n\n[14] G. Giuffrida, E.C Shek and J. Yang, Knowledge-based metadata extraction from postscript files, ACM\n\nDigital Libraries (2000) 77â€“84.\n\n[15] K. Nakagawa, A. Nomura and M. Suzuki, Extraction of Logical Structure from Articles in Mathematics\n\n(Springer, Berlin, 2004).\n\n[16] M. KrÃ¤mer, H. Kaprykowsky, D. Keysers and T. Breuel, Bibliographic metadata extraction using probabi-\n\nlistic finite state transducers, Ninth International Conference on Document Analysis and Recognition\n\n(2007) 609â€“613.\n\n[17] E.G. Berkowitz and M.R. Elkhadiri, Creation of a Style Independent Intelligent Autonomous Citation\n\nIndexer to Support Academic Research (MAICS 2004) 68â€“73.", "summary": "Statistical models used for modeling sequential data, often applied in speech recognition and bioinformatics.", "node_type": "keyword", "_text_locked": true, "metadata": {"term": "Hidden Markov models", "context": "Statistical models used for modeling sequential data, often applied in speech recognition and bioinformatics.", "relevance": "This is a statistical modeling technique relevant to information extraction, particularly in improving probability estimations.", "parent_title": "References", "parent_node_type": "semantic_unit"}, "nodes": [], "node_id": "0347"}, {"title": "Knowledge-based extraction", "start_index": 8, "end_index": 8, "text": "References\n\n[1] K.M. Summers, Automatic discovery of logical document structure (PhD dissertation, Cornell University,\n\nIthaca, NY, 1998).\n\n[2] A. Arasu and H. Garcia-Molina, Extracting structured data from web pages, Proceedings of the 2003 ACM\n\nSIGMOD International Conference on Management of Data (SIGMOD) (June 2003) 337â€“348.\n\n[3] A. Crystal and P. Land, Metadata and search, Global Corporate Circle DCMI 2003 Workshop (2003).\n\nAvailable from http://dublincore.org/groups/corporate/Seattle/\n\n[4] H. Han, C.L. Giles, E. Manavoglu, H. Zha, Z. Zhang and E.A. Fox, Automatic document metadata extraction\n\nusing support vector machine, Joint Conference on Digital Libraries (JCDLâ€™03)  (Houston, Texas USA, 2003).\n\n[5] B.A. Ojokoh, S.O. Falaki and O.S. Adewale, Automated information extraction system for heterogeneous\n\ndigital library documents, Proceedings of the ACM/IEEE Joint Conference on Digital Libraries (JCDL 2007)\n\nDoctoral Consortium (Vancouver, British Columbia, Canada, June 18â€“23, 2007).\n\n[6] A. Kawtrakul and C. Yingsaeree, A Unified Framework for Automatic Metadata Extraction from Electronic\n\nDocument (2004). Available at: http://iadlc.nul.nagoya-u.ac.jp/archives/IADLC2005/kawrtrakul.pdf\n\n[7] E.D. Liddy, S. Sutton, E. Allen, S. Harwell, S. Corieri and O. Yilmazel, Automatic metadata generation and evaluation, Proceedings of the 25th Annual International ACM SIGIR Conference on Research and\n\nDevelopment in Information Retrieval (Tampere, Finland, 2002) 401â€“402.\n\n[8] O. Yilmazel, C.M. Finneran and E.D. Liddy, MetaExtract: an NLP system to automatically assign metadata, Proceedings of the 2004 Joint ACM/IEEE Conference on Digital Libraries  (Tuscan, AZ, USA, 2004) 241â€“242.\n\n[9] S. Mao, J.W. Kim and G.R. Thoma, A dynamic feature generation system for automated metadata extrac-tion in preservation of digital materials, Proceedings of the First International Workshop on Document\n\nImage Analysis for Libraries (Palo Alto, CA, USA, 2004) 225â€“232.\n\n[10] Y. Hu, H. Li, Y. Cao, T. Teng, D. Meyerzon and Q. Zheng, Automatic extraction of titles from general documents, Information Processing and Management 42 (2006) 1276â€“1293.\n\n[11]  F. Peng and A. McCallum, Accurate information extraction from research papers using conditional ran-dom fields, Proceedings of the Human Language Technology Conference/North American Chapter of the\n\nAssociation for Computational Linguistics Annual Meeting (New York, NY, USA, 2004) 329â€“336.\n\n[12] B.A. Ojokoh, O.S. Adewale and S.O. Falaki, Improving on the smoothing technique for obtaining emis-sion probabilities in hidden Markov models, Oriental Journal of Computer Science and Technology 1(1)\n\n(2008) 15â€“24.\n\n[13] K. Seymore, A. McCallum and R. Rosenfeld, Learning hidden Markov model structure for information\n\nextraction. In: AAAI Workshop on Machine Learning for Information Extraction (1999).\n\n[14] G. Giuffrida, E.C Shek and J. Yang, Knowledge-based metadata extraction from postscript files, ACM\n\nDigital Libraries (2000) 77â€“84.\n\n[15] K. Nakagawa, A. Nomura and M. Suzuki, Extraction of Logical Structure from Articles in Mathematics\n\n(Springer, Berlin, 2004).\n\n[16] M. KrÃ¤mer, H. Kaprykowsky, D. Keysers and T. Breuel, Bibliographic metadata extraction using probabi-\n\nlistic finite state transducers, Ninth International Conference on Document Analysis and Recognition\n\n(2007) 609â€“613.\n\n[17] E.G. Berkowitz and M.R. Elkhadiri, Creation of a Style Independent Intelligent Autonomous Citation\n\nIndexer to Support Academic Research (MAICS 2004) 68â€“73.", "summary": "Information extraction that utilizes domain knowledge or ontologies to guide the process.", "node_type": "keyword", "_text_locked": true, "metadata": {"term": "Knowledge-based extraction", "context": "Information extraction that utilizes domain knowledge or ontologies to guide the process.", "relevance": "This represents a specific approach to metadata extraction, contrasting with purely statistical methods.", "parent_title": "References", "parent_node_type": "semantic_unit"}, "nodes": [], "node_id": "0348"}, {"title": "Bibliographic metadata", "start_index": 8, "end_index": 8, "text": "References\n\n[1] K.M. Summers, Automatic discovery of logical document structure (PhD dissertation, Cornell University,\n\nIthaca, NY, 1998).\n\n[2] A. Arasu and H. Garcia-Molina, Extracting structured data from web pages, Proceedings of the 2003 ACM\n\nSIGMOD International Conference on Management of Data (SIGMOD) (June 2003) 337â€“348.\n\n[3] A. Crystal and P. Land, Metadata and search, Global Corporate Circle DCMI 2003 Workshop (2003).\n\nAvailable from http://dublincore.org/groups/corporate/Seattle/\n\n[4] H. Han, C.L. Giles, E. Manavoglu, H. Zha, Z. Zhang and E.A. Fox, Automatic document metadata extraction\n\nusing support vector machine, Joint Conference on Digital Libraries (JCDLâ€™03)  (Houston, Texas USA, 2003).\n\n[5] B.A. Ojokoh, S.O. Falaki and O.S. Adewale, Automated information extraction system for heterogeneous\n\ndigital library documents, Proceedings of the ACM/IEEE Joint Conference on Digital Libraries (JCDL 2007)\n\nDoctoral Consortium (Vancouver, British Columbia, Canada, June 18â€“23, 2007).\n\n[6] A. Kawtrakul and C. Yingsaeree, A Unified Framework for Automatic Metadata Extraction from Electronic\n\nDocument (2004). Available at: http://iadlc.nul.nagoya-u.ac.jp/archives/IADLC2005/kawrtrakul.pdf\n\n[7] E.D. Liddy, S. Sutton, E. Allen, S. Harwell, S. Corieri and O. Yilmazel, Automatic metadata generation and evaluation, Proceedings of the 25th Annual International ACM SIGIR Conference on Research and\n\nDevelopment in Information Retrieval (Tampere, Finland, 2002) 401â€“402.\n\n[8] O. Yilmazel, C.M. Finneran and E.D. Liddy, MetaExtract: an NLP system to automatically assign metadata, Proceedings of the 2004 Joint ACM/IEEE Conference on Digital Libraries  (Tuscan, AZ, USA, 2004) 241â€“242.\n\n[9] S. Mao, J.W. Kim and G.R. Thoma, A dynamic feature generation system for automated metadata extrac-tion in preservation of digital materials, Proceedings of the First International Workshop on Document\n\nImage Analysis for Libraries (Palo Alto, CA, USA, 2004) 225â€“232.\n\n[10] Y. Hu, H. Li, Y. Cao, T. Teng, D. Meyerzon and Q. Zheng, Automatic extraction of titles from general documents, Information Processing and Management 42 (2006) 1276â€“1293.\n\n[11]  F. Peng and A. McCallum, Accurate information extraction from research papers using conditional ran-dom fields, Proceedings of the Human Language Technology Conference/North American Chapter of the\n\nAssociation for Computational Linguistics Annual Meeting (New York, NY, USA, 2004) 329â€“336.\n\n[12] B.A. Ojokoh, O.S. Adewale and S.O. Falaki, Improving on the smoothing technique for obtaining emis-sion probabilities in hidden Markov models, Oriental Journal of Computer Science and Technology 1(1)\n\n(2008) 15â€“24.\n\n[13] K. Seymore, A. McCallum and R. Rosenfeld, Learning hidden Markov model structure for information\n\nextraction. In: AAAI Workshop on Machine Learning for Information Extraction (1999).\n\n[14] G. Giuffrida, E.C Shek and J. Yang, Knowledge-based metadata extraction from postscript files, ACM\n\nDigital Libraries (2000) 77â€“84.\n\n[15] K. Nakagawa, A. Nomura and M. Suzuki, Extraction of Logical Structure from Articles in Mathematics\n\n(Springer, Berlin, 2004).\n\n[16] M. KrÃ¤mer, H. Kaprykowsky, D. Keysers and T. Breuel, Bibliographic metadata extraction using probabi-\n\nlistic finite state transducers, Ninth International Conference on Document Analysis and Recognition\n\n(2007) 609â€“613.\n\n[17] E.G. Berkowitz and M.R. Elkhadiri, Creation of a Style Independent Intelligent Autonomous Citation\n\nIndexer to Support Academic Research (MAICS 2004) 68â€“73.", "summary": "Descriptive information about scholarly publications, such as authors, titles, and publication venues.", "node_type": "keyword", "_text_locked": true, "metadata": {"term": "Bibliographic metadata", "context": "Descriptive information about scholarly publications, such as authors, titles, and publication venues.", "relevance": "This is a specific type of metadata that is a target for automated extraction systems.", "parent_title": "References", "parent_node_type": "semantic_unit"}, "nodes": [], "node_id": "0349"}], "node_id": "0337"}], "node_id": "0336"}], "node_id": "0335"}], "node_id": "0327"}];
        
        function showNodeDetails(nodeId) {
            const node = findNode(nodeData, nodeId);
            if (!node) return;
            
            // Update active state
            document.querySelectorAll('.node-title').forEach(el => {
                el.classList.remove('active');
            });
            document.querySelector(`[data-node-id="${nodeId}"]`).classList.add('active');
            
            // Generate content
            const content = document.getElementById('content');
            content.innerHTML = generateNodeDetails(node);
        }
        
        function findNode(nodes, nodeId) {
            for (const node of nodes) {
                if (node.node_id === nodeId) return node;
                if (node.nodes && node.nodes.length > 0) {
                    const found = findNode(node.nodes, nodeId);
                    if (found) return found;
                }
            }
            return null;
        }
        
        function generateNodeDetails(node) {
            const hasText = node.text && node.text.trim().length > 0;
            const hasSummary = node.summary && node.summary.trim().length > 0;
            const hasChildren = node.nodes && node.nodes.length > 0;
            
            let html = `
                <div class="detail-section">
                    <h2>${escapeHtml(node.title)}</h2>
                    
                    <div class="metadata">
                        <div class="metadata-item">
                            <span class="metadata-label">Node ID:</span> ${node.node_id || 'N/A'}
                        </div>
                        <div class="metadata-item">
                            <span class="metadata-label">Pages:</span> ${node.start_index} - ${node.end_index}
                        </div>
                        ${node.node_type ? `
                        <div class="metadata-item">
                            <span class="metadata-label">Type:</span> ${node.node_type}
                        </div>
                        ` : ''}
                    </div>
                    
                    <div class="stats">
                        <div class="stat">ğŸ“ Text: ${hasText ? node.text.length + ' chars' : 'None'}</div>
                        <div class="stat">ğŸ“‹ Summary: ${hasSummary ? node.summary.length + ' chars' : 'None'}</div>
                        <div class="stat">ğŸ‘¶ Children: ${hasChildren ? node.nodes.length : '0'}</div>
                    </div>
            `;
            
            // Special handling for keyword nodes
            if (node.node_type === 'keyword' && node.metadata) {
                html += `
                    <div style="background: #e8f5e9; padding: 1rem; border-radius: 6px; border-left: 4px solid #4caf50; margin-bottom: 1rem;">
                        <h3 style="color: #2e7d32; margin-bottom: 0.5rem;">ğŸ”‘ Keyword Details</h3>
                        ${node.metadata.term ? `
                        <div style="margin-bottom: 0.5rem;">
                            <strong>Term:</strong> ${escapeHtml(node.metadata.term)}
                        </div>
                        ` : ''}
                        ${node.metadata.context ? `
                        <div style="margin-bottom: 0.5rem;">
                            <strong>Context:</strong> ${escapeHtml(node.metadata.context)}
                        </div>
                        ` : ''}
                        ${node.metadata.relevance ? `
                        <div style="margin-bottom: 0.5rem;">
                            <strong>Relevance:</strong> ${escapeHtml(node.metadata.relevance)}
                        </div>
                        ` : ''}
                        ${node.metadata.parent_title ? `
                        <div style="margin-top: 0.75rem; padding-top: 0.75rem; border-top: 1px solid #c8e6c9;">
                            <strong>Parent Section:</strong> ${escapeHtml(node.metadata.parent_title)}
                            ${node.metadata.parent_node_type ? ` <span style="font-size: 0.85em; color: #666;">(${node.metadata.parent_node_type})</span>` : ''}
                        </div>
                        ` : ''}
                    </div>
                `;
            }
            
            // Check for duplicate text issue
            if (hasChildren && hasText) {
                const childTexts = node.nodes.filter(n => n.text).map(n => n.text);
                const allSame = childTexts.length > 1 && childTexts.every(t => t === childTexts[0]);
                
                if (allSame && childTexts[0] === node.text) {
                    html += `
                        <div class="warning">
                            <div class="warning-title">âš ï¸ Duplicate Text Detected</div>
                            All child nodes have identical text content (same as parent). This typically happens in coarse granularity mode.
                            Consider using medium or fine granularity for proper text segmentation.
                        </div>
                    `;
                }
            }
            
            if (hasSummary) {
                html += `
                    <h3>Summary</h3>
                    <div class="summary-content">${escapeHtml(node.summary)}</div>
                `;
            }
            
            if (hasText) {
                const preview = node.text.length > 5000 ? 
                    node.text.substring(0, 5000) + '\n\n... (truncated, ' + (node.text.length - 5000) + ' more characters)' : 
                    node.text;
                    
                html += `
                    <h3>Text Content</h3>
                    <div class="text-content">${escapeHtml(preview)}</div>
                `;
            }
            
            if (hasChildren) {
                html += `
                    <div class="children-info">
                        <strong>Child Nodes (${node.nodes.length}):</strong><br>
                        ${node.nodes.map(n => `â€¢ ${escapeHtml(n.title)} (Pages ${n.start_index}-${n.end_index})`).join('<br>')}
                    </div>
                `;
            }
            
            html += '</div>';
            return html;
        }
        
        function escapeHtml(text) {
            const div = document.createElement('div');
            div.textContent = text;
            return div.innerHTML;
        }
    </script>
</body>
</html>
